working directory /home/cs.aau.dk/ng78zb/vec2text_exp
sif /home/cs.aau.dk/ng78zb/pytorch_23.10-py3.sif
launch evaluation yiyic/mt5_me5_indo-aryan-fami_32_2layers_corrector with batch size 8
loading experiment and trainer from yiyic/mt5_me5_indo-aryan-fami_32_2layers_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector
on rank 0, output dir: saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_inverter
on rank 0, output dir: saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_inverter
adding embedding type to dataset args.
Loading datasets with TOKENIZERS_PARALLELISM = False
loading train dataset from path: /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/563419ae595a6ce34101b4f4bb0ae282.arrow
loaded dict of val datasets from /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/b7c2d88873c9bb4061ee54b83d4d22ce.arrow
07/04/2024 14:42:36 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
07/04/2024 14:43:36 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
data arguments for experiment: DataArguments(dataset_name='mt-ms_ind_fami', max_eval_samples=500, use_less_data=3000)
model yiyic/mt5_me5_indo-aryan-fami_32_2layers_corrector parameters 890566656
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
Using Frozen Embeddings as Input -- Val datasets
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '24e7b7ef1b0606ddc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7cf9deee5c6ee34dc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7d3c7a3fdc899099c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'a808a07212534aa6c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '1835610d5c7fc595c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '74575508bfab4c9cc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'af6bef1b30e3c5dbc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'bfa2f55e85bb2562c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd839c9a8871bbce8c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '67555e67fd16afc9c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '48ec325196197014c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'a20c740ae5a0d86bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'cc2235accdffe49bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '104320b250ecc6cac111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd7b432ef61da1e93c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'c06e214a198bcc2cc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '3ae3df71733802abc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '18a40ab4beb7f210c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '96cd5258a58b461bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7ee1e04e96a3faa2c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
output dir ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations
evaluating deu_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Allereerst Allereerst Allereerst Allereerst Allereerst Allereerst Allereerst Allereerst. Sortiment de producten sind relevant voor Auswahlmöglichkeiten
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: A Salon für Beauty, Schönheit & Beauty Unsere Dienstleistungen bieten us a große Auswahl von Beauty Services und
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720097253/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720097253
{'eval_loss': 3.5201175212860107, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2422425363097294, 'eval_token_set_recall': 0.34628154832783375, 'eval_token_set_f1': 0.27983195147325773, 'eval_token_set_f1_sem': 0.004212165546337277, 'eval_n_ngrams_match_1': 4.808, 'eval_n_ngrams_match_2': 1.286, 'eval_n_ngrams_match_3': 0.104, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 17.79, 'eval_bleu_score': 5.372605775492211, 'eval_bleu_score_sem': 0.1254460076210943, 'eval_rouge_score': 0.19010605256401014, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8952723741531372, 'eval_emb_cos_sim_sem': 0.017198711689514673, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 101.8814, 'eval_samples_per_second': 4.908, 'eval_steps_per_second': 0.618}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/deu_Latn_steps-1.json
evaluating corrector with steps 20
[pred] query: Allereerst Bestellen Bestellen Bestellen Alle artikelen sind relevant voor onze categorie Convenient Winkels Informatie Informatie Informatie
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Notre Salon Haute-Qualität vous offre des services et prestations pour un beaulissement et un Glamour. Vous 
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720097674/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720097674
{'eval_loss': 3.5201175212860107, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2722728018093244, 'eval_token_set_recall': 0.35961269093823334, 'eval_token_set_f1': 0.3054990393587766, 'eval_token_set_f1_sem': 0.0044503719187885, 'eval_n_ngrams_match_1': 5.412, 'eval_n_ngrams_match_2': 1.424, 'eval_n_ngrams_match_3': 0.162, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.158, 'eval_bleu_score': 5.895412490618786, 'eval_bleu_score_sem': 0.14018766865512355, 'eval_rouge_score': 0.2260321497964119, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8916186690330505, 'eval_emb_cos_sim_sem': 0.014838805591357456, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 421.2912, 'eval_samples_per_second': 1.187, 'eval_steps_per_second': 0.15}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/deu_Latn_steps-20.json
evaluating corrector with steps 50
[pred] query: Allereerst Bestellen Bestellen Bestellen Alle artikelen sind relevant voor onze categorie Convenient Winkels Informatie Informatie Informatie
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Notre Salon Haute-Qualität vous offre des services et prestations pour un beaulissement et un Glamour. Vous 
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller Produkte 2021 ▷ Bestseller
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720098628/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720098628
{'eval_loss': 3.5201175212860107, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2721779719315998, 'eval_token_set_recall': 0.35975663625160614, 'eval_token_set_f1': 0.3054724582232811, 'eval_token_set_f1_sem': 0.004455300924413254, 'eval_n_ngrams_match_1': 5.41, 'eval_n_ngrams_match_2': 1.426, 'eval_n_ngrams_match_3': 0.168, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.152, 'eval_bleu_score': 5.917798184830048, 'eval_bleu_score_sem': 0.14167338468440976, 'eval_rouge_score': 0.22641128550408418, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8927391767501831, 'eval_emb_cos_sim_sem': 0.01500776572159255, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 954.3758, 'eval_samples_per_second': 0.524, 'eval_steps_per_second': 0.066}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/deu_Latn_steps-50.json
evaluating corrector with steps 50 and beam width 4
[pred] query: Allerbeste Wareninformationen in Allerbeste Wareninformationen in Allerbeste Wareninformationen in Allerbeste Wareninformationen in Allerbeste Wareninformationen in Allerbeste Waren
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Salon Haute Dienstleistungen und Beratung bieten us a große Palette von Dienstleistungen für Schönheit, Beauty & Beauty
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: Anfang 2021 ▷ Ausgewählte Bestseller Produkte ▷ Unsere Bestseller Produkte ▷ Unsere Bestseller ▷
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720101212/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720101212
{'eval_loss': 3.5201175212860107, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2555566248617302, 'eval_token_set_recall': 0.3871294267211084, 'eval_token_set_f1': 0.3005845723340095, 'eval_token_set_f1_sem': 0.004453075521844074, 'eval_n_ngrams_match_1': 5.078, 'eval_n_ngrams_match_2': 1.412, 'eval_n_ngrams_match_3': 0.154, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 17.742, 'eval_bleu_score': 5.675927606223509, 'eval_bleu_score_sem': 0.13704997013649206, 'eval_rouge_score': 0.21176843965339737, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8942701816558838, 'eval_emb_cos_sim_sem': 0.011827097163890247, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 2583.8254, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/deu_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 10.08 GiB is free. Including non-PyTorch memory, this process has 34.44 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 4.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating ydd_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: ચીન / ટાઇટેન / ટાઇટેન કચેરીએ 5 હુલ્વેન રેટ
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: اذان المسجد، اذان المسجد، اذان المسجد - www.khaskhabar.com اذا
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: તમે ટ્રમ્પને ઇનકાર કરીશ : અમારા ટ્રમ્પને ઇનકાર કરીશ મમતા બેન્ચ
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720101322/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720101322
{'eval_loss': 8.040231704711914, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.24655132902872834, 'eval_token_set_recall': 0.31832454473631006, 'eval_token_set_f1': 0.27473494394265513, 'eval_token_set_f1_sem': 0.003938360464262588, 'eval_n_ngrams_match_1': 3.53, 'eval_n_ngrams_match_2': 1.232, 'eval_n_ngrams_match_3': 0.1, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 13.084, 'eval_bleu_score': 6.956133977761644, 'eval_bleu_score_sem': 0.14617947857974498, 'eval_rouge_score': 0.7324532404225501, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8948961496353149, 'eval_emb_cos_sim_sem': 0.01542730862256015, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 87.6503, 'eval_samples_per_second': 5.704, 'eval_steps_per_second': 0.719}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/ydd_Hebr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.88 GiB is free. Including non-PyTorch memory, this process has 36.64 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: ચીન / ટાઇટેન (હિન્દુસ્તાન) ક્વેરી ક્વેરી ક્વેરી પાંચ રાજ
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: اذا سُود - العرب المساجد اذا سُود, اذا سُود https://www.عربمساجد
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: અમને ટ્રમ્પ ફટકારશે : અમને ટ્રમ્પ ફટકારશે તમિલનાડુ પ્રીમિયમ એક્
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720103943/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720103943
{'eval_loss': 8.040231704711914, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.24625659386193435, 'eval_token_set_recall': 0.3033542415101244, 'eval_token_set_f1': 0.2696933759506769, 'eval_token_set_f1_sem': 0.003811803975578667, 'eval_n_ngrams_match_1': 3.524, 'eval_n_ngrams_match_2': 1.226, 'eval_n_ngrams_match_3': 0.114, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 13.434, 'eval_bleu_score': 6.853450852965476, 'eval_bleu_score_sem': 0.13196247085817245, 'eval_rouge_score': 0.6923595907916127, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9069885015487671, 'eval_emb_cos_sim_sem': 0.015256686325986906, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 2579.5549, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/ydd_Hebr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 8.00 GiB is free. Including non-PyTorch memory, this process has 36.52 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.12 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating heb_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: لقد وضعت حديث حول بحث "لقد وضعت حديث حول بحث منذ فترة فترات
[true] query: במחקר שהתפרסם לאחרונה (ואני מתנצל שלא הגעתי לדון בו עד כה מפאת עניינים אחר



[pred] query:.......... تلویزیون لبنان एक कार्यक्रम جامع
[true] query: תוכנית ריאליטי בישראל היא לא רק תוכנית ריאליטי. היא שיעור באזרחות,



[pred] query: استدعا ، استدعا ، استدعا ، استدعا ، استنباط مورخة 20 يونيو 2004 بموجب
[true] query: בפני בקשה לעיכוב ביצוע פסק הדין אשר ניתן ביום 20.4.11 ואשר במסגרתו חו
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720104046/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720104046
{'eval_loss': 6.789484024047852, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.1690608783287579, 'eval_token_set_recall': 0.24353921786847527, 'eval_token_set_f1': 0.19533590331579678, 'eval_token_set_f1_sem': 0.0026393812941819467, 'eval_n_ngrams_match_1': 2.72, 'eval_n_ngrams_match_2': 1.064, 'eval_n_ngrams_match_3': 0.038, 'eval_num_true_words': 15.944, 'eval_num_pred_words': 15.84, 'eval_bleu_score': 5.2562889544985305, 'eval_bleu_score_sem': 0.05322212021038877, 'eval_rouge_score': 0.786864807552269, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8734830617904663, 'eval_emb_cos_sim_sem': 0.018007633518806233, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 81.1357, 'eval_samples_per_second': 6.163, 'eval_steps_per_second': 0.776}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/heb_Hebr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 8.24 GiB is free. Including non-PyTorch memory, this process has 36.28 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 5.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: لقد وضعت هذا بحث لم يكن مختصر إلا في حالات معاصرة(بعد استنباط إلى
[true] query: במחקר שהתפרסם לאחרונה (ואני מתנצל שלא הגעתי לדון בו עד כה מפאת עניינים אחר



[pred] query: एक कार्यक्रम......... لبنان की जनता दरअसल
[true] query: תוכנית ריאליטי בישראל היא לא רק תוכנית ריאליטי. היא שיעור באזרחות,



[pred] query: عرض اجازت ، عرض اجازت ، عرض اجازت بموجب قرارداد مورخ 20.04.2011
[true] query: בפני בקשה לעיכוב ביצוע פסק הדין אשר ניתן ביום 20.4.11 ואשר במסגרתו חו
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720106680/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720106680
{'eval_loss': 6.789484024047852, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.17037167785774635, 'eval_token_set_recall': 0.2302899506839915, 'eval_token_set_f1': 0.19204416959342122, 'eval_token_set_f1_sem': 0.002729808270688374, 'eval_n_ngrams_match_1': 2.736, 'eval_n_ngrams_match_2': 1.058, 'eval_n_ngrams_match_3': 0.036, 'eval_num_true_words': 15.944, 'eval_num_pred_words': 16.26, 'eval_bleu_score': 5.153818574208076, 'eval_bleu_score_sem': 0.048191297986436996, 'eval_rouge_score': 0.7845929736929736, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.878716766834259, 'eval_emb_cos_sim_sem': 0.015058877995035122, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2591.96, 'eval_samples_per_second': 0.193, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/heb_Hebr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating arb_Arab val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: فستان يزين بُزُود عفاف، يزين بُزُود از الماكيود العروستين
[true] query: فستان زفاف أنيق بقصّة الأميرة من نسيج الميكادو، مُزيّن بالأزهار



[pred] query: رئيس مجلس القرآن الكريم رؤية العثمانية فتح الباب 20 ملتزمة المجلس القرآن
[true] query: رئيس القمة الدينية لمجموعة العشرين الشيخ د.محمد العيسى يطلق منصة R20 



[pred] query: جامعة العلوم الإسلامية يوسع شعبة الدعوة بين السنوات والسمعة والسمعة بين العالم،
[true] query: تسعى كلية العلوم الإسلامية إلى تبوأ مكانة وسمعة مرموقة بين جامعات العالم، 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720106788/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720106788
{'eval_loss': 2.9798052310943604, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.25575294301501744, 'eval_token_set_recall': 0.3299732138260781, 'eval_token_set_f1': 0.28427958975412915, 'eval_token_set_f1_sem': 0.003976040712349641, 'eval_n_ngrams_match_1': 4.042, 'eval_n_ngrams_match_2': 1.274, 'eval_n_ngrams_match_3': 0.118, 'eval_num_true_words': 15.48, 'eval_num_pred_words': 15.01, 'eval_bleu_score': 6.771816914558456, 'eval_bleu_score_sem': 0.1214853718963526, 'eval_rouge_score': 0.8947796444551619, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.931514322757721, 'eval_emb_cos_sim_sem': 0.0148541865568859, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 85.8927, 'eval_samples_per_second': 5.821, 'eval_steps_per_second': 0.733}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/arb_Arab_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: فستان يزين بُزُود عفاف، يزين بُزُود از مكة المكرمة 365
[true] query: فستان زفاف أنيق بقصّة الأميرة من نسيج الميكادو، مُزيّن بالأزهار



[pred] query: رئيس مجلس الدعوة الدينية رؤية محمد بن يحيى قائم الملتزم 20Media20 
[true] query: رئيس القمة الدينية لمجموعة العشرين الشيخ د.محمد العيسى يطلق منصة R20 



[pred] query: جامعة العلوم الإسلامية يوسع شعبة الدعوة والتمثيلية بين العالم بشكل مثير، 
[true] query: تسعى كلية العلوم الإسلامية إلى تبوأ مكانة وسمعة مرموقة بين جامعات العالم، 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720109410/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720109410
{'eval_loss': 2.9798052310943604, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.26442421957986983, 'eval_token_set_recall': 0.33800393332158074, 'eval_token_set_f1': 0.29287072436560707, 'eval_token_set_f1_sem': 0.004501534607125634, 'eval_n_ngrams_match_1': 4.154, 'eval_n_ngrams_match_2': 1.304, 'eval_n_ngrams_match_3': 0.132, 'eval_num_true_words': 15.48, 'eval_num_pred_words': 15.066, 'eval_bleu_score': 6.950306646458825, 'eval_bleu_score_sem': 0.12766501149141624, 'eval_rouge_score': 0.8905244072594074, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9485501050949097, 'eval_emb_cos_sim_sem': 0.009038308686553219, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2579.6081, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/arb_Arab_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating amh_Ethi val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: ਮਈ 20, 2016 ਇਤਿਹਾਸ ਦੀ ਜ਼ਿਲ•ੇ ਡੈਮਰੀ ਅਤੇ ਹਸਪਤਾਲਾਂ Ray
[true] query: ማርች 20, 2016 የራስ ዱሜራ ደሴቶችና የባህር ግዛት የሚያሳን የኤ



[pred] query: ਇਕੱਤਰਤਾ ਦੀ ਸ਼ਕਤੀ - ਯੁਗ਼ਮ ਯੁਗ਼ਮ ਯੁਗ਼ਮ Unite
[true] query: አንድነት አንድነት ውስጥ ጥንካሬ - የህብረት ማህበረሰብ እንክብካቤ



[pred] query: ਯੁਵਰਾਜ 'ਤੇ ਖੇਡਣ ਵਾਲੇ 20 ਖਿਡਾਰੀਆਂ ਦੀ ਭਰਤੀ ਪਿਛਲੇ ਦੁਪਹਿਰ
[true] query: ከቡናማዎቹ ጋር ነገ ወደ ዩጋንዳ የሚያቀኑ 20 ተጫዋቾች ተለይተው
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720109512/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720109512
{'eval_loss': 8.070234298706055, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.28364906162808695, 'eval_token_set_recall': 0.28574751849457763, 'eval_token_set_f1': 0.2826216462907364, 'eval_token_set_f1_sem': 0.0038555063875401322, 'eval_n_ngrams_match_1': 3.41, 'eval_n_ngrams_match_2': 1.328, 'eval_n_ngrams_match_3': 0.138, 'eval_num_true_words': 11.838, 'eval_num_pred_words': 12.714, 'eval_bleu_score': 8.35881272357664, 'eval_bleu_score_sem': 0.17378341856286983, 'eval_rouge_score': 0.64780323997468, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8611843585968018, 'eval_emb_cos_sim_sem': 0.007691501532576044, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 81.0266, 'eval_samples_per_second': 6.171, 'eval_steps_per_second': 0.778}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/amh_Ethi_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: 20 ਮਈ, 2016 ਜ਼ਿਲ੍ਹੇ ਦੀ ਸ਼ਖ਼ਸੀਅਤ ਅਤੇ ਡੇਮਰੇ ਦੀ RayHaber ਮੁੱਖ
[true] query: ማርች 20, 2016 የራስ ዱሜራ ደሴቶችና የባህር ግዛት የሚያሳን የኤ



[pred] query: ਇਕਾਈ ਦੀ ਸ਼ਮੂਲੀਅਤ - Strength of unity ਇਕਾਈ ਦੀ ਸ਼ਮੂਲੀਅਤ 
[true] query: አንድነት አንድነት ውስጥ ጥንካሬ - የህብረት ማህበረሰብ እንክብካቤ



[pred] query: 20 ਖਿਡਾਰੀਆਂ ਨਾਲ ਯੂਨਾਈਟਿਡ 'ਤੇ ਭੱਜਣ ਦੇ ਖ਼ੁਲਾਸੇ Next week we
[true] query: ከቡናማዎቹ ጋር ነገ ወደ ዩጋንዳ የሚያቀኑ 20 ተጫዋቾች ተለይተው
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720112138/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720112138
{'eval_loss': 8.070234298706055, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.28224931724622165, 'eval_token_set_recall': 0.27843162638015617, 'eval_token_set_f1': 0.27816807834802276, 'eval_token_set_f1_sem': 0.003933137937372529, 'eval_n_ngrams_match_1': 3.394, 'eval_n_ngrams_match_2': 1.342, 'eval_n_ngrams_match_3': 0.138, 'eval_num_true_words': 11.838, 'eval_num_pred_words': 12.954, 'eval_bleu_score': 8.180813302993123, 'eval_bleu_score_sem': 0.15662326586718467, 'eval_rouge_score': 0.6097803938837222, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8662992715835571, 'eval_emb_cos_sim_sem': 0.00855252542770567, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2583.4188, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/amh_Ethi_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mlt_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Musculu musculu musculu musculu - Technical Techniques and Effective Techniques मुख्य विषयों
[true] query: Dħul Temi Temi Problemi muskuloskeletali Practical tools and guidance - Musculoskeletal disorders



[pred] query: l- News, l- News, l- News in Hindi a first test of coronavirus epidemic aaj ke
[true] query: test – One News Mindu feġġ l-ewwel każ ta' coronavirus f'pajjiżna, saru aktar



[pred] query: 'Mf l'objectif l'objectif l'objectif l'ignore who is not... |
[true] query: 'L-MFA emmnet lil min ibagħbas il-logħob u mhux lili' - Illum
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720112239/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720112239
{'eval_loss': 5.297746181488037, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.25148400362966933, 'eval_token_set_recall': 0.3333428302433725, 'eval_token_set_f1': 0.28204614906571346, 'eval_token_set_f1_sem': 0.00414788800127486, 'eval_n_ngrams_match_1': 3.59, 'eval_n_ngrams_match_2': 1.232, 'eval_n_ngrams_match_3': 0.11, 'eval_num_true_words': 13.932, 'eval_num_pred_words': 12.678, 'eval_bleu_score': 7.200259682264557, 'eval_bleu_score_sem': 0.14996914972986186, 'eval_rouge_score': 0.1539312509180527, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9035598039627075, 'eval_emb_cos_sim_sem': 0.010079339796039349, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 79.7664, 'eval_samples_per_second': 6.268, 'eval_steps_per_second': 0.79}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/mlt_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Therapeutics and technical guides to problematics Musculu - Diskusle Therapeutics and technical guides
[true] query: Dħul Temi Temi Problemi muskuloskeletali Practical tools and guidance - Musculoskeletal disorders



[pred] query: l- News, l- News, l- News aaj ki first test of Covid aaj ki khatm
[true] query: test – One News Mindu feġġ l-ewwel każ ta' coronavirus f'pajjiżna, saru aktar



[pred] query: 'M'G' appelle l'interdiction de l'immeuble de football... 'M'G'
[true] query: 'L-MFA emmnet lil min ibagħbas il-logħob u mhux lili' - Illum
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720114858/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720114858
{'eval_loss': 5.297746181488037, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2548934015416988, 'eval_token_set_recall': 0.33150833454471257, 'eval_token_set_f1': 0.282544075114585, 'eval_token_set_f1_sem': 0.004019375227806334, 'eval_n_ngrams_match_1': 3.634, 'eval_n_ngrams_match_2': 1.246, 'eval_n_ngrams_match_3': 0.114, 'eval_num_true_words': 13.932, 'eval_num_pred_words': 13.148, 'eval_bleu_score': 7.149504788704531, 'eval_bleu_score_sem': 0.15552111254465317, 'eval_rouge_score': 0.14968158381441654, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9033214449882507, 'eval_emb_cos_sim_sem': 0.011380179884814821, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 2576.57, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/mlt_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating hin_Deva val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: मुसलमान न्यूज़ पोर्टल: ग़लत न करे! ग़लत न करे! ग़लत
[true] query: Blog News: ग़लती न करे मुसलमान!!! ग़लती न करे मुसलमान!!! 



[pred] query: RBSE Class 9 Solutions for Class 9 Mann Name - RBSE Solutions for Class 9 Mann Name RBSE Solutions for Class 9 Mann Name
[true] query: RBSE Solutions for Class 9 Hindi Sparsh Chapter 11 आदमी नामा - Rbse solutions RBSE Solutions for Class 9



[pred] query: नई दिल्ली, प्रधानमंत्री नरेंद्र मोदी का पदभार पूरा होने का समय सिर्फ 14 महीने में हु
[true] query: नई दिल्ली, प्रधानमंत्री नरेंद्र मोदी का कार्यकाल पूरा होने में केवल 14 महीने का वक्त बा
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720114964/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720114964
{'eval_loss': 1.0775116682052612, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6527538048242713, 'eval_token_set_recall': 0.6831686587593169, 'eval_token_set_f1': 0.6661676968627362, 'eval_token_set_f1_sem': 0.007086472979878062, 'eval_n_ngrams_match_1': 11.35, 'eval_n_ngrams_match_2': 6.092, 'eval_n_ngrams_match_3': 3.402, 'eval_num_true_words': 17.206, 'eval_num_pred_words': 17.024, 'eval_bleu_score': 28.003169959641397, 'eval_bleu_score_sem': 0.9120929813761515, 'eval_rouge_score': 0.7887813714005728, 'eval_exact_match': 0.014, 'eval_exact_match_sem': 0.005259593772650755, 'eval_emb_cos_sim': 0.9776111841201782, 'eval_emb_cos_sim_sem': 0.007778634873516254, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 84.5196, 'eval_samples_per_second': 5.916, 'eval_steps_per_second': 0.745}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/hin_Deva_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: NEWS BLOGGER: ग़लत न कही मुसलमान!!! ग़लत न कही मुसलमान!!!
[true] query: Blog News: ग़लती न करे मुसलमान!!! ग़लती न करे मुसलमान!!! 



[pred] query: RBSE Solutions for Class 9 पुरुष नाम Chapter 11 - Hindi Ashish RBSE Solutions for Class 9 पुरुष नाम Chapter
[true] query: RBSE Solutions for Class 9 Hindi Sparsh Chapter 11 आदमी नामा - Rbse solutions RBSE Solutions for Class 9



[pred] query: नई दिल्ली, प्रधानमंत्री नरेंद्र मोदी का कार्यकाल पूरा होने का समय सिर्फ 14 महीने में अ
[true] query: नई दिल्ली, प्रधानमंत्री नरेंद्र मोदी का कार्यकाल पूरा होने में केवल 14 महीने का वक्त बा
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720117607/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720117607
{'eval_loss': 1.0775116682052612, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.7271176594647176, 'eval_token_set_recall': 0.744340388395574, 'eval_token_set_f1': 0.7348125761240968, 'eval_token_set_f1_sem': 0.008166264792209797, 'eval_n_ngrams_match_1': 12.646, 'eval_n_ngrams_match_2': 7.588, 'eval_n_ngrams_match_3': 4.994, 'eval_num_true_words': 17.206, 'eval_num_pred_words': 17.128, 'eval_bleu_score': 38.231685331017474, 'eval_bleu_score_sem': 1.2704486963715462, 'eval_rouge_score': 0.8285820098640007, 'eval_exact_match': 0.08, 'eval_exact_match_sem': 0.012144751540478706, 'eval_emb_cos_sim': 0.9771908521652222, 'eval_emb_cos_sim_sem': 0.0076283741145853285, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2599.7944, 'eval_samples_per_second': 0.192, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/hin_Deva_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating urd_Arab val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: قائد اعظم سے لکھاری تک۔۔۔۔۔نعیم راس راجا صفحہ اول / کالم / ق
[true] query: قائداعظم سے نہرو تک ۔۔ رؤف کلاسرا مرکزی صفحہ/ لکھاری/ ر



[pred] query: سوناکشی سوامی سوشل میڈیا کے منہجے میں مبتلا ہو گئیں نہ صرف اداکارہ خود
[true] query: سوناکشی سنہا سوشل میڈیا میمز کے نشے میں مبتلا ہو گئیں اداکارہ نہ صرف خود



[pred] query: نئی دہلی:مہاراشٹر میں گزشتہ 3 سالوں میں 1534 کسانوں نے اپنے (2021
[true] query: نئی دہلی:مہاراشٹر میں گزشتہ 5 سالوں میں (18-2014)14034 کسانوں نے خود
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720117704/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720117704
{'eval_loss': 0.9828182458877563, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6637477637407233, 'eval_token_set_recall': 0.6937833989573489, 'eval_token_set_f1': 0.6773337034798911, 'eval_token_set_f1_sem': 0.0073205964915057965, 'eval_n_ngrams_match_1': 11.446, 'eval_n_ngrams_match_2': 6.678, 'eval_n_ngrams_match_3': 4.14, 'eval_num_true_words': 17.024, 'eval_num_pred_words': 16.82, 'eval_bleu_score': 33.69931211815115, 'eval_bleu_score_sem': 1.0401187000649812, 'eval_rouge_score': 0.8839301152064318, 'eval_exact_match': 0.018, 'eval_exact_match_sem': 0.005951709476392708, 'eval_emb_cos_sim': 0.9793025255203247, 'eval_emb_cos_sim_sem': 0.002309023162839552, 'eval_emb_top1_equal': 1.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 75.8802, 'eval_samples_per_second': 6.589, 'eval_steps_per_second': 0.83}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/urd_Arab_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: قائداعظم سے نھرا تک۔۔۔۔۔ رؤف کلاسرا صفحہ اول / لکھاری /
[true] query: قائداعظم سے نہرو تک ۔۔ رؤف کلاسرا مرکزی صفحہ/ لکھاری/ ر



[pred] query: سوناکشی سنہا اداکارہ سوشل میڈیا کے مایوسی میں مبتلا ہو گئیں نہ صرف خود 
[true] query: سوناکشی سنہا سوشل میڈیا میمز کے نشے میں مبتلا ہو گئیں اداکارہ نہ صرف خود



[pred] query: نئی دہلی:مہاراشٹر میں گزشتہ 4 سالوں میں 1534 کسانوں نے اپنے خود (
[true] query: نئی دہلی:مہاراشٹر میں گزشتہ 5 سالوں میں (18-2014)14034 کسانوں نے خود
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720120345/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720120345
{'eval_loss': 0.9828182458877563, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.7518982422525798, 'eval_token_set_recall': 0.7670876371885691, 'eval_token_set_f1': 0.7585223585297627, 'eval_token_set_f1_sem': 0.007659702075129082, 'eval_n_ngrams_match_1': 12.924, 'eval_n_ngrams_match_2': 8.398, 'eval_n_ngrams_match_3': 5.86, 'eval_num_true_words': 17.024, 'eval_num_pred_words': 16.95, 'eval_bleu_score': 44.19994686238793, 'eval_bleu_score_sem': 1.2976968168820833, 'eval_rouge_score': 0.9086482137143905, 'eval_exact_match': 0.102, 'eval_exact_match_sem': 0.01354839910234685, 'eval_emb_cos_sim': 0.9787342548370361, 'eval_emb_cos_sim_sem': 0.004508648253468507, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2598.3652, 'eval_samples_per_second': 0.192, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/urd_Arab_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating guj_Gujr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: 'મારા લગ્નમાં વિરોધ કેમ કર્યો?' કન્યા-કન્યાના પતિએ બોલાવી
[true] query: 'અમારા વિરોધીને લગ્નમાં કેમ બોલાવ્યો?' કહી કન્યાના મા-બા



[pred] query: આજથી શરૂ થશે કેજરીવાલનું ગુજરાત પ્રવાસવારી, જાણો આખી યાત્રા | here
[true] query: આજે સાંજથી કેજરીવાલની ગુજરાત યાત્રા શરૂ, જાણો આખો કાર્યક્રમ | Read here



[pred] query: ગુજરાતી ફિલ્મ ડૉન 3માં જોવા મળશે શાહરુખ ખાન | Shahrukh Khan Meets
[true] query: ફરહાનની ડૉન 3માં જોવા મળશે ગુજરાતી શાહરુખ ખાન | Shahrukh Kahn
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720120441/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720120441
{'eval_loss': 0.9045828580856323, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6110658658850617, 'eval_token_set_recall': 0.6309751743354688, 'eval_token_set_f1': 0.6199397686179025, 'eval_token_set_f1_sem': 0.007736438121480635, 'eval_n_ngrams_match_1': 8.144, 'eval_n_ngrams_match_2': 4.258, 'eval_n_ngrams_match_3': 2.264, 'eval_num_true_words': 13.074, 'eval_num_pred_words': 12.876, 'eval_bleu_score': 26.594959766303322, 'eval_bleu_score_sem': 0.9389378343719623, 'eval_rouge_score': 0.9171887869377, 'eval_exact_match': 0.022, 'eval_exact_match_sem': 0.006566447781940087, 'eval_emb_cos_sim': 0.9767072200775146, 'eval_emb_cos_sim_sem': 0.007025618863140874, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 75.1023, 'eval_samples_per_second': 6.658, 'eval_steps_per_second': 0.839}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/guj_Gujr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: 'અમારા લગ્નમાં વિરોધી કેમ બોલાવ્યાં?' : કન્યાના માબાને કહ
[true] query: 'અમારા વિરોધીને લગ્નમાં કેમ બોલાવ્યો?' કહી કન્યાના મા-બા



[pred] query: આજથી સાંજે શરૂ કેજરીવાલની ગુજરાત યાત્રા, જાણો આખો કાર્યક્રમ | Read here
[true] query: આજે સાંજથી કેજરીવાલની ગુજરાત યાત્રા શરૂ, જાણો આખો કાર્યક્રમ | Read here



[pred] query: શાહરુખ ખાનની ગુજરાતી ડૉન ફરહાન 3માં જોવા મળશે | Shahrukh Khann
[true] query: ફરહાનની ડૉન 3માં જોવા મળશે ગુજરાતી શાહરુખ ખાન | Shahrukh Kahn
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720123079/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720123079
{'eval_loss': 0.9045828580856323, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.7056760838576626, 'eval_token_set_recall': 0.7174942863380166, 'eval_token_set_f1': 0.7108773573013514, 'eval_token_set_f1_sem': 0.009055495096620006, 'eval_n_ngrams_match_1': 9.346, 'eval_n_ngrams_match_2': 5.802, 'eval_n_ngrams_match_3': 3.872, 'eval_num_true_words': 13.074, 'eval_num_pred_words': 12.908, 'eval_bleu_score': 39.891406860730655, 'eval_bleu_score_sem': 1.3639668679081396, 'eval_rouge_score': 0.9388444638694641, 'eval_exact_match': 0.118, 'eval_exact_match_sem': 0.014441922942480794, 'eval_emb_cos_sim': 0.976537823677063, 'eval_emb_cos_sim_sem': 0.007534173932529957, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2594.9596, 'eval_samples_per_second': 0.193, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/guj_Gujr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating sin_Sinh val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: ਯਾਦ ਕਰਨ ਵਾਲੇ ਲੋਕ | ਯਾਦ ਕਰਨ ਵਾਲੇ ਲੋਕ ← 16 ਮਾਰਚ ਅਸੀਂ ਕਿਸੇ ਗੁਰ
[true] query: මිනිස්සු | ඇවිද යන මඟ ← ගරු කිරීම ගුරුවරු → 16 අප් රේල් අපිට කෙනෙක් දැක්කාම ආ



[pred] query: सिप्पेलिया चिड़िया... | सूर्य दस्तक सिप्पेलिया चिड़िया... Posted on March 24, 2017
[true] query: සිවුමැලියා සිකුරු ලියා... | Sunday Apple සිවුමැලියා සිකුරු ලියා... March 24, 2017 | 11:00 am 0



[pred] query: ਨੀਂਦ ના ਬੰਦੇ માટે ਆਈ युवती... - Sri Lanka News ਨੀਂਦ ના ਬੰ
[true] query: නිළිකමට මැදි වුණේ පුංචි කෙල්ලක කාලේ... - Sri Lanka News Update නිළිකමට මැ
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720123180/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720123180
{'eval_loss': 8.261672019958496, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.262486755719341, 'eval_token_set_recall': 0.30110199849170494, 'eval_token_set_f1': 0.27842907822274937, 'eval_token_set_f1_sem': 0.00436157034596296, 'eval_n_ngrams_match_1': 3.81, 'eval_n_ngrams_match_2': 1.42, 'eval_n_ngrams_match_3': 0.192, 'eval_num_true_words': 14.694, 'eval_num_pred_words': 13.798, 'eval_bleu_score': 7.765000448819226, 'eval_bleu_score_sem': 0.21703112520793177, 'eval_rouge_score': 0.7291044378580998, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9279758930206299, 'eval_emb_cos_sim_sem': 0.0052961189832292895, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 79.8083, 'eval_samples_per_second': 6.265, 'eval_steps_per_second': 0.789}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/sin_Sinh_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: ਦਰਸ਼ਨ ਕਰਨ ਵਾਲੇ ਲੋਕ | Youth Guru 16 ਮਾਰਚ → ਜਦੋਂ ਅਸੀਂ ਕਿਸੇ ਨੂੰ ਦੇਖ
[true] query: මිනිස්සු | ඇවිද යන මඟ ← ගරු කිරීම ගුරුවරු → 16 අප් රේල් අපිට කෙනෙක් දැක්කාම ආ



[pred] query: चिपौलिया ज्वेलरी... | चिपौलिया ज्वेलरी... Published March 24, 2017 March 24, 2017 by
[true] query: සිවුමැලියා සිකුරු ලියා... | Sunday Apple සිවුමැලියා සිකුරු ලියා... March 24, 2017 | 11:00 am 0



[pred] query: ਅੰਦੋਲਨ ਦੇ ਵੇਲੇ ਹੋਈ ਸੀ ਲੜਕੀ... - Sri Lanka News ਅੰਦੋਲਨ ਦੇ ਵੇਲੇ
[true] query: නිළිකමට මැදි වුණේ පුංචි කෙල්ලක කාලේ... - Sri Lanka News Update නිළිකමට මැ
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720125810/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720125810
{'eval_loss': 8.261672019958496, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.26402259703660635, 'eval_token_set_recall': 0.301548503268318, 'eval_token_set_f1': 0.27960435686197754, 'eval_token_set_f1_sem': 0.004330926014608598, 'eval_n_ngrams_match_1': 3.85, 'eval_n_ngrams_match_2': 1.428, 'eval_n_ngrams_match_3': 0.184, 'eval_num_true_words': 14.694, 'eval_num_pred_words': 13.872, 'eval_bleu_score': 7.745758834328107, 'eval_bleu_score_sem': 0.22279705058872243, 'eval_rouge_score': 0.7226685059831812, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9187787771224976, 'eval_emb_cos_sim_sem': 0.008783265593868148, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2587.4036, 'eval_samples_per_second': 0.193, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/sin_Sinh_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating pan_Guru val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: ਭਿਆਨਕ ਮਹਾਂਮਾਰੀ ਮਗਰੋਂ ਬੰਦ ਹੋ ਰਹੀਆਂ ਕਰੋਨਾ ਦੀਆਂ ਦੁਕਾਨਾਂ ਫੋਟੋਆਂ
[true] query: ਕਰੋਨਾ ਮਹਾਂਮਾਰੀ ਦੇ ਚੱਲਦੇ ਫੋਟੋਗ੍ਰਾਫਰ ਦੀਆਂ ਬੰਦ ਪਈਆਂ ਦੁਕਾਨਾਂ ਖੋ



[pred] query: ਮੋਦੀ ਦੇ ਸੁਪਨਿਆਂ ਦਾ ਯੂ ਪੀ ਬਣਾਉਣ ਲਈ ਸ਼ਾਇਦ ਸ਼ੁਰੂ - Panjabi
[true] query: ਮੋਦੀ ਦੇ ਸੁਪਨਿਆਂ ਦਾ ਯੂ ਪੀ ਬਣਾਉਣ ਲਈ ਕਵਾਇਦ ਆਰੰਭ - Panja



[pred] query: ਸ਼ਹੀਦਾਂ ਦੀ ਤਸਵੀਰ ਅਜਾਇਬ ਘਰ 'ਚ ਸੁੱਟਣ ਦੀ ਮੰਗ : 
[true] query: ਸ਼ਹੀਦਾਂ ਦੀਆਂ ਤਸਵੀਰਾਂ ਅਜਾਇਬ ਘਰ 'ਚ ਲਗਾਉਣ ਦੀ ਮੰਗ :
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720125907/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720125907
{'eval_loss': 0.5671507716178894, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.7632200719301339, 'eval_token_set_recall': 0.778887000254647, 'eval_token_set_f1': 0.7701950834507743, 'eval_token_set_f1_sem': 0.007575489553332593, 'eval_n_ngrams_match_1': 10.062, 'eval_n_ngrams_match_2': 6.504, 'eval_n_ngrams_match_3': 4.516, 'eval_num_true_words': 13.07, 'eval_num_pred_words': 12.964, 'eval_bleu_score': 45.7172086731156, 'eval_bleu_score_sem': 1.3365100885428387, 'eval_rouge_score': 0.9461238816738816, 'eval_exact_match': 0.136, 'eval_exact_match_sem': 0.015345323649758309, 'eval_emb_cos_sim': 0.9914834499359131, 'eval_emb_cos_sim_sem': 0.0018073614080877781, 'eval_emb_top1_equal': 1.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 76.3283, 'eval_samples_per_second': 6.551, 'eval_steps_per_second': 0.825}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/pan_Guru_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: ਕਰੋਨਾ ਮਹਾਂਮਾਰੀ ਦੇ ਚੱਲਦੇ ਬੰਦ ਪਈਆਂ ਫੋਟੋਗ੍ਰਾਫਰ ਦੀਆਂ ਦੁਕਾਨਾਂ ਖੋ
[true] query: ਕਰੋਨਾ ਮਹਾਂਮਾਰੀ ਦੇ ਚੱਲਦੇ ਫੋਟੋਗ੍ਰਾਫਰ ਦੀਆਂ ਬੰਦ ਪਈਆਂ ਦੁਕਾਨਾਂ ਖੋ



[pred] query: ਮੋਦੀ ਦੇ ਸੁਪਨਿਆਂ ਦਾ ਯੂ ਪੀ ਬਣਵਾਉਣ ਲਈ ਕਾਇਦ ਅਰੰਭ - Panja
[true] query: ਮੋਦੀ ਦੇ ਸੁਪਨਿਆਂ ਦਾ ਯੂ ਪੀ ਬਣਾਉਣ ਲਈ ਕਵਾਇਦ ਆਰੰਭ - Panja



[pred] query: ਸ਼ਹੀਦਾਂ ਦੀਆਂ ਤਸਵੀਰਾਂ ਅਜਾਇਬ ਘਰ 'ਚ ਲਗਾਉਣ ਦੀ ਮੰਗ :
[true] query: ਸ਼ਹੀਦਾਂ ਦੀਆਂ ਤਸਵੀਰਾਂ ਅਜਾਇਬ ਘਰ 'ਚ ਲਗਾਉਣ ਦੀ ਮੰਗ :
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720128545/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720128545
{'eval_loss': 0.5671507716178894, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.8482866608881311, 'eval_token_set_recall': 0.8533308389323095, 'eval_token_set_f1': 0.8503781982775437, 'eval_token_set_f1_sem': 0.007548250116991521, 'eval_n_ngrams_match_1': 11.148, 'eval_n_ngrams_match_2': 8.366, 'eval_n_ngrams_match_3': 6.576, 'eval_num_true_words': 13.07, 'eval_num_pred_words': 13.026, 'eval_bleu_score': 62.41275685700025, 'eval_bleu_score_sem': 1.5198628959858123, 'eval_rouge_score': 0.970180124777184, 'eval_exact_match': 0.37, 'eval_exact_match_sem': 0.021613289165165816, 'eval_emb_cos_sim': 0.9975221753120422, 'eval_emb_cos_sim_sem': 0.0008392142181142542, 'eval_emb_top1_equal': 1.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 2595.238, 'eval_samples_per_second': 0.193, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/pan_Guru_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating tur_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: चुनावी त्रासदी... | Tez News ⁄ चुनावी त्रासदी... चुनावी त्रासदी... 15 April
[true] query: tek parti devri TEK PARTİ DEVRİ haberleri haber haberi | Sayfa 7 Tek parti chp zamanında yapılan... 15 Şu



[pred] query: Galatasaray-Fenerbahçe-Dinamo Fenerbahçe-Dinamo Trabzonspor huzurhaber.com has been updated: 2018-10-18 21:45:00
[true] query: Anasayfa Spor Fenerbahçe-Dinamo Zagreb maçının hakemleri açıklandı kaynuka Tarih: 2018-11-27 Saat: 15:07:19 



[pred] query: Çocuk eğitimi Çocuklar Çocuk eğitimi Çocuklar Çocuk eğitimi Çocuklar Çocuk eğitimi Çocuklar 7–14 yıl
[true] query: Alışveriş Annelik Bebek Çocuk Çocuk Kitapları Eğitim Sağlık 7–14 yaş çocuklar için öğretim metodları 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720128642/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720128642
{'eval_loss': 3.7609097957611084, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23523958680563586, 'eval_token_set_recall': 0.34506173077009045, 'eval_token_set_f1': 0.2741898435282828, 'eval_token_set_f1_sem': 0.004205334980746286, 'eval_n_ngrams_match_1': 3.89, 'eval_n_ngrams_match_2': 1.28, 'eval_n_ngrams_match_3': 0.122, 'eval_num_true_words': 16.658, 'eval_num_pred_words': 17.048, 'eval_bleu_score': 5.772654257309931, 'eval_bleu_score_sem': 0.10900017842063221, 'eval_rouge_score': 0.18311109194712616, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8977709412574768, 'eval_emb_cos_sim_sem': 0.013993206784238309, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 75.7035, 'eval_samples_per_second': 6.605, 'eval_steps_per_second': 0.832}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/tur_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: दैनिक ट्रिब्यून » Page 7 » दैनिक ट्रिब्यून... दैनिक ट्रिब्यून... CM
[true] query: tek parti devri TEK PARTİ DEVRİ haberleri haber haberi | Sayfa 7 Tek parti chp zamanında yapılan... 15 Şu



[pred] query: Fenerbahçe-Dinamo penalty announced | Fenerbahçe-Dinamo penalty announced By: admin | Last Updated: 27
[true] query: Anasayfa Spor Fenerbahçe-Dinamo Zagreb maçının hakemleri açıklandı kaynuka Tarih: 2018-11-27 Saat: 15:07:19 



[pred] query: Çocuklar के लिए आहार-व्यवस्था 7-14 Çocuklar के लिए आहार-व्यवस्था 7-14 Çocuk Eğitim Çocuk Eğitim
[true] query: Alışveriş Annelik Bebek Çocuk Çocuk Kitapları Eğitim Sağlık 7–14 yaş çocuklar için öğretim metodları 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720131266/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720131266
{'eval_loss': 3.7609097957611084, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23210250735639115, 'eval_token_set_recall': 0.3133591428093753, 'eval_token_set_f1': 0.26223653973521177, 'eval_token_set_f1_sem': 0.004088384359481784, 'eval_n_ngrams_match_1': 3.846, 'eval_n_ngrams_match_2': 1.266, 'eval_n_ngrams_match_3': 0.112, 'eval_num_true_words': 16.658, 'eval_num_pred_words': 17.114, 'eval_bleu_score': 5.656732482168569, 'eval_bleu_score_sem': 0.11015578977793981, 'eval_rouge_score': 0.18740212206939647, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8793311715126038, 'eval_emb_cos_sim_sem': 0.011806567697398393, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2581.8596, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/tur_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating kaz_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: મુંબઇ મ્યુનિસિપલ કોંગ્રેસનું સંગઠન છે WORKING AND SECURITY ARREDERS
[true] query: ҚМГ АЛТЫН ЕРЕЖЕЛЕРІ - ЕҢбек қауіпсіздігі және еңбекті қОРҒау жиналыстарын



[pred] query: પરીસ્થિતિ પરીસ્થિતિ પરીસ્થિતિ નું નિવેદન 18/05/2018 28/05/2018 by psycology 
[true] query: психометриялық тестілеу кестесі инструкция по приму апелляциялық ведомость 18.10.2018 ж No 578 бұйры



[pred] query: iGulzarin - iGulzarin - iGulzarin - પુસ્તકો મહાકાળી એ
[true] query: Ыбырай Алтынсарин - Ы - Ұлы заман Тұлғалары - Скачать Рефераты,
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720131364/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720131364
{'eval_loss': 6.258415222167969, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23399156411184274, 'eval_token_set_recall': 0.2785292825595458, 'eval_token_set_f1': 0.25104503132497624, 'eval_token_set_f1_sem': 0.003547652190165411, 'eval_n_ngrams_match_1': 3.6, 'eval_n_ngrams_match_2': 1.152, 'eval_n_ngrams_match_3': 0.052, 'eval_num_true_words': 15.352, 'eval_num_pred_words': 14.724, 'eval_bleu_score': 5.991427977128081, 'eval_bleu_score_sem': 0.08735118273804687, 'eval_rouge_score': 0.5185800697837686, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8822821378707886, 'eval_emb_cos_sim_sem': 0.010946366324359238, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 76.2808, 'eval_samples_per_second': 6.555, 'eval_steps_per_second': 0.826}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/kaz_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: મ્યુનિસિપલ કોંગ્રેસનું મુખ્યમંત્રી છે - AHMED SARKARI WORK AND SECURITY
[true] query: ҚМГ АЛТЫН ЕРЕЖЕЛЕРІ - ЕҢбек қауіпсіздігі және еңбекті қОРҒау жиналыстарын



[pred] query: પ્રેસિડેન્ટ નું પરીક્ષા યોજનાનું નિવેદન 28/05/2018 18/05/2018 psyllium anxiety disorder is
[true] query: психометриялық тестілеу кестесі инструкция по приму апелляциялық ведомость 18.10.2018 ж No 578 бұйры



[pred] query: Ismail ul-Qayrain - સુરેશ યાદવ એ મહાકાળના રચકો છે,
[true] query: Ыбырай Алтынсарин - Ы - Ұлы заман Тұлғалары - Скачать Рефераты,
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720133990/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720133990
{'eval_loss': 6.258415222167969, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23784239551298386, 'eval_token_set_recall': 0.2764669167176134, 'eval_token_set_f1': 0.25289630912378275, 'eval_token_set_f1_sem': 0.0036051433247420513, 'eval_n_ngrams_match_1': 3.626, 'eval_n_ngrams_match_2': 1.18, 'eval_n_ngrams_match_3': 0.08, 'eval_num_true_words': 15.352, 'eval_num_pred_words': 14.956, 'eval_bleu_score': 6.123347569378963, 'eval_bleu_score_sem': 0.13240192599709985, 'eval_rouge_score': 0.5058119263947449, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8977941274642944, 'eval_emb_cos_sim_sem': 0.01227687779448638, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2583.6817, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/kaz_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating cmn_Hani val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: मुख्यपृष्ठchina价格库存紧张,房地产库存紧张,房地产库存紧张,房地产库存紧张 शीघ्र किया 
[true] query: 下行以及现货成交偏弱拖累,市场主导地区价格继续快速调低,邯郸中板价格重



[pred] query: ब्यूटीकॉम्पैक्ट 不锈钢包装袋的设计具有良好的防护功能的显著优势,该包装袋的整体温度是100%
[true] query: 每日彩票 珍珠棉的包装定位是一种具有高强的缓冲吸震抗震作用的有明显环保效力的包装



[pred] query: फेसबुक发布了区块链虚拟货币,区块链虚拟货币,区块链虚拟货币,区块链虚拟货币的使用कर्ताओं में स्थापित है।
[true] query: 火币云于上个月刚刚推出,允许用户开发他们自己的类似火币网的数字货币交易平台,其中包括钱
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720134089/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720134089
{'eval_loss': 4.697510242462158, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.9140625, 'eval_token_set_precision': 0.4465654062311956, 'eval_token_set_recall': 0.352616465397348, 'eval_token_set_f1': 0.3785882657747718, 'eval_token_set_f1_sem': 0.004378848082036521, 'eval_n_ngrams_match_1': 3.488, 'eval_n_ngrams_match_2': 1.018, 'eval_n_ngrams_match_3': 0.014, 'eval_num_true_words': 7.802, 'eval_num_pred_words': 12.65, 'eval_bleu_score': 7.969114495934624, 'eval_bleu_score_sem': 0.19266052234399364, 'eval_rouge_score': 0.6624468416419284, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8700659275054932, 'eval_emb_cos_sim_sem': 0.01637239243141123, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 77.0823, 'eval_samples_per_second': 6.487, 'eval_steps_per_second': 0.817}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/cmn_Hani_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: मुख्यपृष्ठchina|बिक्री मूल्य दर तेजी से बढ़ा,पूर्व और घरेलू कारोबारियों
[true] query: 下行以及现货成交偏弱拖累,市场主导地区价格继续快速调低,邯郸中板价格重



[pred] query:,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[true] query: 每日彩票 珍珠棉的包装定位是一种具有高强的缓冲吸震抗震作用的有明显环保效力的包装



[pred] query: यूएन ने अपने स्मार्टफोन में Bitcoin cryptocurrency cryptocurrency कार्यालय स्थापित किया है।शुक्रवार,2019
[true] query: 火币云于上个月刚刚推出,允许用户开发他们自己的类似火币网的数字货币交易平台,其中包括钱
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720136710/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720136710
{'eval_loss': 4.697510242462158, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.9140625, 'eval_token_set_precision': 0.41942403064771516, 'eval_token_set_recall': 0.26137702027037785, 'eval_token_set_f1': 0.304807464949472, 'eval_token_set_f1_sem': 0.004204881338415499, 'eval_n_ngrams_match_1': 3.04, 'eval_n_ngrams_match_2': 1.022, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 7.802, 'eval_num_pred_words': 15.732, 'eval_bleu_score': 5.980273367160468, 'eval_bleu_score_sem': 0.1449044176548889, 'eval_rouge_score': 0.5985220297676178, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7770124673843384, 'eval_emb_cos_sim_sem': 0.01127646044189656, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 2578.585, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/cmn_Hani_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating jpn_Jpan val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query:......पहली रात बाद शाम शाम गर्मी से बाहर निकलने लगे हैं......पहली रात
[true] query: 花立山荘では夜半から雨が降り続いていて、朝にちょっとだけ雨脚が弱くなったときに出発。 しばらく



[pred] query: ❄️❄️❄️❄️❄️❄️❄️❄️ पहले किया गया पहले जलवायु
[true] query: 今シーズン初の凍結した桧原湖の湖上撮影です。 かなり結氷は進んでいましたが、まだワカサギ



[pred] query: हमारे बीच的不मानता, हमारे बीच的不मानता, हमारे बीच的不मानता...YouTube
[true] query: まず少なくともこの人たちチームにネット周りが強い人間がいることは間違いなくて、YouTubeのメタタグ(メタタグって?って人はこの記事
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720136807/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720136807
{'eval_loss': 7.370152473449707, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.5508588557641179, 'eval_token_set_recall': 0.19554021176621877, 'eval_token_set_f1': 0.2694385085204596, 'eval_token_set_f1_sem': 0.003722158382111044, 'eval_n_ngrams_match_1': 2.352, 'eval_n_ngrams_match_2': 1.016, 'eval_n_ngrams_match_3': 0.004, 'eval_num_true_words': 4.93, 'eval_num_pred_words': 15.598, 'eval_bleu_score': 5.251084863996565, 'eval_bleu_score_sem': 0.09538846571670694, 'eval_rouge_score': 0.5636628056772958, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8521934747695923, 'eval_emb_cos_sim_sem': 0.015339768301114007, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 75.7796, 'eval_samples_per_second': 6.598, 'eval_steps_per_second': 0.831}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/jpn_Jpan_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query:......पहली रात ही गर्मी से बाहर निकलने लगे हैं,पहली रात ही rainfall
[true] query: 花立山荘では夜半から雨が降り続いていて、朝にちょっとだけ雨脚が弱くなったときに出発。 しばらく



[pred] query: ❄️❄️❄️❄️❄️❄️हिमालय की पहली शूटिंग पूरी तरह से हुई
[true] query: 今シーズン初の凍結した桧原湖の湖上撮影です。 かなり結氷は進んでいましたが、まだワカサギ



[pred] query: हमारे टीम की सच्चाई...YouTube की सच्चाई...YouTube की सच्चाई से पहले कोई व्यक्ति नहीं
[true] query: まず少なくともこの人たちチームにネット周りが強い人間がいることは間違いなくて、YouTubeのメタタグ(メタタグって?って人はこの記事
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720139433/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720139433
{'eval_loss': 7.370152473449707, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.5470338842444096, 'eval_token_set_recall': 0.17755089392293677, 'eval_token_set_f1': 0.2504365281290802, 'eval_token_set_f1_sem': 0.003355454255123845, 'eval_n_ngrams_match_1': 2.316, 'eval_n_ngrams_match_2': 1.01, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 4.93, 'eval_num_pred_words': 16.536, 'eval_bleu_score': 4.87151714539854, 'eval_bleu_score_sem': 0.09488152997441031, 'eval_rouge_score': 0.5397627193240201, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8341184854507446, 'eval_emb_cos_sim_sem': 0.010817602433802392, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 2584.2909, 'eval_samples_per_second': 0.193, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/jpn_Jpan_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating kor_Hang val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: प्राकृतिक स्वास्थ्य – Page 2 – Prepaid.in https://prepaid.in https://prepaid.in https://pre
[true] query: 세일 중 – Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price



[pred] query: हितनिर्धारित खोज और हितनिर्धारित खोज का मुद्दा | WWW.MYTECHNEWS.COM Home
[true] query: 신용위험 결정요인 과 관련 - 토토사이트 검증사이트 메이저토토사이트 - 토토탐정 - 신



[pred] query: स्मार्टफोन लॉन्च - Samsung Galaxy T20 - Samsung Galaxy T20 - अंग्रेजी Android -
[true] query: 안드로이드 : 삼성바다폰 영국 온라인 등록 - 타이젠 - 안드로이드 스마트폰과 태블릿 새
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720139530/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720139530
{'eval_loss': 7.193070411682129, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22125344616683668, 'eval_token_set_recall': 0.25294362795786973, 'eval_token_set_f1': 0.23084935958716643, 'eval_token_set_f1_sem': 0.00378758031303394, 'eval_n_ngrams_match_1': 3.152, 'eval_n_ngrams_match_2': 1.1, 'eval_n_ngrams_match_3': 0.052, 'eval_num_true_words': 14.33, 'eval_num_pred_words': 15.468, 'eval_bleu_score': 5.746335608490901, 'eval_bleu_score_sem': 0.10958431567104261, 'eval_rouge_score': 0.5181827521984251, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9200029373168945, 'eval_emb_cos_sim_sem': 0.010164909752317607, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 75.6845, 'eval_samples_per_second': 6.606, 'eval_steps_per_second': 0.832}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/kor_Hang_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: प्राकृतिक सप्ताह – Sehat.com <% if ( total_view > 0 ) {display=none;background
[true] query: 세일 중 – Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price



[pred] query: हितोपयोगी घोषणा की विषय | MYTECHNEWS हितोपयोगी घोषणा की विषय | MYTECHNEWS
[true] query: 신용위험 결정요인 과 관련 - 토토사이트 검증사이트 메이저토토사이트 - 토토탐정 - 신



[pred] query: Samsung Galaxy - लॉन्च - Tinystep भारतीय स्मार्टफोन Samsung Galaxy - लॉन्च Taiwan
[true] query: 안드로이드 : 삼성바다폰 영국 온라인 등록 - 타이젠 - 안드로이드 스마트폰과 태블릿 새
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720142151/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720142151
{'eval_loss': 7.193070411682129, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2176210131200074, 'eval_token_set_recall': 0.25008025350122914, 'eval_token_set_f1': 0.2268770345197349, 'eval_token_set_f1_sem': 0.0036552302203485374, 'eval_n_ngrams_match_1': 3.102, 'eval_n_ngrams_match_2': 1.096, 'eval_n_ngrams_match_3': 0.056, 'eval_num_true_words': 14.33, 'eval_num_pred_words': 15.808, 'eval_bleu_score': 5.691670964955376, 'eval_bleu_score_sem': 0.11259288564805334, 'eval_rouge_score': 0.49457510205603183, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9028826355934143, 'eval_emb_cos_sim_sem': 0.015451523304118675, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2578.3146, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/kor_Hang_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mon_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: ભારતના અર્થતંત્રમાં ડબલ ડોલરની આવક વધશે. 55.55 લાખ જેટલા થ
[true] query: Алтны олборлолт амжилтад хүрнэ ОХУын гадаад өр 56 тэрбум ам.доллар болж өсчээ



[pred] query: Google ની ક્રમાંક પર ફેરફારો નું ધ્યાન રાખો | 3 ફેરફારો Google ની ક્રમાંક
[true] query: Google Текстийн зарын өөрчлөлтийг анхаарч үзэх 3 зүйл | Martech Zone Google Текстийн зарын



[pred] query: ▷ SEX ▷ SEX ▷ SEX ▷ SEX ▷ SEX ▷ SEX ▷ SEX ▷ (105956) 
[true] query: » СЕКС (1085550) » ШАР МЭДЭЭ (805751) » ӨГҮҮЛЛЭГ (906359) хөлийг 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720142248/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720142248
{'eval_loss': 8.219273567199707, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22357811470435365, 'eval_token_set_recall': 0.2600311448355572, 'eval_token_set_f1': 0.23821599674352195, 'eval_token_set_f1_sem': 0.0032001245942732074, 'eval_n_ngrams_match_1': 3.178, 'eval_n_ngrams_match_2': 1.14, 'eval_n_ngrams_match_3': 0.078, 'eval_num_true_words': 14.004, 'eval_num_pred_words': 12.974, 'eval_bleu_score': 6.912024708069075, 'eval_bleu_score_sem': 0.13942225718920415, 'eval_rouge_score': 0.5359546820253982, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.920418918132782, 'eval_emb_cos_sim_sem': 0.007304995175395906, 'eval_emb_top1_equal': 0.875, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 75.2052, 'eval_samples_per_second': 6.648, 'eval_steps_per_second': 0.838}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/mon_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: અર્થતંત્રની અડફેટે ભારતની આવક ઝડપાશે. BOLએ 56 હજાર કરોડ બન
[true] query: Алтны олборлолт амжилтад хүрнэ ОХУын гадаад өр 56 тэрбум ам.доллар болж өсчээ



[pred] query: Google ની ઝલક પર 3 ફેરફારોનું ધ્યાન રાખવું | Play Store Google ની ઝલક પર 3 ફેરફાર
[true] query: Google Текстийн зарын өөрчлөлтийг анхаарч үзэх 3 зүйл | Martech Zone Google Текстийн зарын



[pred] query: ▷ SEX ▷ SEX ▷ SEX ▷ SEX ▷ SEX ▷ (105853) મોઢાની અફડાતમી
[true] query: » СЕКС (1085550) » ШАР МЭДЭЭ (805751) » ӨГҮҮЛЛЭГ (906359) хөлийг 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720144869/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720144869
{'eval_loss': 8.219273567199707, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22618379390647234, 'eval_token_set_recall': 0.2572728261934147, 'eval_token_set_f1': 0.23855035789519605, 'eval_token_set_f1_sem': 0.003269445023597282, 'eval_n_ngrams_match_1': 3.184, 'eval_n_ngrams_match_2': 1.13, 'eval_n_ngrams_match_3': 0.078, 'eval_num_true_words': 14.004, 'eval_num_pred_words': 13.22, 'eval_bleu_score': 6.980456990701809, 'eval_bleu_score_sem': 0.1486608883693328, 'eval_rouge_score': 0.5240133923873935, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9085665345191956, 'eval_emb_cos_sim_sem': 0.012389882714967198, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2578.9788, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/mon_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating hun_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Ultrasonic übungen.telefonisch.telefonisch.telefonisch.telefonisch.telefonisch.telefonisch.telefonisch 痛み
[true] query: Ultrahang kezelés: Fájdalomcsillapítás tűszűrás nélkül [teljes útmutató] Ízületi fájdalom fono



[pred] query: El Segundo Trampolin, El Segundo Trampolin, El Segundo Trampolin, El Segundo Trampolin,
[true] query: Az új Mike Tyson | SamanSport.hu 2019. 12. 13., Péntek, 18:40 Gervonta "Tank" Davis hatalmas



[pred] query: The Trolley – The Trolley मुख्यपृष्ठTrolley – The Trolley – The Trolley सबसे अद्भुत
[true] query: Járművek | Hobbi Zóna - Part 2 TankChair – az Off Road tolószék A rendkívüli gépezet
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720144967/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720144967
{'eval_loss': 5.570969581604004, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.1929206446460321, 'eval_token_set_recall': 0.4218354617604626, 'eval_token_set_f1': 0.2574407195097101, 'eval_token_set_f1_sem': 0.0035455820243037173, 'eval_n_ngrams_match_1': 3.108, 'eval_n_ngrams_match_2': 1.106, 'eval_n_ngrams_match_3': 0.048, 'eval_num_true_words': 16.376, 'eval_num_pred_words': 14.004, 'eval_bleu_score': 4.8945017587222726, 'eval_bleu_score_sem': 0.09262783974819583, 'eval_rouge_score': 0.10019641834365857, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8826460838317871, 'eval_emb_cos_sim_sem': 0.008731904390601558, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 76.1564, 'eval_samples_per_second': 6.565, 'eval_steps_per_second': 0.827}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/hun_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Ultrasonic relief (Ultrasonic relief) Ultrasonic relief (Ultrasonic relief) Ultrasonic relief:痛みના समा
[true] query: Ultrahang kezelés: Fájdalomcsillapítás tűszűrás nélkül [teljes útmutató] Ízületi fájdalom fono



[pred] query: El Segundo Trampolin, El Segundo Trampolin, El Segundo Trampolin, El Segundo Trampolin 2020
[true] query: Az új Mike Tyson | SamanSport.hu 2019. 12. 13., Péntek, 18:40 Gervonta "Tank" Davis hatalmas



[pred] query: मुख्यपृष्ठTrampoline – The Outstanding Motorcycle Equipment Trampoline – The Outstanding Motorcycle Equipment Trampoline
[true] query: Járművek | Hobbi Zóna - Part 2 TankChair – az Off Road tolószék A rendkívüli gépezet
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720147590/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720147590
{'eval_loss': 5.570969581604004, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.1909126880257691, 'eval_token_set_recall': 0.3958759962259968, 'eval_token_set_f1': 0.2505499272656595, 'eval_token_set_f1_sem': 0.0034106400090250745, 'eval_n_ngrams_match_1': 3.048, 'eval_n_ngrams_match_2': 1.088, 'eval_n_ngrams_match_3': 0.042, 'eval_num_true_words': 16.376, 'eval_num_pred_words': 14.174, 'eval_bleu_score': 4.8927588095732215, 'eval_bleu_score_sem': 0.08603484211458821, 'eval_rouge_score': 0.0983727143185327, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8786323070526123, 'eval_emb_cos_sim_sem': 0.008867915563468753, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2580.1065, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/hun_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mhr_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: عشق كى طرف عشق كى طرف عشق كى طرف, muzaffar qalay dayta tik tok
[true] query: Тургым жапыште, шошо ага годым, кеч ик гана Кугу Качак ялыште лияш



[pred] query: માં? માં??????? Ajmer aajder old Age
[true] query: Мо тыгай Агавайрем? Кузе тудо эрта? Тиде да моло йодышлан вашмутым Марий в



[pred] query: Главная страница » Nevsky Prospekt » Костёр вороновская костёр вороновская костёр, где-где-
[true] query: Коряк рвезе Пётр Нестеров дене мый Наро-Фоминск олаште эртыше «По
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720147688/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720147688
{'eval_loss': 6.528791427612305, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.21770036662683753, 'eval_token_set_recall': 0.3125443319752149, 'eval_token_set_f1': 0.2509200479287846, 'eval_token_set_f1_sem': 0.0034750115207244177, 'eval_n_ngrams_match_1': 3.082, 'eval_n_ngrams_match_2': 1.132, 'eval_n_ngrams_match_3': 0.09, 'eval_num_true_words': 13.858, 'eval_num_pred_words': 12.814, 'eval_bleu_score': 6.496333746118006, 'eval_bleu_score_sem': 0.0903523493151716, 'eval_rouge_score': 0.5337259822614668, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8695147633552551, 'eval_emb_cos_sim_sem': 0.008249481025833737, 'eval_emb_top1_equal': 0.875, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 77.0367, 'eval_samples_per_second': 6.49, 'eval_steps_per_second': 0.818}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/mhr_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: میرے لئے عشق میرے لئے عشق میرے لئے جوڑا ٹوٹتا تھا سات روز
[true] query: Тургым жапыште, шошо ага годым, кеч ик гана Кугу Качак ялыште лияш



[pred] query:??????????? Ajurveda gime mature
[true] query: Мо тыгай Агавайрем? Кузе тудо эрта? Тиде да моло йодышлан вашмутым Марий в



[pred] query: Главная страница » Костёр-это-это-это-это-это-это-это-это-это Костёр едет 
[true] query: Коряк рвезе Пётр Нестеров дене мый Наро-Фоминск олаште эртыше «По
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720150294/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720150294
{'eval_loss': 6.528791427612305, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.21482334250716648, 'eval_token_set_recall': 0.3052707465736884, 'eval_token_set_f1': 0.24541318955531843, 'eval_token_set_f1_sem': 0.0035151330758636085, 'eval_n_ngrams_match_1': 3.052, 'eval_n_ngrams_match_2': 1.152, 'eval_n_ngrams_match_3': 0.09, 'eval_num_true_words': 13.858, 'eval_num_pred_words': 12.976, 'eval_bleu_score': 6.393675641207124, 'eval_bleu_score_sem': 0.09850259725732442, 'eval_rouge_score': 0.5351927361960487, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8651713728904724, 'eval_emb_cos_sim_sem': 0.008555713441668814, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2563.3483, 'eval_samples_per_second': 0.195, 'eval_steps_per_second': 0.025}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/mhr_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating fin_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja
[true] query: Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. Työympäristö muutos hankkeissa tuotetaan myö



[pred] query: minä-minä työtä-minä työtä-minä työtä-minä työtä-minä työtä Pohjois Pohjolans કાર્ય体系
[true] query: Pohjois-suomalaisuus ja kaikille arvokas elämä - siinä tavoitteet toiminnalle. Työskentelen Diakonia-



[pred] query: Capsules, medicinal गुणों की तुलना में, hemos suger્યું, "Jupiteriaceae ja prunus
[true] query: Kun kirjoitimme koivunjalojen lääketieteellisistä ominaisuuksista, mainitsimme, että paitsi munuaiset, myös ko
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720150391/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720150391
{'eval_loss': 5.451145648956299, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19118539626008704, 'eval_token_set_recall': 0.30627273484169815, 'eval_token_set_f1': 0.2278938834126434, 'eval_token_set_f1_sem': 0.0030875603526001856, 'eval_n_ngrams_match_1': 3.08, 'eval_n_ngrams_match_2': 1.058, 'eval_n_ngrams_match_3': 0.034, 'eval_num_true_words': 15.462, 'eval_num_pred_words': 15.61, 'eval_bleu_score': 5.231966565803911, 'eval_bleu_score_sem': 0.06492641590322476, 'eval_rouge_score': 0.11527651967368505, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8680098056793213, 'eval_emb_cos_sim_sem': 0.011014189823236377, 'eval_emb_top1_equal': 1.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 76.0529, 'eval_samples_per_second': 6.574, 'eval_steps_per_second': 0.828}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/fin_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja asiakaskokemuksen ja
[true] query: Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. Työympäristö muutos hankkeissa tuotetaan myö



[pred] query: työssä-વ્યવસ્થા: Pohjolan Pohjolan Pohjolan Pohjolan työtä-વ્યવસ્થા: મારું હેતુ છે કે
[true] query: Pohjois-suomalaisuus ja kaikille arvokas elämä - siinä tavoitteet toiminnalle. Työskentelen Diakonia-



[pred] query: Capsules में, हमने विशेषज्ञता को केंद्रित किया, "Jupiteriinas ja nemozola"
[true] query: Kun kirjoitimme koivunjalojen lääketieteellisistä ominaisuuksista, mainitsimme, että paitsi munuaiset, myös ko
outptufile for decoded sequences:  saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720153006/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_indo-aryan-fami_32_2layers_corrector/decoded_eval_1720153006
{'eval_loss': 5.451145648956299, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19266549577014008, 'eval_token_set_recall': 0.28124875916996706, 'eval_token_set_f1': 0.2221880338672327, 'eval_token_set_f1_sem': 0.0033516490340773832, 'eval_n_ngrams_match_1': 3.098, 'eval_n_ngrams_match_2': 1.068, 'eval_n_ngrams_match_3': 0.032, 'eval_num_true_words': 15.462, 'eval_num_pred_words': 15.668, 'eval_bleu_score': 5.265853669140269, 'eval_bleu_score_sem': 0.06914500421801968, 'eval_rouge_score': 0.12342062462466098, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8647760152816772, 'eval_emb_cos_sim_sem': 0.008185878797252768, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2572.3624, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_ind_fami_32_2layers_prefix/evaluations/fin_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.76 GiB is free. Including non-PyTorch memory, this process has 36.76 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.36 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
