working directory /home/cs.aau.dk/ng78zb/vec2text_exp
sif /home/cs.aau.dk/ng78zb/pytorch_23.10-py3.sif
launch evaluation yiyic/mt5_text2vec_cmn_Hani_32_corrector
loading experiment and trainer from yiyic/mt5_text2vec_cmn_Hani_32_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector
on rank 0, output dir: saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_text2vec_cmn_Hani_32_inverter
on rank 0, output dir: saves/yiyic__mt5_text2vec_cmn_Hani_32_inverter
adding embedding type to dataset args.
Loading datasets with TOKENIZERS_PARALLELISM = False
loading train dataset from path: /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/65fb8fcebe7a0f66858ded628b2b1772.arrow
loaded dict of val datasets from /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/2553516a067841b2a72172c033b2bd2e.arrow
07/16/2024 15:17:00 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
07/16/2024 15:17:52 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
data arguments for experiment: DataArguments(dataset_name='mt-ms_cmn_Hani', max_eval_samples=500, use_less_data=3000)
model yiyic/mt5_text2vec_cmn_Hani_32_corrector parameters 730467840
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
The OrderedVocab you are attempting to save contains holes for indices [12084], your vocabulary could be corrupted !
Using Frozen Embeddings as Input -- Val datasets
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '9ef125e9a19702af72119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'f428b0a441eae5bd72119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '03a157c0d2d6d80172119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '9505c5d421dc46c272119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '4876625ae14a1f6272119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '9b82e65528049f7972119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'afd26cefd43c570672119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '137e6baf5cc4815972119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '467e46deba8c695d72119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd75548cf5d0009e672119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'ddec60263975fed372119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '616bf5cbcc9d7a4972119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '41e819c405b19c8672119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '076b91b7e799a6b172119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7b90ceba8a05b5ab72119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'e0f2c6b1fdb531fa72119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'aab3a71086ad568c72119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'e6ddeceecbbff94c72119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '9db65608036481a572119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '0078e527b188419472119d25588d72bb6d31efedf1b0b153', 'num_proc': 1}
output dir ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations
evaluating deu_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/deu_Latn_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/deu_Latn_steps-50_sbeam-8.json already exists
evaluating ydd_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/ydd_Hebr_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/ydd_Hebr_steps-50_sbeam-8.json already exists
evaluating heb_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/heb_Hebr_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/heb_Hebr_steps-50_sbeam-8.json already exists
evaluating arb_Arab val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/arb_Arab_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/arb_Arab_steps-50_sbeam-8.json already exists
evaluating amh_Ethi val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/amh_Ethi_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/amh_Ethi_steps-50_sbeam-8.json already exists
evaluating mlt_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/mlt_Latn_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/mlt_Latn_steps-50_sbeam-8.json already exists
evaluating hin_Deva val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/hin_Deva_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/hin_Deva_steps-50_sbeam-8.json already exists
evaluating urd_Arab val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/urd_Arab_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/urd_Arab_steps-50_sbeam-8.json already exists
evaluating guj_Gujr val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/guj_Gujr_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/guj_Gujr_steps-50_sbeam-8.json already exists
evaluating sin_Sinh val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/sin_Sinh_steps-1.json already exists
evaluating corrector with beam width 8
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/sin_Sinh_steps-50_sbeam-8.json already exists
evaluating pan_Guru val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/pan_Guru_steps-1.json already exists
evaluating corrector with beam width 8
[pred] ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“
[true] à¨•à¨°à©‹à¨¨à¨¾ à¨®à¨¹à¨¾à¨‚à¨®à¨¾à¨°à©€ à¨¦à©‡ à¨šà©±à¨²à¨¦à©‡ à¨«à©‹à¨Ÿà©‹à¨—à©à¨°à¨¾à¨«à¨° à¨¦à©€à¨†à¨‚ à¨¬à©°à¨¦ à¨ªà¨ˆà¨†à¨‚ à¨¦à©à¨•à¨¾à¨¨à¨¾à¨‚ à¨–à©‹à¨²à©à¨¹à¨£ 



[pred] é€™å¼µå½±ç‰‡æ˜¯ã€ŠDaDaDaDaDaDaDaDaDaDaDaDaD
[true] à¨®à©‹à¨¦à©€ à¨¦à©‡ à¨¸à©à¨ªà¨¨à¨¿à¨†à¨‚ à¨¦à¨¾ à¨¯à©‚ à¨ªà©€ à¨¬à¨£à¨¾à¨‰à¨£ à¨²à¨ˆ à¨•à¨µà¨¾à¨‡à¨¦ à¨†à¨°à©°à¨­ - PanjabiLok.



[pred] ã€ŠThe Chaos of the Chaos of the Chaos of the Chaos of the Chaos of the Chaos of the Chaos of the
[true] à¨¸à¨¼à¨¹à©€à¨¦à¨¾à¨‚ à¨¦à©€à¨†à¨‚ à¨¤à¨¸à¨µà©€à¨°à¨¾à¨‚ à¨…à¨œà¨¾à¨‡à¨¬ à¨˜à¨° 'à¨š à¨²à¨—à¨¾à¨‰à¨£ à¨¦à©€ à¨®à©°à¨— : The Tribune
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721152709/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721152709
{'eval_loss': 9.849048614501953, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.008560269142622083, 'eval_token_set_recall': 0.061669047619047616, 'eval_token_set_f1': 0.014307197589207291, 'eval_token_set_f1_sem': 0.0021213782067203988, 'eval_n_ngrams_match_1': 0.102, 'eval_n_ngrams_match_2': 0.002, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 12.258, 'eval_num_pred_words': 8.912, 'eval_bleu_score': 0.2896214451457489, 'eval_bleu_score_sem': 0.04016340799536532, 'eval_rouge_score': 0.01117868187715576, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7553125023841858, 'eval_emb_cos_sim_sem': 0.0010738968432918335, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16742.0344, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/pan_Guru_steps-50_sbeam-8.json
evaluating tur_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] Jacques de la Salle de la Salle de la Salle de la Salle de la Salle de la Salle de la Salle de
[true] tek parti devri TEK PARTÄ° DEVRÄ° haberleri haber haberi | Sayfa 7 Tek parti chp zamanÄ±nda yapÄ±lan... 15 Åubat 2015, 



[pred] Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone Vodafone 
[true] Anasayfa Spor FenerbahÃ§e-Dinamo Zagreb maÃ§Ä±nÄ±n hakemleri aÃ§Ä±klandÄ± kaynuka Tarih: 2018-11-27 Saat: 15:07:19 GÃ¼ncelleme 



[pred] ioioioioioioioioioioioioioioio
[true] AlÄ±ÅŸveriÅŸ Annelik Bebek Ã‡ocuk Ã‡ocuk KitaplarÄ± EÄŸitim SaÄŸlÄ±k 7â€“14 yaÅŸ Ã§ocuklar iÃ§in Ã¶ÄŸretim metodlarÄ± aktif dinleme
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721152930/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721152930
{'eval_loss': 7.276118278503418, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.01343756010071798, 'eval_token_set_recall': 0.043641558441558446, 'eval_token_set_f1': 0.017399924784006402, 'eval_token_set_f1_sem': 0.0017811631734561222, 'eval_n_ngrams_match_1': 0.264, 'eval_n_ngrams_match_2': 0.004, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 16.296, 'eval_num_pred_words': 16.042, 'eval_bleu_score': 0.4510747851725146, 'eval_bleu_score_sem': 0.04097094641222313, 'eval_rouge_score': 0.006253050122076168, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6074132919311523, 'eval_emb_cos_sim_sem': 0.019114315509796143, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 221.0384, 'eval_samples_per_second': 2.262, 'eval_steps_per_second': 0.566}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/tur_Latn_steps-1.json
evaluating corrector with beam width 8
[pred] Antoine de la Gare de la Gare de la Gare de la Gare de la Gare de la Gare de la Gare de la Gare de la Gare de la
[true] tek parti devri TEK PARTÄ° DEVRÄ° haberleri haber haberi | Sayfa 7 Tek parti chp zamanÄ±nda yapÄ±lan... 15 Åubat 2015, 



[pred] Shopify Shopify Shopify Shopify Shopify Shopify Shopify Shopify Shopify Shopify Shopify Shopify Shopify Shopify Shopify S
[true] Anasayfa Spor FenerbahÃ§e-Dinamo Zagreb maÃ§Ä±nÄ±n hakemleri aÃ§Ä±klandÄ± kaynuka Tarih: 2018-11-27 Saat: 15:07:19 GÃ¼ncelleme 



[pred] ioioioioioioioioioioioioioioio
[true] AlÄ±ÅŸveriÅŸ Annelik Bebek Ã‡ocuk Ã‡ocuk KitaplarÄ± EÄŸitim SaÄŸlÄ±k 7â€“14 yaÅŸ Ã§ocuklar iÃ§in Ã¶ÄŸretim metodlarÄ± aktif dinleme
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721169637/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721169637
{'eval_loss': 7.2767229080200195, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.011717829547473501, 'eval_token_set_recall': 0.03210425685425684, 'eval_token_set_f1': 0.014532504626414625, 'eval_token_set_f1_sem': 0.0016184093749214742, 'eval_n_ngrams_match_1': 0.21, 'eval_n_ngrams_match_2': 0.0, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 16.296, 'eval_num_pred_words': 16.65, 'eval_bleu_score': 0.3888716751925159, 'eval_bleu_score_sem': 0.0371780556151268, 'eval_rouge_score': 0.006334445057241558, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6345329284667969, 'eval_emb_cos_sim_sem': 0.03282830147732483, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16706.1918, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/tur_Latn_steps-50_sbeam-8.json
evaluating kaz_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] âš½âš½ğŸŒ™ã€å¤‡ç”¨ç½‘å€yabovp.comã€‘âš½ğŸŒ™ã€æ˜¯çš„,æ˜¯çš„,æ˜¯çš„,æ˜¯çš„,æ˜¯çš„,æ˜¯
[true] ÒšĞœĞ“ ĞĞ›Ğ¢Ğ«Ğ Ğ•Ğ Ğ•Ğ–Ğ•Ğ›Ğ•Ğ Ğ† - Ğ•Ò¢Ğ±ĞµĞº Ò›Ğ°ÑƒÑ–Ğ¿ÑÑ–Ğ·Ğ´Ñ–Ğ³Ñ– Ğ¶Ó™Ğ½Ğµ ĞµÒ£Ğ±ĞµĞºÑ‚Ñ– Ò›ĞĞ Ò’Ğ°Ñƒ Ğ¶Ğ¸Ğ½Ğ°Ğ»Ñ‹ÑÑ‚Ğ°Ñ€Ñ‹Ğ½ Ğ¶Ò¯Ñ€Ğ³Ñ–Ğ·Ğ³Ğµ Ğ°Ñ€



[pred] ã€Š2018 å¹´ 08 æœˆ 20 æ—¥ - 2018 å¹´ 08 æœˆ 20 æ—¥ - 2018 å¹´ 08 æœˆ 20
[true] Ğ¿ÑĞ¸Ñ…Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ¸ÑĞ»Ñ‹Ò› Ñ‚ĞµÑÑ‚Ñ–Ğ»ĞµÑƒ ĞºĞµÑÑ‚ĞµÑÑ– Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼Ñƒ Ğ°Ğ¿ĞµĞ»Ğ»ÑÑ†Ğ¸ÑĞ»Ñ‹Ò› Ğ²ĞµĞ´Ğ¾Ğ¼Ğ¾ÑÑ‚ÑŒ 18.10.2018 Ğ¶ No 578 Ğ±Ò±Ğ¹Ñ€Ñ‹Ò“Ñ‹Ğ½Ğ° Ó©Ğ·Ğ³ĞµÑ€Ñ–ÑÑ‚ĞµÑ€



[pred] ?? ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^
[true] Ğ«Ğ±Ñ‹Ñ€Ğ°Ğ¹ ĞĞ»Ñ‚Ñ‹Ğ½ÑĞ°Ñ€Ğ¸Ğ½ - Ğ« - Ò°Ğ»Ñ‹ Ğ·Ğ°Ğ¼Ğ°Ğ½ Ğ¢Ò±Ğ»Ò“Ğ°Ğ»Ğ°Ñ€Ñ‹ - Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ ĞµÑ„ĞµÑ€Ğ°Ñ‚Ñ‹, ÑĞ»Ğ°Ğ¹Ğ´Ñ‹,
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721169848/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721169848
{'eval_loss': 8.745986938476562, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.011308436738699891, 'eval_token_set_recall': 0.07661634199134197, 'eval_token_set_f1': 0.017630535569235255, 'eval_token_set_f1_sem': 0.0023413058478610922, 'eval_n_ngrams_match_1': 0.192, 'eval_n_ngrams_match_2': 0.02, 'eval_n_ngrams_match_3': 0.01, 'eval_num_true_words': 14.778, 'eval_num_pred_words': 11.228, 'eval_bleu_score': 0.518423427801559, 'eval_bleu_score_sem': 0.08206360924205193, 'eval_rouge_score': 0.025335783913026922, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6772552132606506, 'eval_emb_cos_sim_sem': 0.0562920942902565, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.25, 'eval_runtime': 211.1143, 'eval_samples_per_second': 2.368, 'eval_steps_per_second': 0.592}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/kaz_Cyrl_steps-1.json
evaluating corrector with beam width 8
[pred] ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“
[true] ÒšĞœĞ“ ĞĞ›Ğ¢Ğ«Ğ Ğ•Ğ Ğ•Ğ–Ğ•Ğ›Ğ•Ğ Ğ† - Ğ•Ò¢Ğ±ĞµĞº Ò›Ğ°ÑƒÑ–Ğ¿ÑÑ–Ğ·Ğ´Ñ–Ğ³Ñ– Ğ¶Ó™Ğ½Ğµ ĞµÒ£Ğ±ĞµĞºÑ‚Ñ– Ò›ĞĞ Ò’Ğ°Ñƒ Ğ¶Ğ¸Ğ½Ğ°Ğ»Ñ‹ÑÑ‚Ğ°Ñ€Ñ‹Ğ½ Ğ¶Ò¯Ñ€Ğ³Ñ–Ğ·Ğ³Ğµ Ğ°Ñ€



[pred] - - - - - - - - - - - - - - - 
[true] Ğ¿ÑĞ¸Ñ…Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ¸ÑĞ»Ñ‹Ò› Ñ‚ĞµÑÑ‚Ñ–Ğ»ĞµÑƒ ĞºĞµÑÑ‚ĞµÑÑ– Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼Ñƒ Ğ°Ğ¿ĞµĞ»Ğ»ÑÑ†Ğ¸ÑĞ»Ñ‹Ò› Ğ²ĞµĞ´Ğ¾Ğ¼Ğ¾ÑÑ‚ÑŒ 18.10.2018 Ğ¶ No 578 Ğ±Ò±Ğ¹Ñ€Ñ‹Ò“Ñ‹Ğ½Ğ° Ó©Ğ·Ğ³ĞµÑ€Ñ–ÑÑ‚ĞµÑ€



[pred] ?? ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^
[true] Ğ«Ğ±Ñ‹Ñ€Ğ°Ğ¹ ĞĞ»Ñ‚Ñ‹Ğ½ÑĞ°Ñ€Ğ¸Ğ½ - Ğ« - Ò°Ğ»Ñ‹ Ğ·Ğ°Ğ¼Ğ°Ğ½ Ğ¢Ò±Ğ»Ò“Ğ°Ğ»Ğ°Ñ€Ñ‹ - Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ ĞµÑ„ĞµÑ€Ğ°Ñ‚Ñ‹, ÑĞ»Ğ°Ğ¹Ğ´Ñ‹,
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721186524/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721186524
{'eval_loss': 8.745695114135742, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.008824661037277137, 'eval_token_set_recall': 0.059160714285714275, 'eval_token_set_f1': 0.013347459005368724, 'eval_token_set_f1_sem': 0.002085430261524683, 'eval_n_ngrams_match_1': 0.154, 'eval_n_ngrams_match_2': 0.016, 'eval_n_ngrams_match_3': 0.01, 'eval_num_true_words': 14.778, 'eval_num_pred_words': 10.04, 'eval_bleu_score': 0.41381562164580804, 'eval_bleu_score_sem': 0.07707106490901597, 'eval_rouge_score': 0.018306870032771358, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7085402011871338, 'eval_emb_cos_sim_sem': 0.0528673841183978, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16675.9488, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/kaz_Cyrl_steps-50_sbeam-8.json
evaluating cmn_Hani val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] å—ç–«æƒ…å½±å“,éƒ¨åˆ†åœ°åŒºå¸‚åœºä»·æ ¼å‡ºç°ä½ä½éœ‡è¡,ä¾›éœ€çŸ›ç›¾æŒç»­åŠ å‰§,ä¾›éœ€çŸ›ç›¾æŒç»­åŠ å‰§,ä¾›éœ€
[true] ä¸‹è¡Œä»¥åŠç°è´§æˆäº¤åå¼±æ‹–ç´¯,å¸‚åœºä¸»å¯¼åœ°åŒºä»·æ ¼ç»§ç»­å¿«é€Ÿè°ƒä½,é‚¯éƒ¸ä¸­æ¿ä»·æ ¼é‡å¿ƒä¸‹ç§»



[pred] çç å®ç”µå­æ¸¸è‰ºæ˜¯é‡‡ç”¨é«˜å¼ºåº¦çš„å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹
[true] æ¯æ—¥å½©ç¥¨ çç æ£‰çš„åŒ…è£…å®šä½æ˜¯ä¸€ç§å…·æœ‰é«˜å¼ºçš„ç¼“å†²å¸éœ‡æŠ—éœ‡ä½œç”¨çš„æœ‰æ˜æ˜¾ç¯ä¿æ•ˆåŠ›çš„åŒ…è£…æ–¹å¼ã€‚ç”±äº



[pred] ç«å¸äº‘çš„å¼€å‘è€…åœ¨å»å¹´6æœˆå…¬å¼€äº†è‡ªå·±çš„è´¦å·,ä½†ä»–ä»¬è§‰å¾—è‡ªå·±å¯ä»¥æƒ³è±¡è‡ªå·±åœ¨ç«å¸äº‘ä¸Šåšä»€ä¹ˆ,
[true] ç«å¸äº‘äºä¸Šä¸ªæœˆåˆšåˆšæ¨å‡º,å…è®¸ç”¨æˆ·å¼€å‘ä»–ä»¬è‡ªå·±çš„ç±»ä¼¼ç«å¸ç½‘çš„æ•°å­—è´§å¸äº¤æ˜“å¹³å°,å…¶ä¸­åŒ…æ‹¬é’±åŒ…ã€èµ„äº§
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721186738/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721186738
{'eval_loss': 3.377187728881836, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.890625, 'eval_token_set_precision': 0.21843979158096832, 'eval_token_set_recall': 0.23918901653901672, 'eval_token_set_f1': 0.22047031476435586, 'eval_token_set_f1_sem': 0.005916786380794748, 'eval_n_ngrams_match_1': 1.794, 'eval_n_ngrams_match_2': 0.106, 'eval_n_ngrams_match_3': 0.028, 'eval_num_true_words': 6.336, 'eval_num_pred_words': 6.732, 'eval_bleu_score': 6.1864689666076105, 'eval_bleu_score_sem': 0.3384425931314763, 'eval_rouge_score': 0.0704232323232323, 'eval_exact_match': 0.004, 'eval_exact_match_sem': 0.002825591608118863, 'eval_emb_cos_sim': 0.8547984957695007, 'eval_emb_cos_sim_sem': 0.03631172329187393, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.28867512941360474, 'eval_runtime': 214.5825, 'eval_samples_per_second': 2.33, 'eval_steps_per_second': 0.583}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/cmn_Hani_steps-1.json
evaluating corrector with beam width 8
[pred] å—ç–«æƒ…å½±å“,éƒ¨åˆ†åœ°åŒºä»·æ ¼å‡ºç°ä½ä½éœ‡è¡,ä¾›éœ€ä»·æ ¼æŒç»­ä¸‹è·Œ,é‚¯éƒ¸ã€é‚¯éƒ¸ã€é‚¯éƒ¸ã€é‚¯éƒ¸
[true] ä¸‹è¡Œä»¥åŠç°è´§æˆäº¤åå¼±æ‹–ç´¯,å¸‚åœºä¸»å¯¼åœ°åŒºä»·æ ¼ç»§ç»­å¿«é€Ÿè°ƒä½,é‚¯éƒ¸ä¸­æ¿ä»·æ ¼é‡å¿ƒä¸‹ç§»



[pred] çç å®ç”µå­æ¸¸è‰ºæ˜¯é‡‡ç”¨é«˜å¼ºåº¦çš„å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹æ€§å¼¹
[true] æ¯æ—¥å½©ç¥¨ çç æ£‰çš„åŒ…è£…å®šä½æ˜¯ä¸€ç§å…·æœ‰é«˜å¼ºçš„ç¼“å†²å¸éœ‡æŠ—éœ‡ä½œç”¨çš„æœ‰æ˜æ˜¾ç¯ä¿æ•ˆåŠ›çš„åŒ…è£…æ–¹å¼ã€‚ç”±äº



[pred] ç«å¸äº‘çš„å¼€å‘è€…äº5æœˆ6æ—¥å…¬å¼€äº†è‡ªå·±çš„è´¦å·,ä»–è¡¨ç¤º,ä»–ä»¬å¯ä»¥å¼€å‘å‡ºæ›´å¤šåŸºäºåŒºå—é“¾çš„è™šæ‹Ÿè´§å¸,
[true] ç«å¸äº‘äºä¸Šä¸ªæœˆåˆšåˆšæ¨å‡º,å…è®¸ç”¨æˆ·å¼€å‘ä»–ä»¬è‡ªå·±çš„ç±»ä¼¼ç«å¸ç½‘çš„æ•°å­—è´§å¸äº¤æ˜“å¹³å°,å…¶ä¸­åŒ…æ‹¬é’±åŒ…ã€èµ„äº§
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721203326/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721203326
{'eval_loss': 3.377716302871704, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.890625, 'eval_token_set_precision': 0.2110674972086739, 'eval_token_set_recall': 0.24132172827172835, 'eval_token_set_f1': 0.21752852243066692, 'eval_token_set_f1_sem': 0.006006221738847216, 'eval_n_ngrams_match_1': 1.732, 'eval_n_ngrams_match_2': 0.096, 'eval_n_ngrams_match_3': 0.026, 'eval_num_true_words': 6.336, 'eval_num_pred_words': 6.5, 'eval_bleu_score': 6.011373346680869, 'eval_bleu_score_sem': 0.3143233743317863, 'eval_rouge_score': 0.07511908744849918, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8576104640960693, 'eval_emb_cos_sim_sem': 0.07255545200000385, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16587.5773, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/cmn_Hani_steps-50_sbeam-8.json
evaluating jpn_Jpan val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] å±±é›¨ä¸‹é›¨ å±±é›¨ä¸‹é›¨ å±±é›¨ä¸‹é›¨ å±±é›¨ä¸‹é›¨ å±±é›¨ä¸‹é›¨ å±±é›¨ä¸‹é›¨ 
[true] èŠ±ç«‹å±±è˜ã§ã¯å¤œåŠã‹ã‚‰é›¨ãŒé™ã‚Šç¶šã„ã¦ã„ã¦ã€æœã«ã¡ã‚‡ã£ã¨ã ã‘é›¨è„šãŒå¼±ããªã£ãŸã¨ãã«å‡ºç™ºã€‚ ã—ã°ã‚‰ãã¯éœ§ã®ä¸­



[pred] éœè¬çš„å¹³æ¹–æ°´æ™¯ã€‚ éœè¬çš„å¹³æ¹–æ°´æ™¯ éœè¬çš„å¹³æ¹–æ°´æ™¯ éœè¬çš„å¹³æ¹–
[true] ä»Šã‚·ãƒ¼ã‚ºãƒ³åˆã®å‡çµã—ãŸæ¡§åŸæ¹–ã®æ¹–ä¸Šæ’®å½±ã§ã™ã€‚ ã‹ãªã‚Šçµæ°·ã¯é€²ã‚“ã§ã„ã¾ã—ãŸãŒã€ã¾ã ãƒ¯ã‚«ã‚µã‚®ç©´é‡£ã‚Šã¯



[pred] ã€ŠåŠæœˆç„¡æ†‚ã€‹ / å¨›æ¨‚åœˆ / å¨›æ¨‚åœˆ / å¨›æ¨‚åœˆ / å¨›æ¨‚åœˆ
[true] ã¾ãšå°‘ãªãã¨ã‚‚ã“ã®äººãŸã¡ãƒãƒ¼ãƒ ã«ãƒãƒƒãƒˆå‘¨ã‚ŠãŒå¼·ã„äººé–“ãŒã„ã‚‹ã“ã¨ã¯é–“é•ã„ãªãã¦ã€YouTubeã®ãƒ¡ã‚¿ã‚¿ã‚°(ãƒ¡ã‚¿ã‚¿ã‚°ã£ã¦?ã£ã¦äººã¯ã“ã®è¨˜äº‹ã‚’ã©ã†ã)
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721203542/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721203542
{'eval_loss': 7.411141872406006, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.026277846130477713, 'eval_token_set_recall': 0.03579047619047619, 'eval_token_set_f1': 0.028551549259134404, 'eval_token_set_f1_sem': 0.004091763779039542, 'eval_n_ngrams_match_1': 0.206, 'eval_n_ngrams_match_2': 0.006, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 3.166, 'eval_num_pred_words': 6.842, 'eval_bleu_score': 0.4271197653751494, 'eval_bleu_score_sem': 0.07857080077817208, 'eval_rouge_score': 0.03641843381077127, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7729384899139404, 'eval_emb_cos_sim_sem': 0.03420301899313927, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 216.2013, 'eval_samples_per_second': 2.313, 'eval_steps_per_second': 0.578}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/jpn_Jpan_steps-1.json
evaluating corrector with beam width 8
[pred] å±±ä¸Šéœ²é›ª å±±ä¸Šéœ²é›ª å±±ä¸Šéœ²é›ª å±±ä¸Šéœ²é›ª å±±ä¸Šéœ²é›ª å±±ä¸Šéœ²é›ª 
[true] èŠ±ç«‹å±±è˜ã§ã¯å¤œåŠã‹ã‚‰é›¨ãŒé™ã‚Šç¶šã„ã¦ã„ã¦ã€æœã«ã¡ã‚‡ã£ã¨ã ã‘é›¨è„šãŒå¼±ããªã£ãŸã¨ãã«å‡ºç™ºã€‚ ã—ã°ã‚‰ãã¯éœ§ã®ä¸­



[pred] åŸæ¨™é¡Œ:çµç¶æ¹–åˆå¤æ™¯è§€ åŸæ¨™é¡Œ:çµç¶æ¹–åˆå¤æ™¯è§€ çµç¶æ¹–åˆå¤æ™¯
[true] ä»Šã‚·ãƒ¼ã‚ºãƒ³åˆã®å‡çµã—ãŸæ¡§åŸæ¹–ã®æ¹–ä¸Šæ’®å½±ã§ã™ã€‚ ã‹ãªã‚Šçµæ°·ã¯é€²ã‚“ã§ã„ã¾ã—ãŸãŒã€ã¾ã ãƒ¯ã‚«ã‚µã‚®ç©´é‡£ã‚Šã¯



[pred] ã€Šæ¥µå°‘çš„æ™‚é–“ã€‹ ã€Šæ¥µå°‘çš„æ™‚é–“ã€‹ ã€Šæ¥µå°‘çš„æ™‚é–“ã€‹ ã€Šæ¥µå°‘çš„æ™‚é–“ã€‹ ã€Šæ¥µ
[true] ã¾ãšå°‘ãªãã¨ã‚‚ã“ã®äººãŸã¡ãƒãƒ¼ãƒ ã«ãƒãƒƒãƒˆå‘¨ã‚ŠãŒå¼·ã„äººé–“ãŒã„ã‚‹ã“ã¨ã¯é–“é•ã„ãªãã¦ã€YouTubeã®ãƒ¡ã‚¿ã‚¿ã‚°(ãƒ¡ã‚¿ã‚¿ã‚°ã£ã¦?ã£ã¦äººã¯ã“ã®è¨˜äº‹ã‚’ã©ã†ã)
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721220043/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721220043
{'eval_loss': 7.411140441894531, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.01624559884559884, 'eval_token_set_recall': 0.02512943722943723, 'eval_token_set_f1': 0.018110009764146628, 'eval_token_set_f1_sem': 0.0030914382752538342, 'eval_n_ngrams_match_1': 0.14, 'eval_n_ngrams_match_2': 0.002, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 3.166, 'eval_num_pred_words': 7.07, 'eval_bleu_score': 0.308537423931548, 'eval_bleu_score_sem': 0.0544567774447954, 'eval_rouge_score': 0.037426171858756976, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7894496917724609, 'eval_emb_cos_sim_sem': 0.009545087661404272, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16501.2382, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/jpn_Jpan_steps-50_sbeam-8.json
evaluating kor_Hang val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] è‡ªç„¶ - è‡ªç„¶ - è‡ªç„¶ - è‡ªç„¶ - è‡ªç„¶ - è‡ªç„¶ - è‡ªç„¶ - è‡ªç„¶ 
[true] ì„¸ì¼ ì¤‘ â€“ Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price %}{{



[pred] ğŸ’šğŸ’šğŸ’šğŸŒ™ã€å¤‡ç”¨ç½‘å€hthvp.comã€‘ğŸ’šğŸ’šğŸŒ™ã€æ¯å€‹äººéƒ½ç”¨ä¸åŒçš„æ–¹å¼,éƒ½æœƒç”¨ä¸åŒçš„æ–¹å¼,ä¸¦
[true] ì‹ ìš©ìœ„í—˜ ê²°ì •ìš”ì¸ ê³¼ ê´€ë ¨ - í† í† ì‚¬ì´íŠ¸ ê²€ì¦ì‚¬ì´íŠ¸ ë©”ì´ì €í† í† ì‚¬ì´íŠ¸ - í† í† íƒì • - ì‹ ìš©ìœ„í—˜



[pred] âš½âš½ğŸŒ™ã€å¤‡ç”¨ç½‘å€yabovp.comã€‘vp.com|vp.com|vp.com|vp.com
[true] ì•ˆë“œë¡œì´ë“œ : ì‚¼ì„±ë°”ë‹¤í° ì˜êµ­ ì˜¨ë¼ì¸ ë“±ë¡ - íƒ€ì´ì   - ì•ˆë“œë¡œì´ë“œ ìŠ¤ë§ˆíŠ¸í°ê³¼ íƒœë¸”ë¦¿ ìƒˆë¡œìš´ ì†Œ
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721220258/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721220258
{'eval_loss': 8.01869010925293, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.015490113275097783, 'eval_token_set_recall': 0.07966785714285712, 'eval_token_set_f1': 0.023832361000535908, 'eval_token_set_f1_sem': 0.0025538708889108865, 'eval_n_ngrams_match_1': 0.236, 'eval_n_ngrams_match_2': 0.004, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 13.578, 'eval_num_pred_words': 11.082, 'eval_bleu_score': 0.5507211129400807, 'eval_bleu_score_sem': 0.05910696313313069, 'eval_rouge_score': 0.02074324840654428, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6830919981002808, 'eval_emb_cos_sim_sem': 0.05742426961660385, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.25, 'eval_runtime': 214.5754, 'eval_samples_per_second': 2.33, 'eval_steps_per_second': 0.583}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/kor_Hang_steps-1.json
evaluating corrector with beam width 8
[pred] è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|è‡ªç„¶|
[true] ì„¸ì¼ ì¤‘ â€“ Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price %}{{



[pred] ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“
[true] ì‹ ìš©ìœ„í—˜ ê²°ì •ìš”ì¸ ê³¼ ê´€ë ¨ - í† í† ì‚¬ì´íŠ¸ ê²€ì¦ì‚¬ì´íŠ¸ ë©”ì´ì €í† í† ì‚¬ì´íŠ¸ - í† í† íƒì • - ì‹ ìš©ìœ„í—˜



[pred] âš½âš½ğŸŒ™ã€å¤‡ç”¨ç½‘å€123yb.comã€‘âš½ğŸŒ™ã€å¤‡ç”¨ç½‘å€123yb.comã€‘âš½ğŸŒ™ã€å¤‡ç”¨ç½‘å€123yb.comã€‘âš½ğŸŒ™
[true] ì•ˆë“œë¡œì´ë“œ : ì‚¼ì„±ë°”ë‹¤í° ì˜êµ­ ì˜¨ë¼ì¸ ë“±ë¡ - íƒ€ì´ì   - ì•ˆë“œë¡œì´ë“œ ìŠ¤ë§ˆíŠ¸í°ê³¼ íƒœë¸”ë¦¿ ìƒˆë¡œìš´ ì†Œ
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721236974/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721236974
{'eval_loss': 8.018288612365723, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.012833269302077347, 'eval_token_set_recall': 0.05415840548340548, 'eval_token_set_f1': 0.01819079165478124, 'eval_token_set_f1_sem': 0.0023351858340300534, 'eval_n_ngrams_match_1': 0.2, 'eval_n_ngrams_match_2': 0.004, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 13.578, 'eval_num_pred_words': 10.522, 'eval_bleu_score': 0.40651217621542945, 'eval_bleu_score_sem': 0.0458196117152884, 'eval_rouge_score': 0.013329494287140004, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7694910764694214, 'eval_emb_cos_sim_sem': 0.004236847178688799, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16715.686, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/kor_Hang_steps-50_sbeam-8.json
evaluating mon_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] /film/film/film/film/film/film/film/film/film/film/film/film/film/film/film
[true] ĞĞ»Ñ‚Ğ½Ñ‹ Ğ¾Ğ»Ğ±Ğ¾Ñ€Ğ»Ğ¾Ğ»Ñ‚ Ğ°Ğ¼Ğ¶Ğ¸Ğ»Ñ‚Ğ°Ğ´ Ñ…Ò¯Ñ€Ğ½Ñ ĞĞ¥Ğ£Ñ‹Ğ½ Ğ³Ğ°Ğ´Ğ°Ğ°Ğ´ Ó©Ñ€ 56 Ñ‚ÑÑ€Ğ±ÑƒĞ¼ Ğ°Ğ¼.Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€ Ğ±Ğ¾Ğ»Ğ¶ Ó©ÑÑ‡ÑÑ. Ğ­Ğ½Ñ



[pred] a href="" target="_blank">a href="" target="_blank">a href="" target="_blank">a href="" target="_blank">a href
[true] Google Ğ¢ĞµĞºÑÑ‚Ğ¸Ğ¹Ğ½ Ğ·Ğ°Ñ€Ñ‹Ğ½ Ó©Ó©Ñ€Ñ‡Ğ»Ó©Ğ»Ñ‚Ğ¸Ğ¹Ğ³ Ğ°Ğ½Ñ…Ğ°Ğ°Ñ€Ñ‡ Ò¯Ğ·ÑÑ… 3 Ğ·Ò¯Ğ¹Ğ» | Martech Zone Google Ğ¢ĞµĞºÑÑ‚Ğ¸Ğ¹Ğ½ Ğ·Ğ°Ñ€Ñ‹Ğ½ Ó©Ó©Ñ€Ñ‡Ğ»Ó©Ğ»Ñ‚



[pred] ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“
[true] Â» Ğ¡Ğ•ĞšĞ¡ (1085550) Â» Ğ¨ĞĞ  ĞœĞ­Ğ”Ğ­Ğ­ (805751) Â» Ó¨Ğ“Ò®Ò®Ğ›Ğ›Ğ­Ğ“ (906359) Ñ…Ó©Ğ»Ğ¸Ğ¹Ğ³ Ğ½ÑŒ Ñ…ÑƒĞ³Ğ°Ğ»Ğ°Ğ½
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721237189/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721237189
{'eval_loss': 8.734009742736816, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.009863085770438713, 'eval_token_set_recall': 0.05402089381207029, 'eval_token_set_f1': 0.014865321937904718, 'eval_token_set_f1_sem': 0.001959324738793595, 'eval_n_ngrams_match_1': 0.154, 'eval_n_ngrams_match_2': 0.0, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 13.308, 'eval_num_pred_words': 12.234, 'eval_bleu_score': 0.5118931048274574, 'eval_bleu_score_sem': 0.045293967618344574, 'eval_rouge_score': 0.020754765510105393, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6555038690567017, 'eval_emb_cos_sim_sem': 0.022003112360835075, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 215.5296, 'eval_samples_per_second': 2.32, 'eval_steps_per_second': 0.58}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/mon_Cyrl_steps-1.json
evaluating corrector with beam width 8
[pred] ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[true] ĞĞ»Ñ‚Ğ½Ñ‹ Ğ¾Ğ»Ğ±Ğ¾Ñ€Ğ»Ğ¾Ğ»Ñ‚ Ğ°Ğ¼Ğ¶Ğ¸Ğ»Ñ‚Ğ°Ğ´ Ñ…Ò¯Ñ€Ğ½Ñ ĞĞ¥Ğ£Ñ‹Ğ½ Ğ³Ğ°Ğ´Ğ°Ğ°Ğ´ Ó©Ñ€ 56 Ñ‚ÑÑ€Ğ±ÑƒĞ¼ Ğ°Ğ¼.Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€ Ğ±Ğ¾Ğ»Ğ¶ Ó©ÑÑ‡ÑÑ. Ğ­Ğ½Ñ



[pred] a href="" target="_blank">a href="" target="_blank">a href="" target="_blank">a href="" target="_blank">a href
[true] Google Ğ¢ĞµĞºÑÑ‚Ğ¸Ğ¹Ğ½ Ğ·Ğ°Ñ€Ñ‹Ğ½ Ó©Ó©Ñ€Ñ‡Ğ»Ó©Ğ»Ñ‚Ğ¸Ğ¹Ğ³ Ğ°Ğ½Ñ…Ğ°Ğ°Ñ€Ñ‡ Ò¯Ğ·ÑÑ… 3 Ğ·Ò¯Ğ¹Ğ» | Martech Zone Google Ğ¢ĞµĞºÑÑ‚Ğ¸Ğ¹Ğ½ Ğ·Ğ°Ñ€Ñ‹Ğ½ Ó©Ó©Ñ€Ñ‡Ğ»Ó©Ğ»Ñ‚



[pred] ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“
[true] Â» Ğ¡Ğ•ĞšĞ¡ (1085550) Â» Ğ¨ĞĞ  ĞœĞ­Ğ”Ğ­Ğ­ (805751) Â» Ó¨Ğ“Ò®Ò®Ğ›Ğ›Ğ­Ğ“ (906359) Ñ…Ó©Ğ»Ğ¸Ğ¹Ğ³ Ğ½ÑŒ Ñ…ÑƒĞ³Ğ°Ğ»Ğ°Ğ½
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721253772/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721253772
{'eval_loss': 8.733860969543457, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.0092385083870378, 'eval_token_set_recall': 0.0382281968031968, 'eval_token_set_f1': 0.012207657804277093, 'eval_token_set_f1_sem': 0.0017517764377964983, 'eval_n_ngrams_match_1': 0.146, 'eval_n_ngrams_match_2': 0.0, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 13.308, 'eval_num_pred_words': 12.768, 'eval_bleu_score': 0.4562904877983468, 'eval_bleu_score_sem': 0.04157316439719216, 'eval_rouge_score': 0.01882387835770233, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6562309265136719, 'eval_emb_cos_sim_sem': 0.006826490150450583, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16582.9781, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/mon_Cyrl_steps-50_sbeam-8.json
evaluating hun_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] æ–‡ç« æ‘˜è¦:GitHub,GitHub,GitHub,GitHub,GitHub,GitHub,GitHub
[true] Ultrahang kezelÃ©s: FÃ¡jdalomcsillapÃ­tÃ¡s tÅ±szÅ±rÃ¡s nÃ©lkÃ¼l [teljes ÃºtmutatÃ³] ÃzÃ¼leti fÃ¡jdalom fonoforÃ©zis



[pred] Jamie McMillan / Jamie Mcillan / Jamie Mcillan / Jamie Mcillan / Jamie Mcillan /
[true] Az Ãºj Mike Tyson | SamanSport.hu 2019. 12. 13., PÃ©ntek, 18:40 Gervonta "Tank" Davis hatalmas attrakciÃ³



[pred] / / / / / / / / / / / / / / / 
[true] JÃ¡rmÅ±vek | Hobbi ZÃ³na - Part 2 TankChair â€“ az Off Road tolÃ³szÃ©k A rendkÃ­vÃ¼li gÃ©pezet, egy "
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721253994/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721253994
{'eval_loss': 7.3715596199035645, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.02626033288177249, 'eval_token_set_recall': 0.08420082499200164, 'eval_token_set_f1': 0.03317766358222345, 'eval_token_set_f1_sem': 0.0023864256313450866, 'eval_n_ngrams_match_1': 0.468, 'eval_n_ngrams_match_2': 0.002, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 15.884, 'eval_num_pred_words': 15.41, 'eval_bleu_score': 0.7514416639724905, 'eval_bleu_score_sem': 0.05063265758500062, 'eval_rouge_score': 0.011100424268934378, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6362704634666443, 'eval_emb_cos_sim_sem': 0.027249986305832863, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.25, 'eval_runtime': 221.6371, 'eval_samples_per_second': 2.256, 'eval_steps_per_second': 0.564}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/hun_Latn_steps-1.json
evaluating corrector with beam width 8
[pred] æ‘˜ è¦: gdgdgdgdgdgdgdgdgdgdgdgdg
[true] Ultrahang kezelÃ©s: FÃ¡jdalomcsillapÃ­tÃ¡s tÅ±szÅ±rÃ¡s nÃ©lkÃ¼l [teljes ÃºtmutatÃ³] ÃzÃ¼leti fÃ¡jdalom fonoforÃ©zis



[pred] J.J.J.J.J.J.J.J.J.J.J.J.J.J.J.J
[true] Az Ãºj Mike Tyson | SamanSport.hu 2019. 12. 13., PÃ©ntek, 18:40 Gervonta "Tank" Davis hatalmas attrakciÃ³



[pred] a/b/b/b/b/b/b/b/b/b/b/b/b/b/b/
[true] JÃ¡rmÅ±vek | Hobbi ZÃ³na - Part 2 TankChair â€“ az Off Road tolÃ³szÃ©k A rendkÃ­vÃ¼li gÃ©pezet, egy "
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721270533/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721270533
{'eval_loss': 7.371373176574707, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.024502656734390463, 'eval_token_set_recall': 0.06677112054612065, 'eval_token_set_f1': 0.0297796687234557, 'eval_token_set_f1_sem': 0.0022476002681028327, 'eval_n_ngrams_match_1': 0.438, 'eval_n_ngrams_match_2': 0.004, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 15.884, 'eval_num_pred_words': 15.734, 'eval_bleu_score': 0.707035789120742, 'eval_bleu_score_sem': 0.04422760069738072, 'eval_rouge_score': 0.012257332275497449, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6566790342330933, 'eval_emb_cos_sim_sem': 0.047710211440907785, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.49999999144286444, 'eval_runtime': 16539.305, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/hun_Latn_steps-50_sbeam-8.json
evaluating mhr_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] ??????????????? 
[true] Ğ¢ÑƒÑ€Ğ³Ñ‹Ğ¼ Ğ¶Ğ°Ğ¿Ñ‹ÑˆÑ‚Ğµ, ÑˆĞ¾ÑˆĞ¾ Ğ°Ğ³Ğ° Ğ³Ğ¾Ğ´Ñ‹Ğ¼, ĞºĞµÑ‡ Ğ¸Ğº Ğ³Ğ°Ğ½Ğ° ĞšÑƒĞ³Ñƒ ĞšĞ°Ñ‡Ğ°Ğº ÑĞ»Ñ‹ÑˆÑ‚Ğµ Ğ»Ğ¸ÑÑˆ Ñ‚Ñ‹Ñ€ÑˆĞµĞ¼



[pred] ??????????????? 
[true] ĞœĞ¾ Ñ‚Ñ‹Ğ³Ğ°Ğ¹ ĞĞ³Ğ°Ğ²Ğ°Ğ¹Ñ€ĞµĞ¼? ĞšÑƒĞ·Ğµ Ñ‚ÑƒĞ´Ğ¾ ÑÑ€Ñ‚Ğ°? Ğ¢Ğ¸Ğ´Ğµ Ğ´Ğ° Ğ¼Ğ¾Ğ»Ğ¾ Ğ¹Ğ¾Ğ´Ñ‹ÑˆĞ»Ğ°Ğ½ Ğ²Ğ°ÑˆĞ¼ÑƒÑ‚Ñ‹Ğ¼ ĞœĞ°Ñ€Ğ¸Ğ¹ Ğ²Ğ¸ĞºĞ¸Ğ¿ĞµĞ´Ğ¸Ğ¹Ñ‹ÑˆÑ‚Ğµ



[pred] âœ¨âœ¨ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™ğŸŒ™
[true] ĞšĞ¾Ñ€ÑĞº Ñ€Ğ²ĞµĞ·Ğµ ĞŸÑ‘Ñ‚Ñ€ ĞĞµÑÑ‚ĞµÑ€Ğ¾Ğ² Ğ´ĞµĞ½Ğµ Ğ¼Ñ‹Ğ¹ ĞĞ°Ñ€Ğ¾-Ğ¤Ğ¾Ğ¼Ğ¸Ğ½ÑĞº Ğ¾Ğ»Ğ°ÑˆÑ‚Ğµ ÑÑ€Ñ‚Ñ‹ÑˆĞµ Â«ĞŸĞ¾ĞºĞ¾Ğ»ĞµĞ½Ğ¸ĞµÂ»
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721270748/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721270748
{'eval_loss': 9.407505989074707, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.007195125952478896, 'eval_token_set_recall': 0.05381666666666665, 'eval_token_set_f1': 0.011919261577924929, 'eval_token_set_f1_sem': 0.0017513906127081403, 'eval_n_ngrams_match_1': 0.122, 'eval_n_ngrams_match_2': 0.0, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 13.03, 'eval_num_pred_words': 9.722, 'eval_bleu_score': 0.3447273763024566, 'eval_bleu_score_sem': 0.03794761862545265, 'eval_rouge_score': 0.019526012486631175, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7605811357498169, 'eval_emb_cos_sim_sem': 0.017257358878850937, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.28867512941360474, 'eval_runtime': 215.1414, 'eval_samples_per_second': 2.324, 'eval_steps_per_second': 0.581}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/mhr_Cyrl_steps-1.json
evaluating corrector with beam width 8
[pred] ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“
[true] Ğ¢ÑƒÑ€Ğ³Ñ‹Ğ¼ Ğ¶Ğ°Ğ¿Ñ‹ÑˆÑ‚Ğµ, ÑˆĞ¾ÑˆĞ¾ Ğ°Ğ³Ğ° Ğ³Ğ¾Ğ´Ñ‹Ğ¼, ĞºĞµÑ‡ Ğ¸Ğº Ğ³Ğ°Ğ½Ğ° ĞšÑƒĞ³Ñƒ ĞšĞ°Ñ‡Ğ°Ğº ÑĞ»Ñ‹ÑˆÑ‚Ğµ Ğ»Ğ¸ÑÑˆ Ñ‚Ñ‹Ñ€ÑˆĞµĞ¼



[pred] - - - - - - - - - - - - - - - 
[true] ĞœĞ¾ Ñ‚Ñ‹Ğ³Ğ°Ğ¹ ĞĞ³Ğ°Ğ²Ğ°Ğ¹Ñ€ĞµĞ¼? ĞšÑƒĞ·Ğµ Ñ‚ÑƒĞ´Ğ¾ ÑÑ€Ñ‚Ğ°? Ğ¢Ğ¸Ğ´Ğµ Ğ´Ğ° Ğ¼Ğ¾Ğ»Ğ¾ Ğ¹Ğ¾Ğ´Ñ‹ÑˆĞ»Ğ°Ğ½ Ğ²Ğ°ÑˆĞ¼ÑƒÑ‚Ñ‹Ğ¼ ĞœĞ°Ñ€Ğ¸Ğ¹ Ğ²Ğ¸ĞºĞ¸Ğ¿ĞµĞ´Ğ¸Ğ¹Ñ‹ÑˆÑ‚Ğµ



[pred] ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“ğŸ’“
[true] ĞšĞ¾Ñ€ÑĞº Ñ€Ğ²ĞµĞ·Ğµ ĞŸÑ‘Ñ‚Ñ€ ĞĞµÑÑ‚ĞµÑ€Ğ¾Ğ² Ğ´ĞµĞ½Ğµ Ğ¼Ñ‹Ğ¹ ĞĞ°Ñ€Ğ¾-Ğ¤Ğ¾Ğ¼Ğ¸Ğ½ÑĞº Ğ¾Ğ»Ğ°ÑˆÑ‚Ğµ ÑÑ€Ñ‚Ñ‹ÑˆĞµ Â«ĞŸĞ¾ĞºĞ¾Ğ»ĞµĞ½Ğ¸ĞµÂ»
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721287388/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721287388
{'eval_loss': 9.40828800201416, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.00469183039183039, 'eval_token_set_recall': 0.028820502645502646, 'eval_token_set_f1': 0.007544703915010821, 'eval_token_set_f1_sem': 0.0014265382438806385, 'eval_n_ngrams_match_1': 0.08, 'eval_n_ngrams_match_2': 0.0, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 13.03, 'eval_num_pred_words': 8.178, 'eval_bleu_score': 0.22804354206312732, 'eval_bleu_score_sem': 0.032237856403093776, 'eval_rouge_score': 0.014318112812166517, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7488971948623657, 'eval_emb_cos_sim_sem': 0.014053791561883704, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.49999999144286444, 'eval_runtime': 16640.1633, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/mhr_Cyrl_steps-50_sbeam-8.json
evaluating fin_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan
[true] Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. TyÃ¶ympÃ¤ristÃ¶ muutos hankkeissa tuotetaan myÃ¶s valtava



[pred] Pays de la CÃ´te de la CÃ´te de la CÃ´te de la CÃ´te de la CÃ´te de la CÃ´te de la CÃ´te de
[true] Pohjois-suomalaisuus ja kaikille arvokas elÃ¤mÃ¤ - siinÃ¤ tavoitteet toiminnalle. TyÃ¶skentelen Diakonia-ammattikorkeakoulussa



[pred] - - - - - - - - - - - - - - - 
[true] Kun kirjoitimme koivunjalojen lÃ¤Ã¤ketieteellisistÃ¤ ominaisuuksista, mainitsimme, ettÃ¤ paitsi munuaiset, myÃ¶s koivulehdet
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721287606/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721287606
{'eval_loss': 8.266942977905273, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.017980180431883194, 'eval_token_set_recall': 0.03670007215007215, 'eval_token_set_f1': 0.020555079439390965, 'eval_token_set_f1_sem': 0.0018208543828044977, 'eval_n_ngrams_match_1': 0.338, 'eval_n_ngrams_match_2': 0.002, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 14.876, 'eval_num_pred_words': 17.242, 'eval_bleu_score': 0.5415117174805641, 'eval_bleu_score_sem': 0.043114287387668704, 'eval_rouge_score': 0.0032001738729390606, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6635456085205078, 'eval_emb_cos_sim_sem': 0.033391647040843964, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 217.5779, 'eval_samples_per_second': 2.298, 'eval_steps_per_second': 0.575}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/fin_Latn_steps-1.json
evaluating corrector with beam width 8
[pred] Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan Tajikistan T
[true] Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. TyÃ¶ympÃ¤ristÃ¶ muutos hankkeissa tuotetaan myÃ¶s valtava



[pred] Pays de la CÃ´te de la CÃ´te de la CÃ´te de la CÃ´te de la CÃ´te de la CÃ´te de la CÃ´te de
[true] Pohjois-suomalaisuus ja kaikille arvokas elÃ¤mÃ¤ - siinÃ¤ tavoitteet toiminnalle. TyÃ¶skentelen Diakonia-ammattikorkeakoulussa



[pred] - - - - - - - - - - - - - - - 
[true] Kun kirjoitimme koivunjalojen lÃ¤Ã¤ketieteellisistÃ¤ ominaisuuksista, mainitsimme, ettÃ¤ paitsi munuaiset, myÃ¶s koivulehdet
outptufile for decoded sequences:  saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721304339/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_text2vec_cmn_Hani_32_corrector/decoded_eval_1721304339
{'eval_loss': 8.266942977905273, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.016537180217443357, 'eval_token_set_recall': 0.03120543345543342, 'eval_token_set_f1': 0.01793933338946005, 'eval_token_set_f1_sem': 0.0016159725097674665, 'eval_n_ngrams_match_1': 0.316, 'eval_n_ngrams_match_2': 0.0, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 14.876, 'eval_num_pred_words': 17.51, 'eval_bleu_score': 0.5027730440827941, 'eval_bleu_score_sem': 0.04107147756384152, 'eval_rouge_score': 0.0019020888954290193, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.649037778377533, 'eval_emb_cos_sim_sem': 0.08171123317298004, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16733.2532, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_text2vec-base-cmn_mt-ms_cmn_Hani_32_last_layer/evaluations/fin_Latn_steps-50_sbeam-8.json
