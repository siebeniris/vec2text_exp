working directory /home/cs.aau.dk/ng78zb/vec2text_exp
sif /home/cs.aau.dk/ng78zb/pytorch_23.10-py3.sif
launch evaluation yiyic/mt5_alephbert_heb_Hebr_32_inverter
loading experiment and trainer from yiyic/mt5_alephbert_heb_Hebr_32_inverter
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter
on rank 0, output dir: saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter
adding embedding type to dataset args.
Loading datasets with TOKENIZERS_PARALLELISM = False
loading train dataset from path: /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/213679cf36447f274bbad10a36629707.arrow
loaded dict of val datasets from /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/05ff101d74efb425aabdff16685969ac.arrow
07/08/2024 12:29:14 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
data arguments for experiment: DataArguments(dataset_name='mt-ms_heb_Hebr', max_eval_samples=500, use_less_data=3000)
model yiyic/mt5_alephbert_heb_Hebr_32_inverter parameters 718417920
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
Using Frozen Embeddings as Input -- Val datasets
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': 'd40acbc34dac02767f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '41b9adba9016443f7f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': 'dbf8f15a66a20dd37f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '731965c7535e211b7f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '4068af69c2b130c57f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '51d80ec104a4c62a7f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '9bc2bc39c804f7447f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': 'e33d6f57080076667f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': 'af73b4e4b710b9e87f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '9147c51d631d73ba7f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '372f215f503994d67f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '79d192a070857fb87f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '7452c8ee210755067f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '233a94331855f5fa7f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '2e051e14dbc9baa07f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '78b2c85e5afe40eb7f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '0729e548f13d516b7f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '08fcf80d08ce19117f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '08bfe2552e383cee7f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': 'cc9e080b34a637157f9a3f494dfbfee088d24871f2e00380', 'num_proc': 1}
output dir ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations
evaluating deu_Latn val_dataset
evaluating inversion base model
[pred] Ihre Ihre ErgÃ¤nzung zu den Ergebnissen in der Geschichte und das Konzept der Geschichte. In der Geschichte und das Konzept 
[true] In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sortiert und 



[pred] Eine schÃ¶ne Geschichte und ein schÃ¶ner SchÃ¶nheitskunst - Ihre besten freundin Ihre freundin. 
[true] Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht es aber nicht



[pred] Posted in a new york city in a new york city in the latest versions of the latest versions. a
[true] â± Unsere Bestenliste Dec/2022 á… AusfÃ¼hrlicher Produkttest â˜‘ Ausgezeichnete Produkte â˜‘ Aktuelle Angebote â˜‘
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434665/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434665
{'eval_loss': 5.248283863067627, 'eval_accuracy': 0.2040625, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.07391028372362006, 'eval_token_set_recall': 0.13966329911059036, 'eval_token_set_f1': 0.09153482060238037, 'eval_token_set_f1_sem': 0.003642878343004702, 'eval_n_ngrams_match_1': 1.504, 'eval_n_ngrams_match_2': 0.05, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 19.116, 'eval_num_pred_words': 16.132, 'eval_bleu_score': 1.7621793315693712, 'eval_bleu_score_sem': 0.0531145194429041, 'eval_rouge_score': 0.05861966477384609, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.6855134963989258, 'eval_emb_cos_sim_sem': 0.08684449805065225, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_perplexity': 190.23951110763772, 'eval_runtime': 29.2648, 'eval_samples_per_second': 17.085, 'eval_steps_per_second': 2.153}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/deu_Latn_inversion_base.json
evaluating ydd_Hebr val_dataset
evaluating inversion base model
[pred] ×¢××•×“ ×¢××•×“ ×¢××•×“ ×¢××•×“ ×¢××•×“ ×¢××•×“ ×¢××•×“ ×¢××•×“ ×¢××•×“ ×¢××•×“ 
[true] ×˜×©×™×™× ×Ö· (××¢×¨×™×Ö·×˜ / ×”×™×œ×˜×Ö¸×Ÿ) ×”×Ö¸×˜×¢×œ ×§×Ö·×œ×¢×§×©×Ö·×Ÿ ×¢×•×¨×Ö¸×˜×Ö¸×¤Ö¼ 5 ×©×˜×¢×¨×Ÿ ×”×Ö¸×˜×¢×œ ××Ö·×˜×¨×Ö·×¡ ××Ö·× ×™



[pred] ×—×•×“×© ××“×¨, ×ª×©×¢×´×˜, ×ª×©×¢×´×˜- ×ª×©×¢×´×˜. - ×™×¨×•×©×œ×™× - ×™×¨×•×©×œ×™× - 
[true] ×—×•×œÖ¾×”××•×¢×“ ×¡×•×›Ö¼×•×ª, ×ªÖ¼×©×¢×´×– - yiddish.forward.com ×—×•×œÖ¾×”××•×¢×“ ×¡×•×›Ö¼×•×ª, 



[pred] ×¢××•×“ ××™×Ÿ ×¡××˜×××¨ ×¢××•×“ ××™×Ÿ ×¡××˜×××¨ ×¢××•×“ ××™×Ÿ ×¡××˜×××¨ ×¢××•×“ 
[true] ××™×¨××Ÿ ×¤×¨××•×•××§×™×¨×˜ ×˜×¨×××¤: ××™×¨ ×•×•×¢×œ×Ÿ ××•×™×¡×‘×¨×™×™×˜×¢×¨×Ÿ ×“×¢× ××™×¡×™×œ ×¤×¨××’×¨×× ×˜×¨××¥ ××¤×××š ~ ××™×“
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434699/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434699
{'eval_loss': 5.296220302581787, 'eval_accuracy': 0.2439375, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.060110166501884735, 'eval_token_set_recall': 0.16085121489621507, 'eval_token_set_f1': 0.08336091119974076, 'eval_token_set_f1_sem': 0.004667847407298313, 'eval_n_ngrams_match_1': 0.94, 'eval_n_ngrams_match_2': 0.068, 'eval_n_ngrams_match_3': 0.042, 'eval_num_true_words': 13.82, 'eval_num_pred_words': 11.826, 'eval_bleu_score': 1.6298548881461696, 'eval_bleu_score_sem': 0.11523359812134441, 'eval_rouge_score': 0.004189436370081531, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.47382795810699463, 'eval_emb_cos_sim_sem': 0.06684762021000688, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 199.581026667232, 'eval_runtime': 34.0559, 'eval_samples_per_second': 14.682, 'eval_steps_per_second': 1.85}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/ydd_Hebr_inversion_base.json
evaluating heb_Hebr val_dataset
evaluating inversion base model
[pred] ××›×™×•×•×Ÿ ×©×× ×™ ×œ× ×“×™×‘×¨×ª×™ ×‘×• ×¢×“ ×›×” (×•×‘×¤×¨×˜ ×‘× ×•×©××™× ×©×¢× ×™×™× × ××•×‘××™× ×‘××—×¨×•× ×”...) ×¨×¦×™×ª×™ ×œ×”
[true] ×‘××—×§×¨ ×©×”×ª×¤×¨×¡× ×œ××—×¨×•× ×” (×•×× ×™ ××ª× ×¦×œ ×©×œ× ×”×’×¢×ª×™ ×œ×“×•×Ÿ ×‘×• ×¢×“ ×›×” ××¤××ª ×¢× ×™×™× ×™× ××—×¨×™×...) ×’



[pred] ×ª×•×›× ×™×ª ×¨×™××œ×™×˜×™ ×‘×™×©×¨××œ ×”×™× ×œ× ×¨×§ ×ª×•×›× ×™×ª ×¨×™××œ×™×˜×™. ×”×™× ×ª×•×›× ×™×ª ×¨×™××œ×™×˜×™, ×¨×§
[true] ×ª×•×›× ×™×ª ×¨×™××œ×™×˜×™ ×‘×™×©×¨××œ ×”×™× ×œ× ×¨×§ ×ª×•×›× ×™×ª ×¨×™××œ×™×˜×™. ×”×™× ×©×™×¢×•×¨ ×‘××–×¨×—×•×ª, ××“×™× ×™×•×ª ×××©



[pred] ×‘×¤× ×™ ×‘×§×©×” ××©×¨ × ×™×ª× ×” ×œ×¤× ×™×™ ×™×•× 20.6.20 ××©×¨ ×¢×œ ×™×“×• × ×™×ª×Ÿ ×¦×• ×”×“×—×™×™×” ××©×¨ 
[true] ×‘×¤× ×™ ×‘×§×©×” ×œ×¢×™×›×•×‘ ×‘×™×¦×•×¢ ×¤×¡×§ ×”×“×™×Ÿ ××©×¨ × ×™×ª×Ÿ ×‘×™×•× 20.4.11 ×•××©×¨ ×‘××¡×’×¨×ª×• ×—×•×™×‘×” ×”××‘×§×©
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434727/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434727
{'eval_loss': 1.8132646083831787, 'eval_accuracy': 0.601375, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.32376631864008043, 'eval_token_set_recall': 0.3648450030361802, 'eval_token_set_f1': 0.34172091722683423, 'eval_token_set_f1_sem': 0.006544828163599335, 'eval_n_ngrams_match_1': 5.286, 'eval_n_ngrams_match_2': 1.546, 'eval_n_ngrams_match_3': 0.572, 'eval_num_true_words': 15.47, 'eval_num_pred_words': 14.72, 'eval_bleu_score': 8.991298999962765, 'eval_bleu_score_sem': 0.43653102332799065, 'eval_rouge_score': 0.027938635049161362, 'eval_exact_match': 0.002, 'eval_exact_match_sem': 0.002, 'eval_emb_cos_sim': 0.8601236343383789, 'eval_emb_cos_sim_sem': 0.011408127196644592, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_perplexity': 6.1304282471650735, 'eval_runtime': 28.3016, 'eval_samples_per_second': 17.667, 'eval_steps_per_second': 2.226}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/heb_Hebr_inversion_base.json
evaluating arb_Arab val_dataset
evaluating inversion base model
[pred] Ø§Ù„Ù…ØºØ±Ø¨ÙŠØ© Ù„ÙØ¹ÙØ±ÙØ¨ÙÙŠÙ’ Ù„ÙØ¹ÙØ±ÙØ¨ÙÙŠÙ’ Ù„ÙØ¹Ù’Ø±
[true] ÙØ³ØªØ§Ù† Ø²ÙØ§Ù Ø£Ù†ÙŠÙ‚ Ø¨Ù‚ØµÙ‘Ø© Ø§Ù„Ø£Ù…ÙŠØ±Ø© Ù…Ù† Ù†Ø³ÙŠØ¬ Ø§Ù„Ù…ÙŠÙƒØ§Ø¯ÙˆØŒ Ù…ÙØ²ÙŠÙ‘Ù† Ø¨Ø§Ù„Ø£Ø²Ù‡Ø§Ø± Ø§Ù„Ù†Ù‘Ø§Ø¹Ù…



[pred] Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±ÙŠ ÙÙŠ Ø§Ù„Ù…ØºØ±Ø¨ Ùˆ Ø§Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„Ø¬Ù…Ù‡ÙˆØ±ÙŠ ÙÙŠ Ø§Ù„Ù…ØºØ±Ø¨. ØªØ±Ø¬Ù…Ø© Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù„ØºØ©
[true] Ø±Ø¦ÙŠØ³ Ø§Ù„Ù‚Ù…Ø© Ø§Ù„Ø¯ÙŠÙ†ÙŠØ© Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¹Ø´Ø±ÙŠÙ† Ø§Ù„Ø´ÙŠØ® Ø¯.Ù…Ø­Ù…Ø¯ Ø§Ù„Ø¹ÙŠØ³Ù‰ ÙŠØ·Ù„Ù‚ Ù…Ù†ØµØ© R20 Ù…Ø¬Ù…ÙˆØ¹Ø© ØªÙˆØ§ØµÙ„



[pred] Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© ÙÙŠ Ø§Ù„Ù…ØºØ±Ø¨ Ùˆ Ø§Ù„Ù…ØºØ±Ø¨. Ø¬Ø§Ù…Ø¹Ø© Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© ÙÙŠ Ø§Ù„Ù…ØºØ±Ø¨ Ùˆ Ø§Ù„Ù…ØºØ±Ø¨. Ø¬Ø§Ù…Ø¹Ø©
[true] ØªØ³Ø¹Ù‰ ÙƒÙ„ÙŠØ© Ø§Ù„Ø¹Ù„ÙˆÙ… Ø§Ù„Ø¥Ø³Ù„Ø§Ù…ÙŠØ© Ø¥Ù„Ù‰ ØªØ¨ÙˆØ£ Ù…ÙƒØ§Ù†Ø© ÙˆØ³Ù…Ø¹Ø© Ù…Ø±Ù…ÙˆÙ‚Ø© Ø¨ÙŠÙ† Ø¬Ø§Ù…Ø¹Ø§Øª Ø§Ù„Ø¹Ø§Ù„Ù…ØŒ Ø¹Ø¨Ø± Ø§Ù„ØªØ¹Ø±ÙŠÙ
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434758/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434758
{'eval_loss': 5.106983184814453, 'eval_accuracy': 0.2088125, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.02087292497664012, 'eval_token_set_recall': 0.047710521667874574, 'eval_token_set_f1': 0.027526262460927875, 'eval_token_set_f1_sem': 0.0024471566041115622, 'eval_n_ngrams_match_1': 0.346, 'eval_n_ngrams_match_2': 0.006, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 14.93, 'eval_num_pred_words': 11.02, 'eval_bleu_score': 0.7870856485964, 'eval_bleu_score_sem': 0.08197261806615848, 'eval_rouge_score': 0.00016666666666666666, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7674503326416016, 'eval_emb_cos_sim_sem': 0.032077131367205323, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_perplexity': 165.171311171152, 'eval_runtime': 30.7825, 'eval_samples_per_second': 16.243, 'eval_steps_per_second': 2.047}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/arb_Arab_inversion_base.json
evaluating amh_Ethi val_dataset
evaluating inversion base model
[pred] Posted by ayolaz on × ×•×‘××‘×¨ 29, 2021 × ×•×‘××‘×¨ 29, 2021 × ×•×‘××‘×¨ 29, 2021 Leave a comment on ×—×“×©×•×ª 
[true] áˆ›áˆ­á‰½ 20, 2016 á‹¨áˆ«áˆµ á‹±áˆœáˆ« á‹°áˆ´á‰¶á‰½áŠ“ á‹¨á‰£áˆ…áˆ­ áŒá‹›á‰µ á‹¨áˆšá‹«áˆ³áŠ• á‹¨áŠ¤áˆ­á‰µáˆ«áŠ“



[pred] â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€
[true] áŠ áŠ•á‹µáŠá‰µ áŠ áŠ•á‹µáŠá‰µ á‹áˆµáŒ¥ áŒ¥áŠ•áŠ«áˆ¬ - á‹¨áˆ…á‰¥áˆ¨á‰µ áˆ›áˆ…á‰ áˆ¨áˆ°á‰¥ áŠ¥áŠ•áŠ­á‰¥áŠ«á‰¤ áŠ áŠ•á‹µáŠá‰µ



[pred] Alibaba.com Alibaba.com 1 x 1 x 2 x 3 x 4 x 4 x 5 x 6 
[true] áŠ¨á‰¡áŠ“áˆ›á‹á‰¹ áŒ‹áˆ­ áŠáŒˆ á‹ˆá‹° á‹©áŒ‹áŠ•á‹³ á‹¨áˆšá‹«á‰€áŠ‘ 20 á‰°áŒ«á‹‹á‰¾á‰½ á‰°áˆˆá‹­á‰°á‹ á‰³á‹á‰€
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434792/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434792
{'eval_loss': 9.299176216125488, 'eval_accuracy': 0.1676875, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.020186253615665374, 'eval_token_set_recall': 0.039851188076218354, 'eval_token_set_f1': 0.02446990173982251, 'eval_token_set_f1_sem': 0.0026926173331657173, 'eval_n_ngrams_match_1': 0.3, 'eval_n_ngrams_match_2': 0.008, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 11.006, 'eval_num_pred_words': 6.596, 'eval_bleu_score': 0.7765300893699985, 'eval_bleu_score_sem': 0.0770772926672534, 'eval_rouge_score': 0.006196564050162855, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.32028234004974365, 'eval_emb_cos_sim_sem': 0.03679383786762011, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 10929.01235468208, 'eval_runtime': 33.5011, 'eval_samples_per_second': 14.925, 'eval_steps_per_second': 1.881}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/amh_Ethi_inversion_base.json
evaluating mlt_Latn val_dataset
evaluating inversion base model
[pred] Archives of a few types of a few types of a few type of aluminum oxides. 
[true] DÄ§ul Temi Temi Problemi muskuloskeletali Practical tools and guidance - Musculoskeletal disorders L-Aw



[pred] - io-yi-oo-yi-oo-yi-oo-yi-oo-y
[true] test â€“ One News Mindu feÄ¡Ä¡ l-ewwel kaÅ¼ ta' coronavirus f'pajjiÅ¼na, saru aktar minn erba



[pred] - Alibaba.com - Alibaba.com - Alibaba.com - Alibaba.com - Alibaba.com 
[true] 'L-MFA emmnet lil min ibagÄ§bas il-logÄ§ob u mhux lili' - Illum.com.
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434821/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434821
{'eval_loss': 6.878897666931152, 'eval_accuracy': 0.1829375, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.04198040647003492, 'eval_token_set_recall': 0.23413119788708028, 'eval_token_set_f1': 0.06488358722812124, 'eval_token_set_f1_sem': 0.003912333531978025, 'eval_n_ngrams_match_1': 0.67, 'eval_n_ngrams_match_2': 0.014, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 13.258, 'eval_num_pred_words': 12.818, 'eval_bleu_score': 1.1606774179173929, 'eval_bleu_score_sem': 0.07036452537894773, 'eval_rouge_score': 0.009637274141849842, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.5443857908248901, 'eval_emb_cos_sim_sem': 0.043829279580642054, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_perplexity': 971.5547923124954, 'eval_runtime': 29.4779, 'eval_samples_per_second': 16.962, 'eval_steps_per_second': 2.137}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/mlt_Latn_inversion_base.json
evaluating hin_Deva val_dataset
evaluating inversion base model
[pred] Welcome to the page Welcome to the page Welcome to the page. Welcome to the page. Welcome to the page. Welcome to
[true] Blog News: à¤—à¤¼à¤²à¤¤à¥€ à¤¨ à¤•à¤°à¥‡ à¤®à¥à¤¸à¤²à¤®à¤¾à¤¨!!! à¤—à¤¼à¤²à¤¤à¥€ à¤¨ à¤•à¤°à¥‡ à¤®à¥à¤¸à¤²à¤®à¤¾à¤¨!!! Posted by DR



[pred] Welcome to Agoda.com Agoda.com Agoda.com Agoda.com Agoda.com Agoda.com Agoda.com
[true] RBSE Solutions for Class 9 Hindi Sparsh Chapter 11 à¤†à¤¦à¤®à¥€ à¤¨à¤¾à¤®à¤¾ - Rbse solutions RBSE Solutions for Class 9 Hindi Sparsh



[pred] Welcome to us Welcome to us Welcome to us Welcome to us Welcome to us Welcome to us 
[true] à¤¨à¤ˆ à¤¦à¤¿à¤²à¥à¤²à¥€, à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤‚à¤¤à¥à¤°à¥€ à¤¨à¤°à¥‡à¤‚à¤¦à¥à¤° à¤®à¥‹à¤¦à¥€ à¤•à¤¾ à¤•à¤¾à¤°à¥à¤¯à¤•à¤¾à¤² à¤ªà¥‚à¤°à¤¾ à¤¹à¥‹à¤¨à¥‡ à¤®à¥‡à¤‚ à¤•à¥‡à¤µà¤² 14 à¤®à¤¹à¥€à¤¨à¥‡ à¤•à¤¾ à¤µà¤•à¥à¤¤ à¤¬à¤¾à¤•à¥€ à¤°à¤¹ à¤—
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434852/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434852
{'eval_loss': 8.31383991241455, 'eval_accuracy': 0.157, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.018389438487358786, 'eval_token_set_recall': 0.035818255299911624, 'eval_token_set_f1': 0.022992823296414642, 'eval_token_set_f1_sem': 0.0026607370013065055, 'eval_n_ngrams_match_1': 0.41, 'eval_n_ngrams_match_2': 0.026, 'eval_n_ngrams_match_3': 0.004, 'eval_num_true_words': 16.83, 'eval_num_pred_words': 15.936, 'eval_bleu_score': 0.49170312280524825, 'eval_bleu_score_sem': 0.051793471200330496, 'eval_rouge_score': 0.01558470705938801, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.35920649766921997, 'eval_emb_cos_sim_sem': 0.023886729027727222, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 4079.949591978077, 'eval_runtime': 30.6533, 'eval_samples_per_second': 16.311, 'eval_steps_per_second': 2.055}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/hin_Deva_inversion_base.json
evaluating urd_Arab val_dataset
evaluating inversion base model
[pred] Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ. "×”Ö·
[true] Ù‚Ø§Ø¦Ø¯Ø§Ø¹Ø¸Ù… Ø³Û’ Ù†ÛØ±Ùˆ ØªÚ© Û”Û” Ø±Ø¤Ù Ú©Ù„Ø§Ø³Ø±Ø§ Ù…Ø±Ú©Ø²ÛŒ ØµÙØ­Û/ Ù„Ú©Ú¾Ø§Ø±ÛŒ/ Ø±Ø¤Ù Ú©Ù„Ø§



[pred] Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ Ø¹Ø±Ø¨ÙŠ 
[true] Ø³ÙˆÙ†Ø§Ú©Ø´ÛŒ Ø³Ù†ÛØ§ Ø³ÙˆØ´Ù„ Ù…ÛŒÚˆÛŒØ§ Ù…ÛŒÙ…Ø² Ú©Û’ Ù†Ø´Û’ Ù…ÛŒÚº Ù…Ø¨ØªÙ„Ø§ ÛÙˆ Ú¯Ø¦ÛŒÚº Ø§Ø¯Ø§Ú©Ø§Ø±Û Ù†Û ØµØ±Ù Ø®ÙˆØ¯ Ù…ÛŒÙ…Ø² 



[pred] æ—¥æœ¬èªä¸­æ–‡æ—¥æœ¬èªä¸­æ–‡í•œêµ­ì–´ä¸­æ–‡æ—¥æœ¬èªä¸­æ–‡í•œêµ­ì–´LietuviÅ³LatvieÅ¡uĞ ÑƒÑÑĞºĞ¸Ğ¹NederlandsTÃ¼rkÃ§ePortuguÃªsæ—¥æœ¬èªä¸­æ–‡í•œêµ­ì–´ä¸­æ–‡ç¹é«”ä¸­æ–‡í•œêµ­ì–´LietuviÅ³LatvieÅ¡uMelayuNederlandsPolskiPortuguÃªs
[true] Ù†Ø¦ÛŒ Ø¯ÛÙ„ÛŒ:Ù…ÛØ§Ø±Ø§Ø´Ù¹Ø± Ù…ÛŒÚº Ú¯Ø²Ø´ØªÛ 5 Ø³Ø§Ù„ÙˆÚº Ù…ÛŒÚº (18-2014)14034 Ú©Ø³Ø§Ù†ÙˆÚº Ù†Û’ Ø®ÙˆØ¯Ú©Ø´ÛŒ Ú©ÛŒ ÛÛ’Û”
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434887/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434887
{'eval_loss': 7.244534492492676, 'eval_accuracy': 0.169875, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.010655433163327897, 'eval_token_set_recall': 0.04321363636363634, 'eval_token_set_f1': 0.01666375032987975, 'eval_token_set_f1_sem': 0.0019941630107461732, 'eval_n_ngrams_match_1': 0.182, 'eval_n_ngrams_match_2': 0.002, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 16.742, 'eval_num_pred_words': 14.61, 'eval_bleu_score': 0.3491734564548886, 'eval_bleu_score_sem': 0.04844816137162989, 'eval_rouge_score': 0.0005517241379310345, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.44035738706588745, 'eval_emb_cos_sim_sem': 0.02495358956990545, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 1400.429833616174, 'eval_runtime': 35.0546, 'eval_samples_per_second': 14.263, 'eval_steps_per_second': 1.797}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/urd_Arab_inversion_base.json
evaluating guj_Gujr val_dataset
evaluating inversion base model
[pred] â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€
[true] 'àª…àª®àª¾àª°àª¾ àªµàª¿àª°à«‹àª§à«€àª¨à«‡ àª²àª—à«àª¨àª®àª¾àª‚ àª•à«‡àª® àª¬à«‹àª²àª¾àªµà«àª¯à«‹?' àª•àª¹à«€ àª•àª¨à«àª¯àª¾àª¨àª¾ àª®àª¾-àª¬àª¾àªª àªªàª° àª¹



[pred] Posted by aoi_hao_hao_hao_hao_hao_hao_hao_hao
[true] àª†àªœà«‡ àª¸àª¾àª‚àªœàª¥à«€ àª•à«‡àªœàª°à«€àªµàª¾àª²àª¨à«€ àª—à«àªœàª°àª¾àª¤ àª¯àª¾àª¤à«àª°àª¾ àª¶àª°à«‚, àªœàª¾àª£à«‹ àª†àª–à«‹ àª•àª¾àª°à«àª¯àª•à«àª°àª® | Read here Arvind kej



[pred] Posted by aoi_haisha_haisha_haisha_haisha_haisha_haisha_haisha_haisha
[true] àª«àª°àª¹àª¾àª¨àª¨à«€ àª¡à«‰àª¨ 3àª®àª¾àª‚ àªœà«‹àªµàª¾ àª®àª³àª¶à«‡ àª—à«àªœàª°àª¾àª¤à«€ àª¶àª¾àª¹àª°à«àª– àª–àª¾àª¨ | Shahrukh Kahn Back As 
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434916/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434916
{'eval_loss': 11.16832160949707, 'eval_accuracy': 0.1250625, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.024224944164882245, 'eval_token_set_recall': 0.07318352810759932, 'eval_token_set_f1': 0.033853766472941194, 'eval_token_set_f1_sem': 0.0029446126363032103, 'eval_n_ngrams_match_1': 0.374, 'eval_n_ngrams_match_2': 0.006, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 12.404, 'eval_num_pred_words': 7.324, 'eval_bleu_score': 0.8751401373258152, 'eval_bleu_score_sem': 0.07857922294466947, 'eval_rouge_score': 0.0047364678031006635, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.39708203077316284, 'eval_emb_cos_sim_sem': 0.06357569187147735, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_perplexity': 70850.09666626452, 'eval_runtime': 28.8704, 'eval_samples_per_second': 17.319, 'eval_steps_per_second': 2.182}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/guj_Gujr_inversion_base.json
evaluating sin_Sinh val_dataset
evaluating inversion base model
[pred] â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€
[true] à¶¸à·’à¶±à·’à·ƒà·Šà·ƒà·” | à¶‡à·€à·’à¶¯ à¶ºà¶± à¶¸à¶Ÿ â† à¶œà¶»à·” à¶šà·’à¶»à·“à¶¸ à¶œà·”à¶»à·”à·€à¶»à·” â†’ 16 à¶…à¶´à·Š à¶»à·šà¶½à·Š à¶…à¶´à·’à¶§ à¶šà·™à¶±à·™à¶šà·Š à¶¯à·à¶šà·Šà¶šà·à¶¸ à¶†à¶šà¶»à·Šà·à¶±à¶ºà¶šà·Š



[pred] Posted by aaisha_admin on July 22, 2021 @ 12:53 pm | Posted in ×—×“×©×•×ª | Tags: covid-19, COVID
[true] à·ƒà·’à·€à·”à¶¸à·à¶½à·’à¶ºà· à·ƒà·’à¶šà·”à¶»à·” à¶½à·’à¶ºà·... | Sunday Apple à·ƒà·’à·€à·”à¶¸à·à¶½à·’à¶ºà· à·ƒà·’à¶šà·”à¶»à·” à¶½à·’à¶ºà·... March 24, 2017 | 11:00 am 0 527 à·ƒà·Š



[pred] Posted by ayoli_haisha_haisha_haisha_haisha_haisha_haisha_haisha_haisha_
[true] à¶±à·’à·…à·’à¶šà¶¸à¶§ à¶¸à·à¶¯à·’ à·€à·”à¶«à·š à¶´à·”à¶‚à¶ à·’ à¶šà·™à¶½à·Šà¶½à¶š à¶šà·à¶½à·š... - Sri Lanka News Update à¶±à·’à·…à·’à¶šà¶¸à¶§ à¶¸à·à¶¯à·’ à·€à·”à¶«à·š
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434946/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434946
{'eval_loss': 10.362955093383789, 'eval_accuracy': 0.139625, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.0302527775286289, 'eval_token_set_recall': 0.08064274695892341, 'eval_token_set_f1': 0.039761905752784384, 'eval_token_set_f1_sem': 0.0032387361779358326, 'eval_n_ngrams_match_1': 0.504, 'eval_n_ngrams_match_2': 0.032, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 14.062, 'eval_num_pred_words': 8.454, 'eval_bleu_score': 1.6838095008209844, 'eval_bleu_score_sem': 0.16706937698198523, 'eval_rouge_score': 0.014643877082578628, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.4087628722190857, 'eval_emb_cos_sim_sem': 0.05906242294046858, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_perplexity': 31664.615096318492, 'eval_runtime': 30.6593, 'eval_samples_per_second': 16.308, 'eval_steps_per_second': 2.055}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/sin_Sinh_inversion_base.json
evaluating pan_Guru val_dataset
evaluating inversion base model
[pred] â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€â˜€
[true] à¨•à¨°à©‹à¨¨à¨¾ à¨®à¨¹à¨¾à¨‚à¨®à¨¾à¨°à©€ à¨¦à©‡ à¨šà©±à¨²à¨¦à©‡ à¨«à©‹à¨Ÿà©‹à¨—à©à¨°à¨¾à¨«à¨° à¨¦à©€à¨†à¨‚ à¨¬à©°à¨¦ à¨ªà¨ˆà¨†à¨‚ à¨¦à©à¨•à¨¾à¨¨à¨¾à¨‚ à¨–à©‹à¨²à©à¨¹à¨£ 



[pred] Alibaba.com / Alibaba.com / Alibaba.com / ××•×¦×¨×™ ×¨×¤×•××” ××©×œ×™××” - CBD 
[true] à¨®à©‹à¨¦à©€ à¨¦à©‡ à¨¸à©à¨ªà¨¨à¨¿à¨†à¨‚ à¨¦à¨¾ à¨¯à©‚ à¨ªà©€ à¨¬à¨£à¨¾à¨‰à¨£ à¨²à¨ˆ à¨•à¨µà¨¾à¨‡à¨¦ à¨†à¨°à©°à¨­ - PanjabiLok.



[pred] Posted by aoi_wang_wang_wang_wang_wang_wang_wang_wang_wang_wang_wang_wang
[true] à¨¸à¨¼à¨¹à©€à¨¦à¨¾à¨‚ à¨¦à©€à¨†à¨‚ à¨¤à¨¸à¨µà©€à¨°à¨¾à¨‚ à¨…à¨œà¨¾à¨‡à¨¬ à¨˜à¨° 'à¨š à¨²à¨—à¨¾à¨‰à¨£ à¨¦à©€ à¨®à©°à¨— : The Tribune
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434981/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720434981
{'eval_loss': 10.035463333129883, 'eval_accuracy': 0.152875, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.021117327727312236, 'eval_token_set_recall': 0.05830863919362369, 'eval_token_set_f1': 0.028821943707356617, 'eval_token_set_f1_sem': 0.0027999847547307876, 'eval_n_ngrams_match_1': 0.31, 'eval_n_ngrams_match_2': 0.02, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 12.258, 'eval_num_pred_words': 7.442, 'eval_bleu_score': 0.6980940885090008, 'eval_bleu_score_sem': 0.10625551751075833, 'eval_rouge_score': 0.00803005698005698, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.3191417455673218, 'eval_emb_cos_sim_sem': 0.026420299898084563, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 22821.613652719076, 'eval_runtime': 34.8796, 'eval_samples_per_second': 14.335, 'eval_steps_per_second': 1.806}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/pan_Guru_inversion_base.json
evaluating tur_Latn val_dataset
evaluating inversion base model
[pred] iCii iCii iCii iCii iCii iCii 
[true] tek parti devri TEK PARTÄ° DEVRÄ° haberleri haber haberi | Sayfa 7 Tek parti chp zamanÄ±nda yapÄ±lan... 15 Åubat 2015, 



[pred] ××ª×¨ ××™× ×˜×¨× ×˜ ibrahimi ahmadi ahmadi ahmadi ahmadi ahmadi ahmadi ahmadi ahmad
[true] Anasayfa Spor FenerbahÃ§e-Dinamo Zagreb maÃ§Ä±nÄ±n hakemleri aÃ§Ä±klandÄ± kaynuka Tarih: 2018-11-27 Saat: 15:07:19 GÃ¼ncelleme 



[pred] ××ª×¨ e-commerce e-commerce i-commerce i-commerce i-commerce i-commerce i-commerce 
[true] AlÄ±ÅŸveriÅŸ Annelik Bebek Ã‡ocuk Ã‡ocuk KitaplarÄ± EÄŸitim SaÄŸlÄ±k 7â€“14 yaÅŸ Ã§ocuklar iÃ§in Ã¶ÄŸretim metodlarÄ± aktif dinleme
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435009/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435009
{'eval_loss': 7.1873016357421875, 'eval_accuracy': 0.181, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.018792272665415062, 'eval_token_set_recall': 0.059360217560217525, 'eval_token_set_f1': 0.027008366634424786, 'eval_token_set_f1_sem': 0.0025341981525674653, 'eval_n_ngrams_match_1': 0.332, 'eval_n_ngrams_match_2': 0.014, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 16.296, 'eval_num_pred_words': 12.066, 'eval_bleu_score': 0.7556482594948631, 'eval_bleu_score_sem': 0.06582940687488206, 'eval_rouge_score': 0.011055484272251037, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.43826788663864136, 'eval_emb_cos_sim_sem': 0.021041650800025864, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 1322.5297195668, 'eval_runtime': 27.6524, 'eval_samples_per_second': 18.082, 'eval_steps_per_second': 2.278}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/tur_Latn_inversion_base.json
evaluating kaz_Cyrl val_dataset
evaluating inversion base model
[pred] Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Ğ ÑƒÑÑĞºĞ¸Ğ¹ 
[true] ÒšĞœĞ“ ĞĞ›Ğ¢Ğ«Ğ Ğ•Ğ Ğ•Ğ–Ğ•Ğ›Ğ•Ğ Ğ† - Ğ•Ò¢Ğ±ĞµĞº Ò›Ğ°ÑƒÑ–Ğ¿ÑÑ–Ğ·Ğ´Ñ–Ğ³Ñ– Ğ¶Ó™Ğ½Ğµ ĞµÒ£Ğ±ĞµĞºÑ‚Ñ– Ò›ĞĞ Ò’Ğ°Ñƒ Ğ¶Ğ¸Ğ½Ğ°Ğ»Ñ‹ÑÑ‚Ğ°Ñ€Ñ‹Ğ½ Ğ¶Ò¯Ñ€Ğ³Ñ–Ğ·Ğ³Ğµ Ğ°Ñ€



[pred] ĞšÑƒĞ¿Ğ¸Ñ‚ÑŒ ĞºÑƒĞ¿Ğ¾Ğ½ Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ. Ğ”Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ. Ğ”Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ° Ğ´Ğ»Ñ Ğ¸Ğ½Ğ¾ÑÑ‚Ñ€Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ² Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚Ğµ
[true] Ğ¿ÑĞ¸Ñ…Ğ¾Ğ¼ĞµÑ‚Ñ€Ğ¸ÑĞ»Ñ‹Ò› Ñ‚ĞµÑÑ‚Ñ–Ğ»ĞµÑƒ ĞºĞµÑÑ‚ĞµÑÑ– Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼Ñƒ Ğ°Ğ¿ĞµĞ»Ğ»ÑÑ†Ğ¸ÑĞ»Ñ‹Ò› Ğ²ĞµĞ´Ğ¾Ğ¼Ğ¾ÑÑ‚ÑŒ 18.10.2018 Ğ¶ No 578 Ğ±Ò±Ğ¹Ñ€Ñ‹Ò“Ñ‹Ğ½Ğ° Ó©Ğ·Ğ³ĞµÑ€Ñ–ÑÑ‚ĞµÑ€



[pred] - Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ñ€ÑƒÑÑĞºĞ¸Ğ¹. - Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ
[true] Ğ«Ğ±Ñ‹Ñ€Ğ°Ğ¹ ĞĞ»Ñ‚Ñ‹Ğ½ÑĞ°Ñ€Ğ¸Ğ½ - Ğ« - Ò°Ğ»Ñ‹ Ğ·Ğ°Ğ¼Ğ°Ğ½ Ğ¢Ò±Ğ»Ò“Ğ°Ğ»Ğ°Ñ€Ñ‹ - Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ğ ĞµÑ„ĞµÑ€Ğ°Ñ‚Ñ‹, ÑĞ»Ğ°Ğ¹Ğ´Ñ‹,
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435038/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435038
{'eval_loss': 7.026938438415527, 'eval_accuracy': 0.1755, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.03474367139568379, 'eval_token_set_recall': 0.0992043401043402, 'eval_token_set_f1': 0.04714356622230444, 'eval_token_set_f1_sem': 0.003437569200522791, 'eval_n_ngrams_match_1': 0.606, 'eval_n_ngrams_match_2': 0.042, 'eval_n_ngrams_match_3': 0.032, 'eval_num_true_words': 14.778, 'eval_num_pred_words': 13.782, 'eval_bleu_score': 1.2665401665180966, 'eval_bleu_score_sem': 0.1098312541715867, 'eval_rouge_score': 0.003435049917402859, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.5740879774093628, 'eval_emb_cos_sim_sem': 0.04380267438251956, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 1126.5762424589068, 'eval_runtime': 28.8257, 'eval_samples_per_second': 17.346, 'eval_steps_per_second': 2.186}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/kaz_Cyrl_inversion_base.json
evaluating cmn_Hani val_dataset
evaluating inversion base model
[pred] Alibaba.com Alibaba.com Alibaba.com Alibaba.com Alibaba.com Alibaba.com Alibaba.com Alibaba.
[true] ä¸‹è¡Œä»¥åŠç°è´§æˆäº¤åå¼±æ‹–ç´¯,å¸‚åœºä¸»å¯¼åœ°åŒºä»·æ ¼ç»§ç»­å¿«é€Ÿè°ƒä½,é‚¯éƒ¸ä¸­æ¿ä»·æ ¼é‡å¿ƒä¸‹ç§»



[pred] ğŸ’ Myanmar Arabic Arabic Armenian Azerbaijani Basque Arabic Arabic Armenian Azerbaijani Basque Arabic Arabic 
[true] æ¯æ—¥å½©ç¥¨ çç æ£‰çš„åŒ…è£…å®šä½æ˜¯ä¸€ç§å…·æœ‰é«˜å¼ºçš„ç¼“å†²å¸éœ‡æŠ—éœ‡ä½œç”¨çš„æœ‰æ˜æ˜¾ç¯ä¿æ•ˆåŠ›çš„åŒ…è£…æ–¹å¼ã€‚ç”±äº



[pred] ğŸ’ Taipei Chinese New Year 2021 Arabic Arabic Arabic Armenian Armenian Azerbaijani Basque Italiano æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª
[true] ç«å¸äº‘äºä¸Šä¸ªæœˆåˆšåˆšæ¨å‡º,å…è®¸ç”¨æˆ·å¼€å‘ä»–ä»¬è‡ªå·±çš„ç±»ä¼¼ç«å¸ç½‘çš„æ•°å­—è´§å¸äº¤æ˜“å¹³å°,å…¶ä¸­åŒ…æ‹¬é’±åŒ…ã€èµ„äº§
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435070/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435070
{'eval_loss': 7.633476734161377, 'eval_accuracy': 0.136625, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.890625, 'eval_token_set_precision': 0.03919472520943106, 'eval_token_set_recall': 0.049909090909090875, 'eval_token_set_f1': 0.04037340954554036, 'eval_token_set_f1_sem': 0.0038660074238027857, 'eval_n_ngrams_match_1': 0.39, 'eval_n_ngrams_match_2': 0.006, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 6.336, 'eval_num_pred_words': 14.944, 'eval_bleu_score': 0.5751796601374943, 'eval_bleu_score_sem': 0.05193884860154569, 'eval_rouge_score': 0.0012478254459678609, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.2882682681083679, 'eval_emb_cos_sim_sem': 0.03019255347528692, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 2066.2212483853073, 'eval_runtime': 31.8944, 'eval_samples_per_second': 15.677, 'eval_steps_per_second': 1.975}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/cmn_Hani_inversion_base.json
evaluating jpn_Jpan val_dataset
evaluating inversion base model
[pred] Posted by Jennifer Lopez in Uncategorized and tagged paintings paintings paintings paintings paintings paintings painting
[true] èŠ±ç«‹å±±è˜ã§ã¯å¤œåŠã‹ã‚‰é›¨ãŒé™ã‚Šç¶šã„ã¦ã„ã¦ã€æœã«ã¡ã‚‡ã£ã¨ã ã‘é›¨è„šãŒå¼±ããªã£ãŸã¨ãã«å‡ºç™ºã€‚ ã—ã°ã‚‰ãã¯éœ§ã®ä¸­



[pred] æ—¥æœ¬èª English æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´
[true] ä»Šã‚·ãƒ¼ã‚ºãƒ³åˆã®å‡çµã—ãŸæ¡§åŸæ¹–ã®æ¹–ä¸Šæ’®å½±ã§ã™ã€‚ ã‹ãªã‚Šçµæ°·ã¯é€²ã‚“ã§ã„ã¾ã—ãŸãŒã€ã¾ã ãƒ¯ã‚«ã‚µã‚®ç©´é‡£ã‚Šã¯



[pred] æ—¥æœ¬èª English æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´
[true] ã¾ãšå°‘ãªãã¨ã‚‚ã“ã®äººãŸã¡ãƒãƒ¼ãƒ ã«ãƒãƒƒãƒˆå‘¨ã‚ŠãŒå¼·ã„äººé–“ãŒã„ã‚‹ã“ã¨ã¯é–“é•ã„ãªãã¦ã€YouTubeã®ãƒ¡ã‚¿ã‚¿ã‚°(ãƒ¡ã‚¿ã‚¿ã‚°ã£ã¦?ã£ã¦äººã¯ã“ã®è¨˜äº‹ã‚’ã©ã†ã)
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435101/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435101
{'eval_loss': 8.624513626098633, 'eval_accuracy': 0.1000625, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.009736147186147185, 'eval_token_set_recall': 0.009846532999164579, 'eval_token_set_f1': 0.009158628190981132, 'eval_token_set_f1_sem': 0.00222845557533802, 'eval_n_ngrams_match_1': 0.092, 'eval_n_ngrams_match_2': 0.0, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 3.166, 'eval_num_pred_words': 15.434, 'eval_bleu_score': 0.19794114129673301, 'eval_bleu_score_sem': 0.07333742907304781, 'eval_rouge_score': 0.0006372688477951636, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.48497113585472107, 'eval_emb_cos_sim_sem': 0.033429995155022416, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 5566.4546717846815, 'eval_runtime': 30.877, 'eval_samples_per_second': 16.193, 'eval_steps_per_second': 2.04}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/jpn_Jpan_inversion_base.json
evaluating kor_Hang val_dataset
evaluating inversion base model
[pred] Updated on October 10, 2021. Updated on October 10, 2021. Warning: Invalid argument = "https://www.fertility.
[true] ì„¸ì¼ ì¤‘ â€“ Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price %}{{



[pred] ĞšĞ½Ğ¸Ğ³Ğ¸ Ğ½Ğ° ĞºĞ°Ğ·Ğ°Ñ…ÑĞºĞ¾Ğ¼ Ğ¸ Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ø¹Ø±Ø¨ÙŠ Ğ ÑƒÑÑĞºĞ¸Ğ¹ Italiano Ğ ÑƒÑÑĞºĞ¸Ğ¹ Italiano Ğ ÑƒÑÑĞºĞ¸Ğ¹ Italiano Ğ ÑƒÑÑĞºĞ¸Ğ¹ Italiano Ğ ÑƒÑÑĞºĞ¸Ğ¹
[true] ì‹ ìš©ìœ„í—˜ ê²°ì •ìš”ì¸ ê³¼ ê´€ë ¨ - í† í† ì‚¬ì´íŠ¸ ê²€ì¦ì‚¬ì´íŠ¸ ë©”ì´ì €í† í† ì‚¬ì´íŠ¸ - í† í† íƒì • - ì‹ ìš©ìœ„í—˜



[pred] Arabic Arabic Armenian Azerbaijani Basque Arabic Bahasa Indonesia Bahasa Indonesia Bahasa Indonesia Bahasa Indonesia Bahasa Indonesia Bahasa Indonesia
[true] ì•ˆë“œë¡œì´ë“œ : ì‚¼ì„±ë°”ë‹¤í° ì˜êµ­ ì˜¨ë¼ì¸ ë“±ë¡ - íƒ€ì´ì   - ì•ˆë“œë¡œì´ë“œ ìŠ¤ë§ˆíŠ¸í°ê³¼ íƒœë¸”ë¦¿ ìƒˆë¡œìš´ ì†Œ
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435129/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435129
{'eval_loss': 8.060479164123535, 'eval_accuracy': 0.1668125, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.013237907637598039, 'eval_token_set_recall': 0.02882171717171717, 'eval_token_set_f1': 0.01727841338273331, 'eval_token_set_f1_sem': 0.002649681572000532, 'eval_n_ngrams_match_1': 0.25, 'eval_n_ngrams_match_2': 0.028, 'eval_n_ngrams_match_3': 0.016, 'eval_num_true_words': 13.578, 'eval_num_pred_words': 14.918, 'eval_bleu_score': 0.39869156996436744, 'eval_bleu_score_sem': 0.0830316108219698, 'eval_rouge_score': 0.003542886232541405, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.383232980966568, 'eval_emb_cos_sim_sem': 0.049683516351475714, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 3166.807191260754, 'eval_runtime': 28.2146, 'eval_samples_per_second': 17.721, 'eval_steps_per_second': 2.233}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/kor_Hang_inversion_base.json
evaluating mon_Cyrl val_dataset
evaluating inversion base model
[pred] ĞŸĞ¾Ğ·Ğ´Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ Ğ’Ğ°Ğ»ĞµĞ½Ñ‚Ğ¸Ğ½Ğ¾Ğ¼ Ğ’Ğ°Ğ»ĞµĞ½Ñ‚Ğ¸Ğ½Ğ¾Ğ¼ Ğ’Ğ°Ğ»ĞµĞ½Ñ‚Ğ¸Ğ½Ğ¾Ğ¼ Ğ’Ğ°Ğ»ĞµĞ½Ñ‚Ğ¸Ğ½Ğ¾Ğ²Ğ¸Ñ‡ - ĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ñ†Ğ²ĞµÑ‚, ĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¹ Ñ†Ğ²ĞµÑ‚. Ğ¤Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ Ğ¸
[true] ĞĞ»Ñ‚Ğ½Ñ‹ Ğ¾Ğ»Ğ±Ğ¾Ñ€Ğ»Ğ¾Ğ»Ñ‚ Ğ°Ğ¼Ğ¶Ğ¸Ğ»Ñ‚Ğ°Ğ´ Ñ…Ò¯Ñ€Ğ½Ñ ĞĞ¥Ğ£Ñ‹Ğ½ Ğ³Ğ°Ğ´Ğ°Ğ°Ğ´ Ó©Ñ€ 56 Ñ‚ÑÑ€Ğ±ÑƒĞ¼ Ğ°Ğ¼.Ğ´Ğ¾Ğ»Ğ»Ğ°Ñ€ Ğ±Ğ¾Ğ»Ğ¶ Ó©ÑÑ‡ÑÑ. Ğ­Ğ½Ñ



[pred] ĞšÑƒĞ¿Ğ¸Ñ‚ÑŒ ĞĞ¾ÑƒÑ‚Ğ±ÑƒĞº Ğ´Ğ»Ñ iPhone 6s plus iPhone 6s plus iPhone 6s plus iPhone 6s plus iPhone 6s plus iPhone 6s plus iPhone
[true] Google Ğ¢ĞµĞºÑÑ‚Ğ¸Ğ¹Ğ½ Ğ·Ğ°Ñ€Ñ‹Ğ½ Ó©Ó©Ñ€Ñ‡Ğ»Ó©Ğ»Ñ‚Ğ¸Ğ¹Ğ³ Ğ°Ğ½Ñ…Ğ°Ğ°Ñ€Ñ‡ Ò¯Ğ·ÑÑ… 3 Ğ·Ò¯Ğ¹Ğ» | Martech Zone Google Ğ¢ĞµĞºÑÑ‚Ğ¸Ğ¹Ğ½ Ğ·Ğ°Ñ€Ñ‹Ğ½ Ó©Ó©Ñ€Ñ‡Ğ»Ó©Ğ»Ñ‚



[pred] 88 (ĞÌÌÑ€ÌÑÌÌÑ€ÌÑÌÌÑ€ÌÑÌÌÑ€ÌÑÌÌ) 88 (Ğ
[true] Â» Ğ¡Ğ•ĞšĞ¡ (1085550) Â» Ğ¨ĞĞ  ĞœĞ­Ğ”Ğ­Ğ­ (805751) Â» Ó¨Ğ“Ò®Ò®Ğ›Ğ›Ğ­Ğ“ (906359) Ñ…Ó©Ğ»Ğ¸Ğ¹Ğ³ Ğ½ÑŒ Ñ…ÑƒĞ³Ğ°Ğ»Ğ°Ğ½
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435167/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435167
{'eval_loss': 7.51076078414917, 'eval_accuracy': 0.1339375, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.01808213028801263, 'eval_token_set_recall': 0.05487206682206681, 'eval_token_set_f1': 0.02515767301224195, 'eval_token_set_f1_sem': 0.0026420385300223513, 'eval_n_ngrams_match_1': 0.278, 'eval_n_ngrams_match_2': 0.006, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 13.308, 'eval_num_pred_words': 13.012, 'eval_bleu_score': 0.9906890677210463, 'eval_bleu_score_sem': 0.06584025790647072, 'eval_rouge_score': 0.0031997427859496827, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.5338140726089478, 'eval_emb_cos_sim_sem': 0.058866250434074625, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 1827.6034257664044, 'eval_runtime': 38.5057, 'eval_samples_per_second': 12.985, 'eval_steps_per_second': 1.636}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/mon_Cyrl_inversion_base.json
evaluating hun_Latn val_dataset
evaluating inversion base model
[pred] a a a a a a a a a a a a a a a 
[true] Ultrahang kezelÃ©s: FÃ¡jdalomcsillapÃ­tÃ¡s tÅ±szÅ±rÃ¡s nÃ©lkÃ¼l [teljes ÃºtmutatÃ³] ÃzÃ¼leti fÃ¡jdalom fonoforÃ©zis



[pred] ............... 
[true] Az Ãºj Mike Tyson | SamanSport.hu 2019. 12. 13., PÃ©ntek, 18:40 Gervonta "Tank" Davis hatalmas attrakciÃ³



[pred] - iHerb - a journey to the truth - iHerb - a journey to the 
[true] JÃ¡rmÅ±vek | Hobbi ZÃ³na - Part 2 TankChair â€“ az Off Road tolÃ³szÃ©k A rendkÃ­vÃ¼li gÃ©pezet, egy "
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435196/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435196
{'eval_loss': 7.299790859222412, 'eval_accuracy': 0.1908125, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.037034212588237324, 'eval_token_set_recall': 0.15852805527805539, 'eval_token_set_f1': 0.05482142457340276, 'eval_token_set_f1_sem': 0.0033649479573515727, 'eval_n_ngrams_match_1': 0.712, 'eval_n_ngrams_match_2': 0.014, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 15.884, 'eval_num_pred_words': 10.442, 'eval_bleu_score': 1.2722593800422393, 'eval_bleu_score_sem': 0.06309031832615987, 'eval_rouge_score': 0.017438745051023753, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.49055397510528564, 'eval_emb_cos_sim_sem': 0.039876950958998875, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_perplexity': 1479.9903688784295, 'eval_runtime': 29.1809, 'eval_samples_per_second': 17.134, 'eval_steps_per_second': 2.159}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/hun_Latn_inversion_base.json
evaluating mhr_Cyrl val_dataset
evaluating inversion base model
[pred] - ĞšÑƒĞ¿Ğ¸Ñ‚ÑŒ ĞºĞ¾ÑĞ¼ĞµÑ‚Ğ¸ĞºÑƒ, Ğ´Ğ»Ñ Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ×™×œ×“×™×, Ğ´Ğ»Ñ Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ñ ×™×œ×“×™×. - ĞšÑƒĞ¿Ğ¸Ñ‚ÑŒ ĞºĞ¾ÑĞ¼ĞµÑ‚Ğ¸ĞºÑƒ, 
[true] Ğ¢ÑƒÑ€Ğ³Ñ‹Ğ¼ Ğ¶Ğ°Ğ¿Ñ‹ÑˆÑ‚Ğµ, ÑˆĞ¾ÑˆĞ¾ Ğ°Ğ³Ğ° Ğ³Ğ¾Ğ´Ñ‹Ğ¼, ĞºĞµÑ‡ Ğ¸Ğº Ğ³Ğ°Ğ½Ğ° ĞšÑƒĞ³Ñƒ ĞšĞ°Ñ‡Ğ°Ğº ÑĞ»Ñ‹ÑˆÑ‚Ğµ Ğ»Ğ¸ÑÑˆ Ñ‚Ñ‹Ñ€ÑˆĞµĞ¼



[pred] Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ. Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ - 
[true] ĞœĞ¾ Ñ‚Ñ‹Ğ³Ğ°Ğ¹ ĞĞ³Ğ°Ğ²Ğ°Ğ¹Ñ€ĞµĞ¼? ĞšÑƒĞ·Ğµ Ñ‚ÑƒĞ´Ğ¾ ÑÑ€Ñ‚Ğ°? Ğ¢Ğ¸Ğ´Ğµ Ğ´Ğ° Ğ¼Ğ¾Ğ»Ğ¾ Ğ¹Ğ¾Ğ´Ñ‹ÑˆĞ»Ğ°Ğ½ Ğ²Ğ°ÑˆĞ¼ÑƒÑ‚Ñ‹Ğ¼ ĞœĞ°Ñ€Ğ¸Ğ¹ Ğ²Ğ¸ĞºĞ¸Ğ¿ĞµĞ´Ğ¸Ğ¹Ñ‹ÑˆÑ‚Ğµ



[pred] Ğ¤Ğ¸Ğ»ÑŒĞ¼Ñ‹ Ğ¾ ĞŸÑƒÑ‚Ğ¸Ğ½Ğµ - Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ Ğ›ÑƒÑ‡ÑˆĞµĞµ. Ğ›ÑƒÑ‡
[true] ĞšĞ¾Ñ€ÑĞº Ñ€Ğ²ĞµĞ·Ğµ ĞŸÑ‘Ñ‚Ñ€ ĞĞµÑÑ‚ĞµÑ€Ğ¾Ğ² Ğ´ĞµĞ½Ğµ Ğ¼Ñ‹Ğ¹ ĞĞ°Ñ€Ğ¾-Ğ¤Ğ¾Ğ¼Ğ¸Ğ½ÑĞº Ğ¾Ğ»Ğ°ÑˆÑ‚Ğµ ÑÑ€Ñ‚Ñ‹ÑˆĞµ Â«ĞŸĞ¾ĞºĞ¾Ğ»ĞµĞ½Ğ¸ĞµÂ»
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435225/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435225
{'eval_loss': 7.657943248748779, 'eval_accuracy': 0.11325, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.03835798466239642, 'eval_token_set_recall': 0.09467560217560228, 'eval_token_set_f1': 0.05089131875304104, 'eval_token_set_f1_sem': 0.003049835787902138, 'eval_n_ngrams_match_1': 0.558, 'eval_n_ngrams_match_2': 0.002, 'eval_n_ngrams_match_3': 0.0, 'eval_num_true_words': 13.03, 'eval_num_pred_words': 13.06, 'eval_bleu_score': 1.5905233989795733, 'eval_bleu_score_sem': 0.06674372674490918, 'eval_rouge_score': 0.0011870967741935484, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.7084029912948608, 'eval_emb_cos_sim_sem': 0.030837368647367216, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_perplexity': 2117.397986013715, 'eval_runtime': 28.9774, 'eval_samples_per_second': 17.255, 'eval_steps_per_second': 2.174}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/mhr_Cyrl_inversion_base.json
evaluating fin_Latn val_dataset
evaluating inversion base model
[pred] ×‘×—×¨ ××§×•× ×‘×—×¨ ××§×•× ×‘×—×¨ ××§×•× ×‘×—×¨ ××§×•× ×‘×—×¨ ××§×•× ×‘×—×¨ ××§×•× ×‘×—×¨ ××§×•×, ×‘×—×¨
[true] Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. TyÃ¶ympÃ¤ristÃ¶ muutos hankkeissa tuotetaan myÃ¶s valtava



[pred] æ—¥æœ¬èª æ—¥æœ¬èª í•œêµ­ì–´ æ—¥æœ¬èª í•œêµ­ì–´ LietuviÅ³ Kalba Tiáº¿ng Viá»‡t Tiáº¿ng Viá»‡t Tiáº¿ng Viá»‡t Tiáº¿ng Viá»‡t Tiáº¿ng Viá»‡t Tiáº¿ng
[true] Pohjois-suomalaisuus ja kaikille arvokas elÃ¤mÃ¤ - siinÃ¤ tavoitteet toiminnalle. TyÃ¶skentelen Diakonia-ammattikorkeakoulussa



[pred] aeeeeeeeeeeeeeeeeeeeeeeeeeeeee
[true] Kun kirjoitimme koivunjalojen lÃ¤Ã¤ketieteellisistÃ¤ ominaisuuksista, mainitsimme, ettÃ¤ paitsi munuaiset, myÃ¶s koivulehdet
outptufile for decoded sequences:  saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435254/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_alephbert_heb_Hebr_32_inverter/decoded_eval_1720435254
{'eval_loss': 8.105596542358398, 'eval_accuracy': 0.132875, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.011199115659022775, 'eval_token_set_recall': 0.03383117715617716, 'eval_token_set_f1': 0.01583048559772799, 'eval_token_set_f1_sem': 0.0022026862828607753, 'eval_n_ngrams_match_1': 0.226, 'eval_n_ngrams_match_2': 0.008, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 14.876, 'eval_num_pred_words': 11.028, 'eval_bleu_score': 0.4591531874187433, 'eval_bleu_score_sem': 0.05005178648999018, 'eval_rouge_score': 0.004362881392286286, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.408765971660614, 'eval_emb_cos_sim_sem': 0.04690991127631474, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_perplexity': 3312.9573952877668, 'eval_runtime': 28.4896, 'eval_samples_per_second': 17.55, 'eval_steps_per_second': 2.211}
saving results to ./saves/inverters/mt5_alephbert_mt-ms_heb_Hebr_32_last_layer/evaluations/fin_Latn_inversion_base.json
