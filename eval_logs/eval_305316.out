working directory /home/cs.aau.dk/ng78zb/vec2text_exp
sif /home/cs.aau.dk/ng78zb/pytorch_23.10-py3.sif
launch evaluation yiyic/mt5_me5_latn-script_32_2layers_corrector with batch size 8
loading experiment and trainer from yiyic/mt5_me5_latn-script_32_2layers_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_me5_latn-script_32_2layers_corrector
on rank 0, output dir: saves/yiyic__mt5_me5_latn-script_32_2layers_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_me5_latn-script_32_2layers_inverter
on rank 0, output dir: saves/yiyic__mt5_me5_latn-script_32_2layers_inverter
adding embedding type to dataset args.
Loading datasets with TOKENIZERS_PARALLELISM = False
loading data from yiyic/Latn_train for lat_scrp
loading data from yiyic/Latn_dev for lat_scrp
allowed columns ['text', 'lang']
>> using fast tokenizers: True True
dataset kwargs: {'batched': True, 'num_proc': 6, 'remove_columns': ['text', 'lang'], 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'batched': True, 'num_proc': 6, 'remove_columns': ['text', 'lang'], 'desc': 'Running tokenizer on dataset'}
[Precomputing embeddings with batch size: 256]
	saving precomputed embeddings to file: 5ea4a6c4e8c95d59c111194716da8091da112d4db2a7a08e
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '5ea4a6c4e8c95d59c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
	saving precomputed embeddings to file: 9c88976e96c32780c111194716da8091da112d4db2a7a08e
dataset kwargs: {'batched': True, 'batch_size': 256, 'new_fingerprint': '9c88976e96c32780c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
saving train_dataset to path: /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/d9851dbd5328b1848bdcf6df05922c95.arrow
loaded dict of val datasets from /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/b7c2d88873c9bb4061ee54b83d4d22ce.arrow
07/04/2024 16:49:25 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
07/04/2024 16:51:04 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
data arguments for experiment: DataArguments(dataset_name='mt-ms_lat_scrp', max_eval_samples=500, use_less_data=3000)
model yiyic/mt5_me5_latn-script_32_2layers_corrector parameters 890566656
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
Using Frozen Embeddings as Input -- Val datasets
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '24e7b7ef1b0606ddc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7cf9deee5c6ee34dc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7d3c7a3fdc899099c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'a808a07212534aa6c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '1835610d5c7fc595c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '74575508bfab4c9cc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'af6bef1b30e3c5dbc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'bfa2f55e85bb2562c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd839c9a8871bbce8c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '67555e67fd16afc9c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '48ec325196197014c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'a20c740ae5a0d86bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'cc2235accdffe49bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '104320b250ecc6cac111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd7b432ef61da1e93c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'c06e214a198bcc2cc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '3ae3df71733802abc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '18a40ab4beb7f210c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '96cd5258a58b461bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7ee1e04e96a3faa2c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
output dir ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations
evaluating deu_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Easystore Convention. Die Artikel sind nach Relevanz
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Hair & Beauty Studio bietet Ihnen eine breite Palette an Services rund um Beauty und Wellness. Dabei geht 
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720104843/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720104843
{'eval_loss': 1.1325310468673706, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6145771882900909, 'eval_token_set_recall': 0.6467177487444272, 'eval_token_set_f1': 0.629069128228851, 'eval_token_set_f1_sem': 0.007887252099056713, 'eval_n_ngrams_match_1': 11.938, 'eval_n_ngrams_match_2': 6.262, 'eval_n_ngrams_match_3': 3.76, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.988, 'eval_bleu_score': 27.4409953984514, 'eval_bleu_score_sem': 1.1875229854928415, 'eval_rouge_score': 0.6023081208927366, 'eval_exact_match': 0.07, 'eval_exact_match_sem': 0.011421949126295709, 'eval_emb_cos_sim': 0.9594492316246033, 'eval_emb_cos_sim_sem': 0.009618777474758523, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 68.6466, 'eval_samples_per_second': 7.284, 'eval_steps_per_second': 0.918}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-1.json
evaluating corrector with steps 20
[pred] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Convenienstore. Die Artikel sind nach Relevanz sort
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Hair and Beauty Studio bietet Ihnen eine große Palette an Services rund um Beauty und Wellness. Dabei geht 
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720105271/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720105271
{'eval_loss': 1.1325310468673706, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6560337287747774, 'eval_token_set_recall': 0.6747441331189407, 'eval_token_set_f1': 0.6643164951572407, 'eval_token_set_f1_sem': 0.008080084717980083, 'eval_n_ngrams_match_1': 12.752, 'eval_n_ngrams_match_2': 6.954, 'eval_n_ngrams_match_3': 4.358, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 19.058, 'eval_bleu_score': 31.03580902758716, 'eval_bleu_score_sem': 1.2015748757337594, 'eval_rouge_score': 0.6508855232670424, 'eval_exact_match': 0.074, 'eval_exact_match_sem': 0.011718474529160406, 'eval_emb_cos_sim': 0.9592612981796265, 'eval_emb_cos_sim_sem': 0.015164131846656983, 'eval_emb_top1_equal': 0.875, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 427.8683, 'eval_samples_per_second': 1.169, 'eval_steps_per_second': 0.147}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-20.json
evaluating corrector with steps 50
[pred] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Convenienstore. Die Artikel sind nach Relevanz sort
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Hair and Beauty Studio bietet Ihnen eine große Palette an Services rund um Beauty und Wellness. Dabei geht 
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720106257/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720106257
{'eval_loss': 1.1325310468673706, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6590776100849094, 'eval_token_set_recall': 0.6776872142036626, 'eval_token_set_f1': 0.6673177409819564, 'eval_token_set_f1_sem': 0.008057754028931911, 'eval_n_ngrams_match_1': 12.824, 'eval_n_ngrams_match_2': 7.02, 'eval_n_ngrams_match_3': 4.386, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 19.042, 'eval_bleu_score': 31.208485747040598, 'eval_bleu_score_sem': 1.201878264438922, 'eval_rouge_score': 0.6547379829668407, 'eval_exact_match': 0.074, 'eval_exact_match_sem': 0.011718474529160406, 'eval_emb_cos_sim': 0.9592612981796265, 'eval_emb_cos_sim_sem': 0.015164131846656983, 'eval_emb_top1_equal': 0.875, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 986.1275, 'eval_samples_per_second': 0.507, 'eval_steps_per_second': 0.064}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-50.json
evaluating corrector with steps 50 and beam width 4
[pred] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Hair and Beauty Studio bietet Ihnen eine große Palette an Dienstleistungen rund um Beauty und Wellness. Dabei geht
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720108932/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720108932
{'eval_loss': 1.1325310468673706, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6933193241335615, 'eval_token_set_recall': 0.711908947359381, 'eval_token_set_f1': 0.7015604709069785, 'eval_token_set_f1_sem': 0.008016433777024863, 'eval_n_ngrams_match_1': 13.432, 'eval_n_ngrams_match_2': 7.704, 'eval_n_ngrams_match_3': 4.976, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.966, 'eval_bleu_score': 34.81815198653232, 'eval_bleu_score_sem': 1.2630349100584766, 'eval_rouge_score': 0.690101162657395, 'eval_exact_match': 0.072, 'eval_exact_match_sem': 0.011571508095282932, 'eval_emb_cos_sim': 0.9584424495697021, 'eval_emb_cos_sim_sem': 0.015982889696719772, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2675.3468, 'eval_samples_per_second': 0.187, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 10.07 GiB is free. Including non-PyTorch memory, this process has 34.45 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 4.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating ydd_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Çin (Çin) / Çin / Kıbrıs (Çin) 5 çöp çöp
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: سَبَتُ الْحَسْتُ الْحَسْتُ الْحَسْ
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: bizim türkiye türkiye türkiye türkiye türkiye türkiye türkiye türkiye nizam
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720109034/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720109034
{'eval_loss': 6.934736251831055, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23811247601727478, 'eval_token_set_recall': 0.36834070518853185, 'eval_token_set_f1': 0.28308074405226924, 'eval_token_set_f1_sem': 0.0037974580091124158, 'eval_n_ngrams_match_1': 3.438, 'eval_n_ngrams_match_2': 1.19, 'eval_n_ngrams_match_3': 0.088, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 13.77, 'eval_bleu_score': 6.456543742885746, 'eval_bleu_score_sem': 0.13071284170444028, 'eval_rouge_score': 0.1762758872409818, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8703110218048096, 'eval_emb_cos_sim_sem': 0.009663814016570444, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 79.6041, 'eval_samples_per_second': 6.281, 'eval_steps_per_second': 0.791}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/ydd_Hebr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.87 GiB is free. Including non-PyTorch memory, this process has 36.65 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.25 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Çin / Kıbrıs / Taipei (Çin) 5 çöp çöp çöp
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: سُسُسُ سُسُ سُسُ | دار البيان سُسُسُ سُسُ
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: biz türkiye türkiye türkiye türkiye türkiye türkiye türkiye türkiye: Paşa
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720111727/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720111727
{'eval_loss': 6.934736251831055, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.24113287529464017, 'eval_token_set_recall': 0.36060492651483417, 'eval_token_set_f1': 0.28287028899123823, 'eval_token_set_f1_sem': 0.003809202101599454, 'eval_n_ngrams_match_1': 3.488, 'eval_n_ngrams_match_2': 1.194, 'eval_n_ngrams_match_3': 0.082, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 14.254, 'eval_bleu_score': 6.368266464892018, 'eval_bleu_score_sem': 0.11089661341193814, 'eval_rouge_score': 0.17838079115137168, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8706769347190857, 'eval_emb_cos_sim_sem': 0.01893541868052162, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2649.3078, 'eval_samples_per_second': 0.189, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/ydd_Hebr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.99 GiB is free. Including non-PyTorch memory, this process has 36.53 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating heb_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Geçtiğimiz günlerde sizlere ufak bir araştırma yaparak sizlere belirtmek gerekirse,(The problem is not
[true] query: במחקר שהתפרסם לאחרונה (ואני מתנצל שלא הגעתי לדון בו עד כה מפאת עניינים אחר



[pred] query: RIZA TÜRKİYE, ülkemizi çok önemli bir program. RIZA TÜRKİYE, ülkemizi çok önem
[true] query: תוכנית ריאליטי בישראל היא לא רק תוכנית ריאליטי. היא שיעור באזרחות,



[pred] query: Merhaba, sizlere ivedilikle ivedilikle ivedilikle ivedilikle ivedilikle 20.04.2011
[true] query: בפני בקשה לעיכוב ביצוע פסק הדין אשר ניתן ביום 20.4.11 ואשר במסגרתו חו
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720111823/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720111823
{'eval_loss': 6.843958854675293, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19462919480760071, 'eval_token_set_recall': 0.2708872952211188, 'eval_token_set_f1': 0.223133580539708, 'eval_token_set_f1_sem': 0.002893249398590247, 'eval_n_ngrams_match_1': 3.25, 'eval_n_ngrams_match_2': 1.062, 'eval_n_ngrams_match_3': 0.024, 'eval_num_true_words': 15.944, 'eval_num_pred_words': 15.858, 'eval_bleu_score': 5.456870334842506, 'eval_bleu_score_sem': 0.047939403325796305, 'eval_rouge_score': 0.13212755256670894, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8863322734832764, 'eval_emb_cos_sim_sem': 0.008767784529574489, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 74.1554, 'eval_samples_per_second': 6.743, 'eval_steps_per_second': 0.85}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/heb_Hebr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 8.23 GiB is free. Including non-PyTorch memory, this process has 36.29 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Geçtiğimiz günlerde yeni bir araştırma gerçekleştirerek sizlere belirtmek isterim ki,(The fact that we did not 
[true] query: במחקר שהתפרסם לאחרונה (ואני מתנצל שלא הגעתי לדון בו עד כה מפאת עניינים אחר



[pred] query: TÜRKİYE RIZASI, çok ciddi bir programdır. TÜRKİYE RIZASI, çok ciddi bir program
[true] query: תוכנית ריאליטי בישראל היא לא רק תוכנית ריאליטי. היא שיעור באזרחות,



[pred] query: Merhaba, sizlere ivedilikle ivedilikle ivedilikle ivedilikle ivedilikle 20.04.2011
[true] query: בפני בקשה לעיכוב ביצוע פסק הדין אשר ניתן ביום 20.4.11 ואשר במסגרתו חו
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720114533/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720114533
{'eval_loss': 6.843958854675293, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.194512801354133, 'eval_token_set_recall': 0.2722511119943011, 'eval_token_set_f1': 0.2234872519110282, 'eval_token_set_f1_sem': 0.0028152427500174387, 'eval_n_ngrams_match_1': 3.222, 'eval_n_ngrams_match_2': 1.054, 'eval_n_ngrams_match_3': 0.028, 'eval_num_true_words': 15.944, 'eval_num_pred_words': 16.038, 'eval_bleu_score': 5.360311215780149, 'eval_bleu_score_sem': 0.04671949684098653, 'eval_rouge_score': 0.12906167194808246, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8874098062515259, 'eval_emb_cos_sim_sem': 0.007351563491733396, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2666.513, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/heb_Hebr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 8.23 GiB is free. Including non-PyTorch memory, this process has 36.29 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating arb_Arab val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Nikah Çantası ile Floral Floral Floral Floral Floral Floral Floral Floral Floral Floral Floral
[true] query: فستان زفاف أنيق بقصّة الأميرة من نسيج الميكادو، مُزيّن بالأزهار



[pred] query: Muhammed Rıdsa Müslüman lideri Muhammed Rıdsa Müslüman ekibi tarafından 20P20
[true] query: رئيس القمة الدينية لمجموعة العشرين الشيخ د.محمد العيسى يطلق منصة R20 



[pred] query: Sosyal Bilimler Meslek Yüksekokulu, İslami Araştırmaları ile dikkati çekmeye devam ederek, 
[true] query: تسعى كلية العلوم الإسلامية إلى تبوأ مكانة وسمعة مرموقة بين جامعات العالم، 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720114637/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720114637
{'eval_loss': 4.516104221343994, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.16210325428785222, 'eval_token_set_recall': 0.20177967619755607, 'eval_token_set_f1': 0.17673311547102372, 'eval_token_set_f1_sem': 0.0023526465485143562, 'eval_n_ngrams_match_1': 2.528, 'eval_n_ngrams_match_2': 1.04, 'eval_n_ngrams_match_3': 0.02, 'eval_num_true_words': 15.48, 'eval_num_pred_words': 14.746, 'eval_bleu_score': 5.556889546364698, 'eval_bleu_score_sem': 0.09999958957331591, 'eval_rouge_score': 0.13835368530319575, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8561858534812927, 'eval_emb_cos_sim_sem': 0.013509314865217687, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 81.9989, 'eval_samples_per_second': 6.098, 'eval_steps_per_second': 0.768}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/arb_Arab_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Zarif Çiçekler ile Âşıklık Eşyalarından Âşıklık Eşya, Monique Moğodar
[true] query: فستان زفاف أنيق بقصّة الأميرة من نسيج الميكادو، مُزيّن بالأزهار



[pred] query: Müslüman Divanı Muhammed Rıdsî tarafından yeni toplantı aracı Müslüman Divanı Rıdsî 20
[true] query: رئيس القمة الدينية لمجموعة العشرين الشيخ د.محمد العيسى يطلق منصة R20 



[pred] query: İslami Bilimler Fakültesi, Sosyal Medya ile Öğrencilerini İlgilendirmeye Devam Ediyor, Ho
[true] query: تسعى كلية العلوم الإسلامية إلى تبوأ مكانة وسمعة مرموقة بين جامعات العالم، 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720117342/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720117342
{'eval_loss': 4.516104221343994, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.16140323094518177, 'eval_token_set_recall': 0.198110353105787, 'eval_token_set_f1': 0.17474459400302236, 'eval_token_set_f1_sem': 0.002342404244509806, 'eval_n_ngrams_match_1': 2.504, 'eval_n_ngrams_match_2': 1.034, 'eval_n_ngrams_match_3': 0.014, 'eval_num_true_words': 15.48, 'eval_num_pred_words': 14.776, 'eval_bleu_score': 5.4788333928338275, 'eval_bleu_score_sem': 0.10001010240126275, 'eval_rouge_score': 0.14150796840713373, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8533005714416504, 'eval_emb_cos_sim_sem': 0.009555115318627325, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 2661.3484, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/arb_Arab_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating amh_Ethi val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: 20 Mart 2016, featured images, featured images El Marması eğri ve deniz eğrilerini
[true] query: ማርች 20, 2016 የራስ ዱሜራ ደሴቶችና የባህር ግዛት የሚያሳን የኤ



[pred] query: egemenliğin uyum şansı - egemenliğin uyum şansı - egemenliğin uyum şansı
[true] query: አንድነት አንድነት ውስጥ ጥንካሬ - የህብረት ማህበረሰብ እንክብካቤ



[pred] query: 20 ilginç haberleri 20 ilginç haberleri Uzay'a giden futbolcuların evinde kal
[true] query: ከቡናማዎቹ ጋር ነገ ወደ ዩጋንዳ የሚያቀኑ 20 ተጫዋቾች ተለይተው
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720117441/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720117441
{'eval_loss': 7.175166130065918, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.25997767920933584, 'eval_token_set_recall': 0.33006729221071396, 'eval_token_set_f1': 0.2851089970266921, 'eval_token_set_f1_sem': 0.003694943051754633, 'eval_n_ngrams_match_1': 3.114, 'eval_n_ngrams_match_2': 1.214, 'eval_n_ngrams_match_3': 0.074, 'eval_num_true_words': 11.838, 'eval_num_pred_words': 13.464, 'eval_bleu_score': 7.182042237257129, 'eval_bleu_score_sem': 0.12161977962777742, 'eval_rouge_score': 0.17503246111945653, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8577709794044495, 'eval_emb_cos_sim_sem': 0.007564408369435951, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 77.5265, 'eval_samples_per_second': 6.449, 'eval_steps_per_second': 0.813}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/amh_Ethi_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: 20 Mart 2016, featured images, featured images, featured images deniz damarlarının ömrü ve
[true] query: ማርች 20, 2016 የራስ ዱሜራ ደሴቶችና የባህር ግዛት የሚያሳን የኤ



[pred] query: egemenliğin uyumu - Kolektif egemenliğin uyumu VİDEO egemenliğin uyumu
[true] query: አንድነት አንድነት ውስጥ ጥንካሬ - የህብረት ማህበረሰብ እንክብካቤ



[pred] query: 20 ilginç haberleri 20 ilginç haberleri Önümüzdeki hafta Ukrayna'ya giden futbolcuların
[true] query: ከቡናማዎቹ ጋር ነገ ወደ ዩጋንዳ የሚያቀኑ 20 ተጫዋቾች ተለይተው
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720120147/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720120147
{'eval_loss': 7.175166130065918, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2596178294615604, 'eval_token_set_recall': 0.3190248470483772, 'eval_token_set_f1': 0.28104917662255596, 'eval_token_set_f1_sem': 0.003700952097391428, 'eval_n_ngrams_match_1': 3.104, 'eval_n_ngrams_match_2': 1.194, 'eval_n_ngrams_match_3': 0.078, 'eval_num_true_words': 11.838, 'eval_num_pred_words': 13.698, 'eval_bleu_score': 7.070501925219982, 'eval_bleu_score_sem': 0.12685464613440905, 'eval_rouge_score': 0.1729833666628552, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8278573751449585, 'eval_emb_cos_sim_sem': 0.012552063788037119, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 2662.4246, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/amh_Ethi_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mlt_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Musculoskeletal Problems and Mechanisms - Multidisciplinary guides to problematics and practical solutions Musculoskelet
[true] query: Dħul Temi Temi Problemi muskuloskeletali Practical tools and guidance - Musculoskeletal disorders



[pred] query: Koronavirüs - News of the World Ċi̇n Ċi̇n, one of the first test to test 
[true] query: test – One News Mindu feġġ l-ewwel każ ta' coronavirus f'pajjiżna, saru aktar



[pred] query: Mfm'nin iğrenç oyunculara uyarı - "Ona iğrenç oyuncular
[true] query: 'L-MFA emmnet lil min ibagħbas il-logħob u mhux lili' - Illum
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720120248/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720120248
{'eval_loss': 5.094670295715332, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.25852130626511444, 'eval_token_set_recall': 0.347562423197718, 'eval_token_set_f1': 0.2914707144833024, 'eval_token_set_f1_sem': 0.004043207846081924, 'eval_n_ngrams_match_1': 3.702, 'eval_n_ngrams_match_2': 1.246, 'eval_n_ngrams_match_3': 0.108, 'eval_num_true_words': 13.932, 'eval_num_pred_words': 13.514, 'eval_bleu_score': 7.159300508382065, 'eval_bleu_score_sem': 0.12791871650001418, 'eval_rouge_score': 0.16243529608383242, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8938446044921875, 'eval_emb_cos_sim_sem': 0.010819513529964558, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 78.3309, 'eval_samples_per_second': 6.383, 'eval_steps_per_second': 0.804}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/mlt_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Musculoskeletal Problems and Techniques - temel kılavuzu Musculoskeletal Problems and Techniques - 
[true] query: Dħul Temi Temi Problemi muskuloskeletali Practical tools and guidance - Musculoskeletal disorders



[pred] query: February, 2020 - Ċiġ News Ċiġ News Ċiġ News Ċiġ one of the
[true] query: test – One News Mindu feġġ l-ewwel każ ta' coronavirus f'pajjiżna, saru aktar



[pred] query: Mfm'nin 'ilk olarak rencide edilmesini isteyen kişi' mesajı - LOJ
[true] query: 'L-MFA emmnet lil min ibagħbas il-logħob u mhux lili' - Illum
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720122944/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720122944
{'eval_loss': 5.094670295715332, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2648647422409035, 'eval_token_set_recall': 0.358653195660549, 'eval_token_set_f1': 0.2983648738549566, 'eval_token_set_f1_sem': 0.004472869394839943, 'eval_n_ngrams_match_1': 3.796, 'eval_n_ngrams_match_2': 1.274, 'eval_n_ngrams_match_3': 0.128, 'eval_num_true_words': 13.932, 'eval_num_pred_words': 13.674, 'eval_bleu_score': 7.288874260980783, 'eval_bleu_score_sem': 0.15242888639532567, 'eval_rouge_score': 0.16928030252700574, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9035558104515076, 'eval_emb_cos_sim_sem': 0.01052774341006929, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2653.1679, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/mlt_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating hin_Deva val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: müslüman olmak!!! : : : : : Müslüman olmak!!! müslüman olmak!!!
[true] query: Blog News: ग़लती न करे मुसलमान!!! ग़लती न करे मुसलमान!!! 



[pred] query: Chapter 9 - brother name solution for students in hindi Chapter 9 - brother name solution for students in hindi Chapter 9 
[true] query: RBSE Solutions for Class 9 Hindi Sparsh Chapter 11 आदमी नामा - Rbse solutions RBSE Solutions for Class 9



[pred] query: Hindistan Cumhurbaşkanı Muhammed Narendra Modi son 14 yılın sonuna kadar sadece 14 dakika olmasını, 
[true] query: नई दिल्ली, प्रधानमंत्री नरेंद्र मोदी का कार्यकाल पूरा होने में केवल 14 महीने का वक्त बा
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720123045/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720123045
{'eval_loss': 4.223048686981201, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2322954464161796, 'eval_token_set_recall': 0.323778122048081, 'eval_token_set_f1': 0.2646301288419753, 'eval_token_set_f1_sem': 0.005232097416852639, 'eval_n_ngrams_match_1': 4.214, 'eval_n_ngrams_match_2': 1.43, 'eval_n_ngrams_match_3': 0.23, 'eval_num_true_words': 17.206, 'eval_num_pred_words': 16.598, 'eval_bleu_score': 6.346230333967315, 'eval_bleu_score_sem': 0.2152697388964839, 'eval_rouge_score': 0.21584695064674858, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8802515268325806, 'eval_emb_cos_sim_sem': 0.021914836036584406, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 79.1145, 'eval_samples_per_second': 6.32, 'eval_steps_per_second': 0.796}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/hin_Deva_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: İslami Yazılar : mistaken mistaken mistaken mistaken mistaken mistaken!!! 
[true] query: Blog News: ग़लती न करे मुसलमान!!! ग़लती न करे मुसलमान!!! 



[pred] query: Rss 9 class name solution for brother in hindi - BABESE GROUP Rss 9 class name solution for brother in hindi
[true] query: RBSE Solutions for Class 9 Hindi Sparsh Chapter 11 आदमी नामा - Rbse solutions RBSE Solutions for Class 9



[pred] query: Hindistan Cumhurbaşkanı Muhammed Narendra Modi son 14 yılın sonuna kadar sadece 24 saat olmasını, malayal
[true] query: नई दिल्ली, प्रधानमंत्री नरेंद्र मोदी का कार्यकाल पूरा होने में केवल 14 महीने का वक्त बा
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720125756/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720125756
{'eval_loss': 4.223048686981201, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23386028988024918, 'eval_token_set_recall': 0.3215374365553833, 'eval_token_set_f1': 0.2627510251263592, 'eval_token_set_f1_sem': 0.0052503801948682715, 'eval_n_ngrams_match_1': 4.26, 'eval_n_ngrams_match_2': 1.458, 'eval_n_ngrams_match_3': 0.244, 'eval_num_true_words': 17.206, 'eval_num_pred_words': 16.794, 'eval_bleu_score': 6.497303084317016, 'eval_bleu_score_sem': 0.2343906333758629, 'eval_rouge_score': 0.22442481458306476, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8780653476715088, 'eval_emb_cos_sim_sem': 0.01631155082140772, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2667.0478, 'eval_samples_per_second': 0.187, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/hin_Deva_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating urd_Arab val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: baştan başa rektöre rektöre rektöre rektöre rektöre https://www.
[true] query: قائداعظم سے نہرو تک ۔۔ رؤف کلاسرا مرکزی صفحہ/ لکھاری/ ر



[pred] query: Sunay Manyaki sadece sosyal medyada kendisini mağdur etmemiş Sunay Manyaki sosyal medyada
[true] query: سوناکشی سنہا سوشل میڈیا میمز کے نشے میں مبتلا ہو گئیں اداکارہ نہ صرف خود



[pred] query: : : : : : : : Hindistan'ın Maharashtra eyaletinde 2018 yılında 
[true] query: نئی دہلی:مہاراشٹر میں گزشتہ 5 سالوں میں (18-2014)14034 کسانوں نے خود
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720125856/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720125856
{'eval_loss': 5.243589878082275, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.18158702103336335, 'eval_token_set_recall': 0.23878943429291744, 'eval_token_set_f1': 0.20332228454144605, 'eval_token_set_f1_sem': 0.003375515275190598, 'eval_n_ngrams_match_1': 3.032, 'eval_n_ngrams_match_2': 1.148, 'eval_n_ngrams_match_3': 0.058, 'eval_num_true_words': 17.024, 'eval_num_pred_words': 15.332, 'eval_bleu_score': 5.413424051571852, 'eval_bleu_score_sem': 0.13443860300450064, 'eval_rouge_score': 0.16362518738156145, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8688704371452332, 'eval_emb_cos_sim_sem': 0.0077541607254215834, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 77.7855, 'eval_samples_per_second': 6.428, 'eval_steps_per_second': 0.81}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/urd_Arab_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: başından başına / rektör / rektör / rektör / rektör Muhammed Kalas
[true] query: قائداعظم سے نہرو تک ۔۔ رؤف کلاسرا مرکزی صفحہ/ لکھاری/ ر



[pred] query: Sunay Sönmezi Manyaksa kendisini sadece sosyal medya influencers tarafından endişeye uğra
[true] query: سوناکشی سنہا سوشل میڈیا میمز کے نشے میں مبتلا ہو گئیں اداکارہ نہ صرف خود



[pred] query: Marathi: Maharashtra'nın Maharashtra eyaletinde son olarak 1834-1834 yılları arasında y
[true] query: نئی دہلی:مہاراشٹر میں گزشتہ 5 سالوں میں (18-2014)14034 کسانوں نے خود
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720128565/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720128565
{'eval_loss': 5.243589878082275, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.1785863668715636, 'eval_token_set_recall': 0.23282348399794273, 'eval_token_set_f1': 0.19851253673825853, 'eval_token_set_f1_sem': 0.0032806758944491266, 'eval_n_ngrams_match_1': 2.974, 'eval_n_ngrams_match_2': 1.132, 'eval_n_ngrams_match_3': 0.044, 'eval_num_true_words': 17.024, 'eval_num_pred_words': 15.418, 'eval_bleu_score': 5.3092756332861075, 'eval_bleu_score_sem': 0.1282641271836623, 'eval_rouge_score': 0.16327553132322253, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8729498982429504, 'eval_emb_cos_sim_sem': 0.007199541784788125, 'eval_emb_top1_equal': 1.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 2665.4149, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/urd_Arab_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating guj_Gujr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: "Neden bizim karı-kız nikaha gitti?" 'Möcümüz nikaha çağırdılar'
[true] query: 'અમારા વિરોધીને લગ્નમાં કેમ બોલાવ્યો?' કહી કન્યાના મા-બા



[pred] query: Latest gujarat tourism news from today, gujarat tourism information. Bu yolculuğuna buradan başlayalım, 
[true] query: આજે સાંજથી કેજરીવાલની ગુજરાત યાત્રા શરૂ, જાણો આખો કાર્યક્રમ | Read here



[pred] query: Darüşşafaka Şahin 2nd (2019) Hindistan vizyona girecek | xprodoksit Darüşşafaka Şah
[true] query: ફરહાનની ડૉન 3માં જોવા મળશે ગુજરાતી શાહરુખ ખાન | Shahrukh Kahn
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720128665/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720128665
{'eval_loss': 7.044559001922607, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23313065715674094, 'eval_token_set_recall': 0.2649549013422082, 'eval_token_set_f1': 0.24403282732825696, 'eval_token_set_f1_sem': 0.003400906999998593, 'eval_n_ngrams_match_1': 3.13, 'eval_n_ngrams_match_2': 1.122, 'eval_n_ngrams_match_3': 0.044, 'eval_num_true_words': 13.074, 'eval_num_pred_words': 14.128, 'eval_bleu_score': 6.448304829118641, 'eval_bleu_score_sem': 0.0810558043129226, 'eval_rouge_score': 0.15183556704246576, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.894666314125061, 'eval_emb_cos_sim_sem': 0.004584541227474213, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 78.1457, 'eval_samples_per_second': 6.398, 'eval_steps_per_second': 0.806}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/guj_Gujr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: "Neden bizim karı-kızımızı nikaha çağırdılar?" Maharashtra'da nikah sözcüsü, 
[true] query: 'અમારા વિરોધીને લગ્નમાં કેમ બોલાવ્યો?' કહી કન્યાના મા-બા



[pred] query: Latest gujarat tourism information from today, Kağıthane yolculuğuna buradan başlayalım. Read this content,
[true] query: આજે સાંજથી કેજરીવાલની ગુજરાત યાત્રા શરૂ, જાણો આખો કાર્યક્રમ | Read here



[pred] query: Drahn Şahin (2017) vizyona girecek | xprodoksit Drahn Şahin (2017) vizyona girecek
[true] query: ફરહાનની ડૉન 3માં જોવા મળશે ગુજરાતી શાહરુખ ખાન | Shahrukh Kahn
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720131370/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720131370
{'eval_loss': 7.044559001922607, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2332838187010789, 'eval_token_set_recall': 0.2666959092592997, 'eval_token_set_f1': 0.2443697736425151, 'eval_token_set_f1_sem': 0.003344612649709221, 'eval_n_ngrams_match_1': 3.144, 'eval_n_ngrams_match_2': 1.11, 'eval_n_ngrams_match_3': 0.04, 'eval_num_true_words': 13.074, 'eval_num_pred_words': 14.28, 'eval_bleu_score': 6.388415258889845, 'eval_bleu_score_sem': 0.08055210449791536, 'eval_rouge_score': 0.15043540922626525, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8664020299911499, 'eval_emb_cos_sim_sem': 0.009921259479620637, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 2661.3498, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/guj_Gujr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating sin_Sinh val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Posted by gurur on 16th February 2016 \ \ \ İnsanları görmek adına yola çık
[true] query: මිනිස්සු | ඇවිද යන මඟ ← ගරු කිරීම ගුරුවරු → 16 අප් රේල් අපිට කෙනෙක් දැක්කාම ආ



[pred] query: siccamaya sümüli... | Apple Türkçe siccamaya sümüli... Posted on Mart 24, 2017 Mart 24,
[true] query: සිවුමැලියා සිකුරු ලියා... | Sunday Apple සිවුමැලියා සිකුරු ලියා... March 24, 2017 | 11:00 am 0



[pred] query: Nişanın yanında olmak... - Latest News Latest News Latest News Nişanın yanında olmak
[true] query: නිළිකමට මැදි වුණේ පුංචි කෙල්ලක කාලේ... - Sri Lanka News Update නිළිකමට මැ
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720131469/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720131469
{'eval_loss': 6.955296993255615, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.25180483658927955, 'eval_token_set_recall': 0.32019962577841893, 'eval_token_set_f1': 0.2777564744418786, 'eval_token_set_f1_sem': 0.004070094388665189, 'eval_n_ngrams_match_1': 3.656, 'eval_n_ngrams_match_2': 1.29, 'eval_n_ngrams_match_3': 0.094, 'eval_num_true_words': 14.694, 'eval_num_pred_words': 14.694, 'eval_bleu_score': 6.649930750451294, 'eval_bleu_score_sem': 0.12654123171224188, 'eval_rouge_score': 0.16437826639971972, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8672207593917847, 'eval_emb_cos_sim_sem': 0.011476867389476845, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 77.364, 'eval_samples_per_second': 6.463, 'eval_steps_per_second': 0.814}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/sin_Sinh_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: - İnsanları görmek Posted by - İnsanları görmek Posted on 16-04-2016 eğer yoluna gider
[true] query: මිනිස්සු | ඇවිද යන මඟ ← ගරු කිරීම ගුරුවරු → 16 අප් රේල් අපිට කෙනෙක් දැක්කාම ආ



[pred] query: sicca mavi sümüli... | Apple Türkçe sicca mavi sümüli... Published on Mart 24, 2017
[true] query: සිවුමැලියා සිකුරු ලියා... | Sunday Apple සිවුමැලියා සිකුරු ලියා... March 24, 2017 | 11:00 am 0



[pred] query: Çocukluğuna nişan olmak... - Latest News Latest News Latest News Çocukluğuna nişan olmak
[true] query: නිළිකමට මැදි වුණේ පුංචි කෙල්ලක කාලේ... - Sri Lanka News Update නිළිකමට මැ
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720134180/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720134180
{'eval_loss': 6.955296993255615, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.25192868202488944, 'eval_token_set_recall': 0.3134444449083771, 'eval_token_set_f1': 0.2754395798074954, 'eval_token_set_f1_sem': 0.004051024077980178, 'eval_n_ngrams_match_1': 3.644, 'eval_n_ngrams_match_2': 1.298, 'eval_n_ngrams_match_3': 0.108, 'eval_num_true_words': 14.694, 'eval_num_pred_words': 14.86, 'eval_bleu_score': 6.614303639315859, 'eval_bleu_score_sem': 0.13077715256182515, 'eval_rouge_score': 0.16068111211566802, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8763360977172852, 'eval_emb_cos_sim_sem': 0.012322849469499637, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 2666.2166, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/sin_Sinh_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating pan_Guru val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Pandemi nedeniyle kapanan mağazaları mağdur | Videography Pandemi nedeniyle kapanan mağazaları mağ
[true] query: ਕਰੋਨਾ ਮਹਾਂਮਾਰੀ ਦੇ ਚੱਲਦੇ ਫੋਟੋਗ੍ਰਾਫਰ ਦੀਆਂ ਬੰਦ ਪਈਆਂ ਦੁਕਾਨਾਂ ਖੋ



[pred] query: UPA'nın hayallerini yerine getirmek için mümkün - Mahmud Paşa - MOVIES
[true] query: ਮੋਦੀ ਦੇ ਸੁਪਨਿਆਂ ਦਾ ਯੂ ਪੀ ਬਣਾਉਣ ਲਈ ਕਵਾਇਦ ਆਰੰਭ - Panja



[pred] query: : : : : : : : : : : : : : :
[true] query: ਸ਼ਹੀਦਾਂ ਦੀਆਂ ਤਸਵੀਰਾਂ ਅਜਾਇਬ ਘਰ 'ਚ ਲਗਾਉਣ ਦੀ ਮੰਗ :
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720134279/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720134279
{'eval_loss': 6.692384243011475, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22820517716717448, 'eval_token_set_recall': 0.3102979527008942, 'eval_token_set_f1': 0.25442468220817116, 'eval_token_set_f1_sem': 0.003576974269948836, 'eval_n_ngrams_match_1': 3.048, 'eval_n_ngrams_match_2': 1.074, 'eval_n_ngrams_match_3': 0.028, 'eval_num_true_words': 13.07, 'eval_num_pred_words': 14.322, 'eval_bleu_score': 5.9616388760528185, 'eval_bleu_score_sem': 0.06715474950431109, 'eval_rouge_score': 0.18774209754948032, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8281530737876892, 'eval_emb_cos_sim_sem': 0.01023654227262892, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 77.735, 'eval_samples_per_second': 6.432, 'eval_steps_per_second': 0.81}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/pan_Guru_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Hindistan haberleri | Hindistan haberleri Korona virüs mağduriyeti nedeniyle kapanma aşamasına giren mağa
[true] query: ਕਰੋਨਾ ਮਹਾਂਮਾਰੀ ਦੇ ਚੱਲਦੇ ਫੋਟੋਗ੍ਰਾਫਰ ਦੀਆਂ ਬੰਦ ਪਈਆਂ ਦੁਕਾਨਾਂ ਖੋ



[pred] query: Param Piya'nın hayallerini gerçekleştirmek için başlangıç edilebilir - UZMANTV Param Piya
[true] query: ਮੋਦੀ ਦੇ ਸੁਪਨਿਆਂ ਦਾ ਯੂ ਪੀ ਬਣਾਉਣ ਲਈ ਕਵਾਇਦ ਆਰੰਭ - Panja



[pred] query: : : : : : : : : : : : : : :
[true] query: ਸ਼ਹੀਦਾਂ ਦੀਆਂ ਤਸਵੀਰਾਂ ਅਜਾਇਬ ਘਰ 'ਚ ਲਗਾਉਣ ਦੀ ਮੰਗ :
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720136988/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720136988
{'eval_loss': 6.692384243011475, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22273073690155773, 'eval_token_set_recall': 0.3110692539400747, 'eval_token_set_f1': 0.24782757983754602, 'eval_token_set_f1_sem': 0.003296192459402885, 'eval_n_ngrams_match_1': 2.964, 'eval_n_ngrams_match_2': 1.066, 'eval_n_ngrams_match_3': 0.024, 'eval_num_true_words': 13.07, 'eval_num_pred_words': 14.442, 'eval_bleu_score': 5.8082160798253835, 'eval_bleu_score_sem': 0.05996492465503408, 'eval_rouge_score': 0.19949530364727347, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8167304396629333, 'eval_emb_cos_sim_sem': 0.014395116497460163, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 2664.8417, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/pan_Guru_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating tur_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: tek parti devri haberi | Sayfa 7 tek parti devri haberi Geçtiğimiz günlerde yapılan... HÜSEYİN Ş
[true] query: tek parti devri TEK PARTİ DEVRİ haberleri haber haberi | Sayfa 7 Tek parti chp zamanında yapılan... 15 Şu



[pred] query: Anasayfa SPOR Fenerbahçe-Dinamo Zagreb maçının hakemleri belli oldu Tarih: 2018-10-27 Saat: 16:17:00 Güncel
[true] query: Anasayfa Spor Fenerbahçe-Dinamo Zagreb maçının hakemleri açıklandı kaynuka Tarih: 2018-11-27 Saat: 15:07:19 



[pred] query: Alışveriş yöntemleri Çocuk kitapları Çocuk Eğitimi Çocuk Eğitimi 7-14 yaş arası Annelik Sağlık
[true] query: Alışveriş Annelik Bebek Çocuk Çocuk Kitapları Eğitim Sağlık 7–14 yaş çocuklar için öğretim metodları 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720137087/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720137087
{'eval_loss': 1.2927372455596924, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.5487499658681011, 'eval_token_set_recall': 0.5964741574144284, 'eval_token_set_f1': 0.569223703410499, 'eval_token_set_f1_sem': 0.007949633268310994, 'eval_n_ngrams_match_1': 9.23, 'eval_n_ngrams_match_2': 4.862, 'eval_n_ngrams_match_3': 2.654, 'eval_num_true_words': 16.658, 'eval_num_pred_words': 16.296, 'eval_bleu_score': 23.36294117709806, 'eval_bleu_score_sem': 0.9315270916385369, 'eval_rouge_score': 0.5625994737021716, 'eval_exact_match': 0.014, 'eval_exact_match_sem': 0.005259593772650755, 'eval_emb_cos_sim': 0.9637246131896973, 'eval_emb_cos_sim_sem': 0.00839786888418396, 'eval_emb_top1_equal': 1.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 77.5502, 'eval_samples_per_second': 6.447, 'eval_steps_per_second': 0.812}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/tur_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: tek parti devri haberleri | Sayfa 15 tek parti devri haberi Bu haber 15 kez okundu... ÇİP H
[true] query: tek parti devri TEK PARTİ DEVRİ haberleri haber haberi | Sayfa 7 Tek parti chp zamanında yapılan... 15 Şu



[pred] query: Anasayfa SPOR Fenerbahçe-Dinamo Zagreb maçının hakemleri belli oldu Tarih: 2018-10-27 Saat: 16:13:00 Güncel
[true] query: Anasayfa Spor Fenerbahçe-Dinamo Zagreb maçının hakemleri açıklandı kaynuka Tarih: 2018-11-27 Saat: 15:07:19 



[pred] query: Çocuk Eğitimi Çocuk Kitapları 7-14 yaş arası Çocuk Eğitim yöntemleri Annelik-Bebek Sağlık alış
[true] query: Alışveriş Annelik Bebek Çocuk Çocuk Kitapları Eğitim Sağlık 7–14 yaş çocuklar için öğretim metodları 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720139809/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720139809
{'eval_loss': 1.2927372455596924, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6121027877825799, 'eval_token_set_recall': 0.6458599432559182, 'eval_token_set_f1': 0.6265778895477462, 'eval_token_set_f1_sem': 0.009161282359040221, 'eval_n_ngrams_match_1': 10.31, 'eval_n_ngrams_match_2': 5.906, 'eval_n_ngrams_match_3': 3.636, 'eval_num_true_words': 16.658, 'eval_num_pred_words': 16.394, 'eval_bleu_score': 30.263373712783174, 'eval_bleu_score_sem': 1.2323358273594243, 'eval_rouge_score': 0.6380289814068252, 'eval_exact_match': 0.06, 'eval_exact_match_sem': 0.010631371130019326, 'eval_emb_cos_sim': 0.9589841365814209, 'eval_emb_cos_sim_sem': 0.009508742590008706, 'eval_emb_top1_equal': 0.875, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 2678.4502, 'eval_samples_per_second': 0.187, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/tur_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating kaz_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: MHP Kahramanmaraş Ağır Güvenlik Komitesi - EĞLENCE VE ÇALIŞMA ETKİNLİKLERİNİ
[true] query: ҚМГ АЛТЫН ЕРЕЖЕЛЕРІ - ЕҢбек қауіпсіздігі және еңбекті қОРҒау жиналыстарын



[pred] query: PSİKOLOJİ sınav reçetesinin rejimi test nömrəsi pdf 18.10.18 18.10.18 18.10.18 18.10.18
[true] query: психометриялық тестілеу кестесі инструкция по приму апелляциялық ведомость 18.10.2018 ж No 578 бұйры



[pred] query: İlhan Uzuner - i.İ.İ. - Büyük İslâm Devleti Güçlü Yazarlar
[true] query: Ыбырай Алтынсарин - Ы - Ұлы заман Тұлғалары - Скачать Рефераты,
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720139916/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720139916
{'eval_loss': 5.384270668029785, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.24821368075508957, 'eval_token_set_recall': 0.30344516153780887, 'eval_token_set_f1': 0.270409851271171, 'eval_token_set_f1_sem': 0.0037684405237610775, 'eval_n_ngrams_match_1': 3.9, 'eval_n_ngrams_match_2': 1.232, 'eval_n_ngrams_match_3': 0.114, 'eval_num_true_words': 15.352, 'eval_num_pred_words': 14.964, 'eval_bleu_score': 6.454180157782856, 'eval_bleu_score_sem': 0.1418886547972797, 'eval_rouge_score': 0.16822692240978848, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8696866035461426, 'eval_emb_cos_sim_sem': 0.00855200649463338, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 84.5575, 'eval_samples_per_second': 5.913, 'eval_steps_per_second': 0.745}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/kaz_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: MHP Karabük eğri̇m eğri̇m - ÇALIŞMA VE YARDIMLAŞMA
[true] query: ҚМГ АЛТЫН ЕРЕЖЕЛЕРІ - ЕҢбек қауіпсіздігі және еңбекті қОРҒау жиналыстарын



[pred] query: Psikoloji sınavı adlı prosedür mevzuatı атестамент таблица 18.10.18 атестамент таблица
[true] query: психометриялық тестілеу кестесі инструкция по приму апелляциялық ведомость 18.10.2018 ж No 578 бұйры



[pred] query: İsmail Uzunay - Büyük İmparatorlar Dağrısı - Yazarlar - Kültür-Sanat
[true] query: Ыбырай Алтынсарин - Ы - Ұлы заман Тұлғалары - Скачать Рефераты,
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720142626/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720142626
{'eval_loss': 5.384270668029785, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2503421544056219, 'eval_token_set_recall': 0.29821986725864424, 'eval_token_set_f1': 0.2696186171575994, 'eval_token_set_f1_sem': 0.0037578981081626715, 'eval_n_ngrams_match_1': 3.954, 'eval_n_ngrams_match_2': 1.264, 'eval_n_ngrams_match_3': 0.13, 'eval_num_true_words': 15.352, 'eval_num_pred_words': 15.392, 'eval_bleu_score': 6.472815947641374, 'eval_bleu_score_sem': 0.1414019655989712, 'eval_rouge_score': 0.16891296212700663, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8988559246063232, 'eval_emb_cos_sim_sem': 0.008205452715663537, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2666.0813, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/kaz_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating cmn_Hani val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: [vc_column][vc_column][vc_column][vc_column]Birinci çeyrekte artış gösteren ekonomik durum
[true] query: 下行以及现货成交偏弱拖累,市场主导地区价格继续快速调低,邯郸中板价格重



[pred] query: <strong><strong><strong><strong><strong><strong><strong><strong><strong>Buzdolabı ekonomik dayanıklılık gösteren
[true] query: 每日彩票 珍珠棉的包装定位是一种具有高强的缓冲吸震抗震作用的有明显环保效力的包装



[pred] query: [china.china.china.china.china.china]Yılın ilk aylarında kullanıcıların sunduğu cryptocurrency hesap işlem platformu
[true] query: 火币云于上个月刚刚推出,允许用户开发他们自己的类似火币网的数字货币交易平台,其中包括钱
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720142725/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720142725
{'eval_loss': 5.97467565536499, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.9140625, 'eval_token_set_precision': 0.37221605733447904, 'eval_token_set_recall': 0.24347206325666138, 'eval_token_set_f1': 0.27502793652106405, 'eval_token_set_f1_sem': 0.0035004658631847705, 'eval_n_ngrams_match_1': 2.59, 'eval_n_ngrams_match_2': 1.012, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 7.802, 'eval_num_pred_words': 19.356, 'eval_bleu_score': 4.200214118700305, 'eval_bleu_score_sem': 0.11052630431684371, 'eval_rouge_score': 0.14987191884880185, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8273188471794128, 'eval_emb_cos_sim_sem': 0.004507985428421222, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 77.388, 'eval_samples_per_second': 6.461, 'eval_steps_per_second': 0.814}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/cmn_Hani_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: [vc_column][vc_column][vc_column][vc_column]Satış hacmi hızla artış gösteren hakim
[true] query: 下行以及现货成交偏弱拖累,市场主导地区价格继续快速调低,邯郸中板价格重



[pred] query: <strong><strong><strong><strong><strong><strong><strong>Buzdolabı plastik kampanyasında fark yaratan ekonomik dayanıklı
[true] query: 每日彩票 珍珠棉的包装定位是一种具有高强的缓冲吸震抗震作用的有明显环保效力的包装



[pred] query: [china.china.china.china.china.china.china üyelerinin bir dönem boyunca sunduğu sunmoney hesap hizmet
[true] query: 火币云于上个月刚刚推出,允许用户开发他们自己的类似火币网的数字货币交易平台,其中包括钱
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720145432/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720145432
{'eval_loss': 5.97467565536499, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.9140625, 'eval_token_set_precision': 0.3709735647393551, 'eval_token_set_recall': 0.23722303711080872, 'eval_token_set_f1': 0.2724332443727068, 'eval_token_set_f1_sem': 0.0034360451543417204, 'eval_n_ngrams_match_1': 2.57, 'eval_n_ngrams_match_2': 1.016, 'eval_n_ngrams_match_3': 0.008, 'eval_num_true_words': 7.802, 'eval_num_pred_words': 20.524, 'eval_bleu_score': 3.874663989707692, 'eval_bleu_score_sem': 0.07666915113327886, 'eval_rouge_score': 0.1350246756258322, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8307362794876099, 'eval_emb_cos_sim_sem': 0.005097877659263505, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2663.0733, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/cmn_Hani_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating jpn_Jpan val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: [quote][quote][quote][quote][quote]Japonya yaz tatili başlamadan yaklaşık yarım saat sonra çıkış 
[true] query: 花立山荘では夜半から雨が降り続いていて、朝にちょっとだけ雨脚が弱くなったときに出発。 しばらく



[pred] query: [video]Hokkaido'daki ilk kış soğumasıyla birlikte devam eden kış soğumasıyla birlikte...
[true] query: 今シーズン初の凍結した桧原湖の湖上撮影です。 かなり結氷は進んでいましたが、まだワカサギ



[pred] query: [youtube|youtube|youtube|youtube|youtube|youtube]Bence bu takıma sahip olan kişilerin gerçekten medya markası
[true] query: まず少なくともこの人たちチームにネット周りが強い人間がいることは間違いなくて、YouTubeのメタタグ(メタタグって?って人はこの記事
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720145532/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720145532
{'eval_loss': 6.205530166625977, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.5405758180416061, 'eval_token_set_recall': 0.19799856904623123, 'eval_token_set_f1': 0.2683660883470476, 'eval_token_set_f1_sem': 0.003699040744191559, 'eval_n_ngrams_match_1': 2.306, 'eval_n_ngrams_match_2': 1.018, 'eval_n_ngrams_match_3': 0.004, 'eval_num_true_words': 4.93, 'eval_num_pred_words': 18.106, 'eval_bleu_score': 4.638199611650663, 'eval_bleu_score_sem': 0.10242385111633845, 'eval_rouge_score': 0.14306247161838204, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8473864197731018, 'eval_emb_cos_sim_sem': 0.009063436110799808, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 78.0266, 'eval_samples_per_second': 6.408, 'eval_steps_per_second': 0.807}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/jpn_Jpan_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: [color=blue][color=blue][color=blue][color=blue][color=blue]Haziran tatilinden sonra çık
[true] query: 花立山荘では夜半から雨が降り続いていて、朝にちょっとだけ雨脚が弱くなったときに出発。 しばらく



[pred] query: [Hokkaido,japan] kış sezonunun ilk kış çekimi devam ederken ancak şimdiye kadar yapılacak olan
[true] query: 今シーズン初の凍結した桧原湖の湖上撮影です。 かなり結氷は進んでいましたが、まだワカサギ



[pred] query: [youtube][youtube][youtube][youtube]Bence bu takıma sahip olan kişilerin özellikle son yıllardaki medya gücü
[true] query: まず少なくともこの人たちチームにネット周りが強い人間がいることは間違いなくて、YouTubeのメタタグ(メタタグって?って人はこの記事
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720148241/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720148241
{'eval_loss': 6.205530166625977, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.5394284691916257, 'eval_token_set_recall': 0.20652107703098505, 'eval_token_set_f1': 0.2747906472834257, 'eval_token_set_f1_sem': 0.0037798393984658325, 'eval_n_ngrams_match_1': 2.294, 'eval_n_ngrams_match_2': 1.022, 'eval_n_ngrams_match_3': 0.006, 'eval_num_true_words': 4.93, 'eval_num_pred_words': 18.208, 'eval_bleu_score': 4.52508191235373, 'eval_bleu_score_sem': 0.09559276211765587, 'eval_rouge_score': 0.14001384600607403, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8473891615867615, 'eval_emb_cos_sim_sem': 0.012009719458487951, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 2665.8766, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/jpn_Jpan_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating kor_Hang val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: '); } var month = [1,2,3,4,5,6,7,8,9,10,11,12]; var month = [1,2,3,4,5,6,7,8,9,10,11,12]; var month = [1,2,3,4,5,6,7,8,9,10,11,12]; var
[true] query: 세일 중 – Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price



[pred] query: tercih iddia ve güvenlik nedenleri | Mynet bahis | Mynet bahis Haberleri | Mynet bahis [product_
[true] query: 신용위험 결정요인 과 관련 - 토토사이트 검증사이트 메이저토토사이트 - 토토탐정 - 신



[pred] query: Tayfun - Android - iPhone - Teknoloji - ODANET İki ülkede yeni çıkan samsung 
[true] query: 안드로이드 : 삼성바다폰 영국 온라인 등록 - 타이젠 - 안드로이드 스마트폰과 태블릿 새
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720148351/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720148351
{'eval_loss': 5.901504039764404, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22559225372151118, 'eval_token_set_recall': 0.26310713619026344, 'eval_token_set_f1': 0.23718934252448898, 'eval_token_set_f1_sem': 0.003839913178259645, 'eval_n_ngrams_match_1': 3.226, 'eval_n_ngrams_match_2': 1.126, 'eval_n_ngrams_match_3': 0.074, 'eval_num_true_words': 14.33, 'eval_num_pred_words': 16.288, 'eval_bleu_score': 5.432757028956929, 'eval_bleu_score_sem': 0.10747213954331267, 'eval_rouge_score': 0.1546662557945533, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8744000792503357, 'eval_emb_cos_sim_sem': 0.01645903976650455, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 87.5076, 'eval_samples_per_second': 5.714, 'eval_steps_per_second': 0.72}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/kor_Hang_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: '); var month = [1,2,3,4,5,6,7,8,9,10,11,12]; var month = [1,2,3,4,5,6,7,8,9,10,11,12]; var month = [1,2,3,4,5,6,7,8,9,10,11,12]; var month
[true] query: 세일 중 – Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price



[pred] query: oyuncu tercihinde gereklilik iddia | MyGame | www.mygame.com oyuncu tercihinde gereklilik iddia
[true] query: 신용위험 결정요인 과 관련 - 토토사이트 검증사이트 메이저토토사이트 - 토토탐정 - 신



[pred] query: Tayzen - Türkçe - Teknoloji - ODANET İngiltere ve Singapur arasında çıkan yeni akıllı telefon
[true] query: 안드로이드 : 삼성바다폰 영국 온라인 등록 - 타이젠 - 안드로이드 스마트폰과 태블릿 새
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720151061/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720151061
{'eval_loss': 5.901504039764404, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2270842634317871, 'eval_token_set_recall': 0.26760960670736256, 'eval_token_set_f1': 0.2394828756900657, 'eval_token_set_f1_sem': 0.0039031554756232393, 'eval_n_ngrams_match_1': 3.266, 'eval_n_ngrams_match_2': 1.152, 'eval_n_ngrams_match_3': 0.09, 'eval_num_true_words': 14.33, 'eval_num_pred_words': 16.204, 'eval_bleu_score': 5.415761791108635, 'eval_bleu_score_sem': 0.11002540631568582, 'eval_rouge_score': 0.16034550106770093, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8707962036132812, 'eval_emb_cos_sim_sem': 0.017852712240392313, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2667.0355, 'eval_samples_per_second': 0.187, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/kor_Hang_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mon_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Ölüm gücü artırdı - ppt video online indir Ölüm gücü artırdı ABD'de 56 milyon 
[true] query: Алтны олборлолт амжилтад хүрнэ ОХУын гадаад өр 56 тэрбум ам.доллар болж өсчээ



[pred] query: Google aracılığıyla göz atın 3 önemli değişiklik | GREAT TIMES Google aracılığıyla göz atın 3 önem
[true] query: Google Текстийн зарын өөрчлөлтийг анхаарч үзэх 3 зүйл | Martech Zone Google Текстийн зарын



[pred] query: ŞÖP EDİLMESİ (85) (85) (85) (85) (85) (85) (85) (85) (85) (85) 
[true] query: » СЕКС (1085550) » ШАР МЭДЭЭ (805751) » ӨГҮҮЛЛЭГ (906359) хөлийг 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720151162/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720151162
{'eval_loss': 6.580191135406494, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22053302780810563, 'eval_token_set_recall': 0.2937312075179729, 'eval_token_set_f1': 0.24704098233017022, 'eval_token_set_f1_sem': 0.0034064054100132355, 'eval_n_ngrams_match_1': 3.156, 'eval_n_ngrams_match_2': 1.138, 'eval_n_ngrams_match_3': 0.084, 'eval_num_true_words': 14.004, 'eval_num_pred_words': 13.706, 'eval_bleu_score': 6.657612816603934, 'eval_bleu_score_sem': 0.12984016584833794, 'eval_rouge_score': 0.17177492517129683, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8805269002914429, 'eval_emb_cos_sim_sem': 0.012334808637764604, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 77.9651, 'eval_samples_per_second': 6.413, 'eval_steps_per_second': 0.808}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/mon_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Ölüm gücü artırdı - ppt video online indir Azerbaycan'ın altın ihracatı 56 milyar do
[true] query: Алтны олборлолт амжилтад хүрнэ ОХУын гадаад өр 56 тэрбум ам.доллар болж өсчээ



[pred] query: Görmeniz gereken 3 Google changes in the grammar bölümü | ŞARKUL AVSAT Görmeniz gereken 3 Google 
[true] query: Google Текстийн зарын өөрчлөлтийг анхаарч үзэх 3 зүйл | Martech Zone Google Текстийн зарын



[pred] query: ŞÖP EDİLMESİ (8035) (8035) (8035) (8035) (8035) Sex ŞÖP EDİ
[true] query: » СЕКС (1085550) » ШАР МЭДЭЭ (805751) » ӨГҮҮЛЛЭГ (906359) хөлийг 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720153869/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720153869
{'eval_loss': 6.580191135406494, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22306892226280817, 'eval_token_set_recall': 0.29126407440169105, 'eval_token_set_f1': 0.2475867849910575, 'eval_token_set_f1_sem': 0.0033701859366903207, 'eval_n_ngrams_match_1': 3.182, 'eval_n_ngrams_match_2': 1.138, 'eval_n_ngrams_match_3': 0.08, 'eval_num_true_words': 14.004, 'eval_num_pred_words': 13.83, 'eval_bleu_score': 6.560522523085382, 'eval_bleu_score_sem': 0.1354251101974817, 'eval_rouge_score': 0.17492184207493813, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9110767841339111, 'eval_emb_cos_sim_sem': 0.004277948917065524, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 2663.7912, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/mon_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating hun_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Fonksiyonel segítség: tüz ağrısı (ücretsiz) tüz ağrısı (ücretsiz) tüz ağrısı
[true] query: Ultrahang kezelés: Fájdalomcsillapítás tűszűrás nélkül [teljes útmutató] Ízületi fájdalom fono



[pred] query: Antrenman, yeni Mike Tyson | Fanatik Antrenman, yeni Mike Tyson 15.12.2019, 13:40 15.12.2019, 
[true] query: Az új Mike Tyson | SamanSport.hu 2019. 12. 13., Péntek, 18:40 Gervonta "Tank" Davis hatalmas



[pred] query: Az hatalmas gépkocsiról: az hatalmas gépkocsiról | Fanatik Az hatalmas gépkocsiról: az 
[true] query: Járművek | Hobbi Zóna - Part 2 TankChair – az Off Road tolószék A rendkívüli gépezet
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720153972/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720153972
{'eval_loss': 3.707455635070801, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.26386007156757946, 'eval_token_set_recall': 0.3948809360574079, 'eval_token_set_f1': 0.31169462611404447, 'eval_token_set_f1_sem': 0.004212359057031874, 'eval_n_ngrams_match_1': 4.362, 'eval_n_ngrams_match_2': 1.298, 'eval_n_ngrams_match_3': 0.126, 'eval_num_true_words': 16.376, 'eval_num_pred_words': 15.666, 'eval_bleu_score': 6.239352186463938, 'eval_bleu_score_sem': 0.13235893211135868, 'eval_rouge_score': 0.20171978327842321, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9007292985916138, 'eval_emb_cos_sim_sem': 0.008275561363983377, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 81.4304, 'eval_samples_per_second': 6.14, 'eval_steps_per_second': 0.774}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/hun_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Fonksiyonel tüz ağrısı: ücretsiz telefon yardımı Fonksiyonel tüz ağrısı: ücretsiz telefon
[true] query: Ultrahang kezelés: Fájdalomcsillapítás tűszűrás nélkül [teljes útmutató] Ízületi fájdalom fono



[pred] query: Antrenman, Mike Tyson | GriHat.tv Antrenman, Mike Tyson 14.12.2019, 15:15 14.12.2019, 
[true] query: Az új Mike Tyson | SamanSport.hu 2019. 12. 13., Péntek, 18:40 Gervonta "Tank" Davis hatalmas



[pred] query: Az hatalmas gépkocsi: Off-Road Show 2 | Tóraszék Az hatalmas gépkocsi: Off-Road Show 2
[true] query: Járművek | Hobbi Zóna - Part 2 TankChair – az Off Road tolószék A rendkívüli gépezet
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720156685/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720156685
{'eval_loss': 3.707455635070801, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.268892074042229, 'eval_token_set_recall': 0.3926517973856223, 'eval_token_set_f1': 0.31448870968292936, 'eval_token_set_f1_sem': 0.004170816775705727, 'eval_n_ngrams_match_1': 4.444, 'eval_n_ngrams_match_2': 1.338, 'eval_n_ngrams_match_3': 0.122, 'eval_num_true_words': 16.376, 'eval_num_pred_words': 15.816, 'eval_bleu_score': 6.344510178390272, 'eval_bleu_score_sem': 0.12447901630594708, 'eval_rouge_score': 0.21325259223798404, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9233015179634094, 'eval_emb_cos_sim_sem': 0.00931995434318276, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 2668.7909, 'eval_samples_per_second': 0.187, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/hun_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mhr_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Geçen hafta da mücadele edeyim, Geçen hafta da mücadele edeyim Tuğçe Çal
[true] query: Тургым жапыште, шошо ага годым, кеч ик гана Кугу Качак ялыште лияш



[pred] query: Güney âdemin âdemin âdemin âdemin âdemin? Marju Marju
[true] query: Мо тыгай Агавайрем? Кузе тудо эрта? Тиде да моло йодышлан вашмутым Марий в



[pred] query: «Neroski efsanesi nеr-i nеr-i nеr Puşko
[true] query: Коряк рвезе Пётр Нестеров дене мый Наро-Фоминск олаште эртыше «По
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720156785/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720156785
{'eval_loss': 5.852706432342529, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23381969223586876, 'eval_token_set_recall': 0.35678084317643205, 'eval_token_set_f1': 0.2780739459585843, 'eval_token_set_f1_sem': 0.003507458904320492, 'eval_n_ngrams_match_1': 3.32, 'eval_n_ngrams_match_2': 1.156, 'eval_n_ngrams_match_3': 0.11, 'eval_num_true_words': 13.858, 'eval_num_pred_words': 12.378, 'eval_bleu_score': 7.097576915606693, 'eval_bleu_score_sem': 0.12357267699639247, 'eval_rouge_score': 0.21313852517735554, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8795145750045776, 'eval_emb_cos_sim_sem': 0.007552782424692024, 'eval_emb_top1_equal': 1.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 77.9773, 'eval_samples_per_second': 6.412, 'eval_steps_per_second': 0.808}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/mhr_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Geçen hafta da kavga edeyim, Geçen hafta da kavga edeyim Gamel Tuğçe
[true] query: Тургым жапыште, шошо ага годым, кеч ик гана Кугу Качак ялыште лияш



[pred] query: Mar аааааааааааааааааааа? Mar ааа
[true] query: Мо тыгай Агавайрем? Кузе тудо эрта? Тиде да моло йодышлан вашмутым Марий в



[pred] query: «Nore eğ eğ eğ eğ eğ eğ eğ eğ 
[true] query: Коряк рвезе Пётр Нестеров дене мый Наро-Фоминск олаште эртыше «По
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720159478/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720159478
{'eval_loss': 5.852706432342529, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23584235290852948, 'eval_token_set_recall': 0.35581826604767836, 'eval_token_set_f1': 0.27895928816717036, 'eval_token_set_f1_sem': 0.0034475764628975653, 'eval_n_ngrams_match_1': 3.376, 'eval_n_ngrams_match_2': 1.158, 'eval_n_ngrams_match_3': 0.102, 'eval_num_true_words': 13.858, 'eval_num_pred_words': 12.84, 'eval_bleu_score': 7.0667450531499245, 'eval_bleu_score_sem': 0.11783416745863698, 'eval_rouge_score': 0.21544852697970793, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.858016848564148, 'eval_emb_cos_sim_sem': 0.008039677306669048, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2649.4397, 'eval_samples_per_second': 0.189, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/mhr_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating fin_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Osallistuma sürecini tarkenn, muutoksen devam etmesini sürdüren. Palvelinympäristö muutta, asiakasta
[true] query: Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. Työympäristö muutos hankkeissa tuotetaan myö



[pred] query: Hayatta olmak - hayatta olmak - hayatta olmak - hayatta olmak. PIA Pohjois-Amerikan
[true] query: Pohjois-suomalaisuus ja kaikille arvokas elämä - siinä tavoitteet toiminnalle. Työskentelen Diakonia-



[pred] query: Nachfolgend berichteten wir darüber, dass koivunaisten gesundheitlichen Eigenschaften, sondern auch
[true] query: Kun kirjoitimme koivunjalojen lääketieteellisistä ominaisuuksista, mainitsimme, että paitsi munuaiset, myös ko
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720159579/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720159579
{'eval_loss': 5.089448928833008, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.20911204876994358, 'eval_token_set_recall': 0.26914683963267555, 'eval_token_set_f1': 0.22979425688503635, 'eval_token_set_f1_sem': 0.0030988911891521803, 'eval_n_ngrams_match_1': 3.354, 'eval_n_ngrams_match_2': 1.104, 'eval_n_ngrams_match_3': 0.042, 'eval_num_true_words': 15.462, 'eval_num_pred_words': 14.734, 'eval_bleu_score': 5.834093984298422, 'eval_bleu_score_sem': 0.09109636177026466, 'eval_rouge_score': 0.11735386107930237, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8858370780944824, 'eval_emb_cos_sim_sem': 0.009872224914100752, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 78.5735, 'eval_samples_per_second': 6.363, 'eval_steps_per_second': 0.802}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/fin_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Osallistuma sürecini yeniden devam ediyoruz. Tüketicinin hayatı, ihtiyaç ve katkısının muotosuna
[true] query: Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. Työympäristö muutos hankkeissa tuotetaan myö



[pred] query: Hayata dienen - tüm hayata dienen - tüm hayata dienen... Pohjois-Pohjanmaa Diakoni
[true] query: Pohjois-suomalaisuus ja kaikille arvokas elämä - siinä tavoitteet toiminnalle. Työskentelen Diakonia-



[pred] query: Dazu berichteten wir, dass molekülsäuren, sowohl gesundheitlichen Eigenschaften, als auch koju
[true] query: Kun kirjoitimme koivunjalojen lääketieteellisistä ominaisuuksista, mainitsimme, että paitsi munuaiset, myös ko
outptufile for decoded sequences:  saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720162281/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_latn-script_32_2layers_corrector/_decoded_eval_1720162281
{'eval_loss': 5.089448928833008, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2082247965055242, 'eval_token_set_recall': 0.26386973668746116, 'eval_token_set_f1': 0.22659652899276336, 'eval_token_set_f1_sem': 0.0031733327354410627, 'eval_n_ngrams_match_1': 3.344, 'eval_n_ngrams_match_2': 1.11, 'eval_n_ngrams_match_3': 0.046, 'eval_num_true_words': 15.462, 'eval_num_pred_words': 15.008, 'eval_bleu_score': 5.743753518823514, 'eval_bleu_score_sem': 0.0832933315732464, 'eval_rouge_score': 0.1174844489062978, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8837782144546509, 'eval_emb_cos_sim_sem': 0.006969787459754098, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 2658.8089, 'eval_samples_per_second': 0.188, 'eval_steps_per_second': 0.024}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_lat_scrp_32_2layers_prefix/evaluations/fin_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.53 GiB of which 7.75 GiB is free. Including non-PyTorch memory, this process has 36.77 GiB memory in use. Of the allocated memory 29.91 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
