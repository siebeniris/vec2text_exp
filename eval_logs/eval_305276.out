working directory /home/cs.aau.dk/ng78zb/vec2text_exp
sif /home/cs.aau.dk/ng78zb/pytorch_23.10-py3.sif
launch evaluation yiyic/mt5_me5_deu_Latn_32_2layers_corrector with batch size 8
loading experiment and trainer from yiyic/mt5_me5_deu_Latn_32_2layers_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector
on rank 0, output dir: saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_me5_deu_Latn_32_2layers_inverter
on rank 0, output dir: saves/yiyic__mt5_me5_deu_Latn_32_2layers_inverter
adding embedding type to dataset args.
Loading datasets with TOKENIZERS_PARALLELISM = False
loading train dataset from path: /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/9611798e53dc59310add381e5e858b5a.arrow
loaded dict of val datasets from /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/b7c2d88873c9bb4061ee54b83d4d22ce.arrow
07/04/2024 14:31:10 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
07/04/2024 14:32:12 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
data arguments for experiment: DataArguments(dataset_name='mt-ms_deu_Latn', max_eval_samples=500, use_less_data=3000)
model yiyic/mt5_me5_deu_Latn_32_2layers_corrector parameters 890566656
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
Using Frozen Embeddings as Input -- Val datasets
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '24e7b7ef1b0606ddc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7cf9deee5c6ee34dc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7d3c7a3fdc899099c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'a808a07212534aa6c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '1835610d5c7fc595c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '74575508bfab4c9cc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'af6bef1b30e3c5dbc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'bfa2f55e85bb2562c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd839c9a8871bbce8c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '67555e67fd16afc9c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '48ec325196197014c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'a20c740ae5a0d86bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'cc2235accdffe49bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '104320b250ecc6cac111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd7b432ef61da1e93c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'c06e214a198bcc2cc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '3ae3df71733802abc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '18a40ab4beb7f210c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '96cd5258a58b461bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7ee1e04e96a3faa2c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
output dir ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations
evaluating deu_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conventionstore. Die Artikel sind nach Relevanz sort
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Beauty & Hair Studio bietet Ihnen ein breites Spektrum an Beauty Services rund um Ihre Gesundheit und Haare
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720096594/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720096594
{'eval_loss': 1.2666798830032349, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6012144991631357, 'eval_token_set_recall': 0.6343728148315539, 'eval_token_set_f1': 0.6158780276214046, 'eval_token_set_f1_sem': 0.007959029323600262, 'eval_n_ngrams_match_1': 11.642, 'eval_n_ngrams_match_2': 6.128, 'eval_n_ngrams_match_3': 3.712, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.846, 'eval_bleu_score': 27.347423776136807, 'eval_bleu_score_sem': 1.196855443166141, 'eval_rouge_score': 0.5878332755379766, 'eval_exact_match': 0.072, 'eval_exact_match_sem': 0.011571508095282932, 'eval_emb_cos_sim': 0.9562997817993164, 'eval_emb_cos_sim_sem': 0.010541430599123203, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 110.6382, 'eval_samples_per_second': 4.519, 'eval_steps_per_second': 0.569}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/deu_Latn_steps-1.json
evaluating corrector with steps 20
[pred] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conventionstore. Die Artikel sind nach Relevanz sort
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Beauty & Hair Studio bietet Ihnen ein breites Spektrum an Beauty Services rund um Ihre Gesundheit und Wellness.
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720097319/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720097319
{'eval_loss': 1.2666798830032349, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6098570640648444, 'eval_token_set_recall': 0.6350738924145505, 'eval_token_set_f1': 0.6207426473047437, 'eval_token_set_f1_sem': 0.008203038888981884, 'eval_n_ngrams_match_1': 11.796, 'eval_n_ngrams_match_2': 6.29, 'eval_n_ngrams_match_3': 3.864, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.906, 'eval_bleu_score': 28.132598592315016, 'eval_bleu_score_sem': 1.212651379706321, 'eval_rouge_score': 0.5943170996092643, 'eval_exact_match': 0.074, 'eval_exact_match_sem': 0.011718474529160406, 'eval_emb_cos_sim': 0.9497199058532715, 'eval_emb_cos_sim_sem': 0.011080513157724334, 'eval_emb_top1_equal': 0.75, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 724.4535, 'eval_samples_per_second': 0.69, 'eval_steps_per_second': 0.087}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/deu_Latn_steps-20.json
evaluating corrector with steps 50
[pred] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conventionstore. Die Artikel sind nach Relevanz sort
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Beauty & Hair Studio bietet Ihnen ein breites Spektrum an Beauty Services rund um Ihre Gesundheit und Wellness.
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720098929/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720098929
{'eval_loss': 1.2666798830032349, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6107321663559516, 'eval_token_set_recall': 0.6347241812303697, 'eval_token_set_f1': 0.6211718348228569, 'eval_token_set_f1_sem': 0.008222572973466716, 'eval_n_ngrams_match_1': 11.82, 'eval_n_ngrams_match_2': 6.31, 'eval_n_ngrams_match_3': 3.89, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.962, 'eval_bleu_score': 28.24068456773315, 'eval_bleu_score_sem': 1.2108703089586943, 'eval_rouge_score': 0.5957145213073562, 'eval_exact_match': 0.074, 'eval_exact_match_sem': 0.011718474529160406, 'eval_emb_cos_sim': 0.9445474147796631, 'eval_emb_cos_sim_sem': 0.013129742981706608, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 1610.6269, 'eval_samples_per_second': 0.31, 'eval_steps_per_second': 0.039}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/deu_Latn_steps-50.json
evaluating corrector with steps 50 and beam width 4
[pred] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unser Beauty & Hair Studio bietet Ihnen eine große Palette an Dienstleistungen rund um Beauty und Wellness. Dabei geht
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: ❱ Unsere Bestenliste Dec/2022 ☑ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720103307/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720103307
{'eval_loss': 1.2666798830032349, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.6404255405424508, 'eval_token_set_recall': 0.6668814854395987, 'eval_token_set_f1': 0.6516367831230977, 'eval_token_set_f1_sem': 0.008054846608706128, 'eval_n_ngrams_match_1': 12.4, 'eval_n_ngrams_match_2': 6.836, 'eval_n_ngrams_match_3': 4.25, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.81, 'eval_bleu_score': 30.52965412439334, 'eval_bleu_score_sem': 1.2470148945450843, 'eval_rouge_score': 0.6360817083676542, 'eval_exact_match': 0.064, 'eval_exact_match_sem': 0.01095664621097098, 'eval_emb_cos_sim': 0.9695841073989868, 'eval_emb_cos_sim_sem': 0.009628234832437663, 'eval_emb_top1_equal': 0.875, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4377.8495, 'eval_samples_per_second': 0.114, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/deu_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 10.46 GiB is free. Including non-PyTorch memory, this process has 34.09 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 3.87 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating ydd_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: KAYAK / Küste / Küste / Küste / Küste / Küste / Küste 5
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: Suḥaẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓẓ
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: Wir wollen euch entschuldigen: Melania Trump fordert unseren Entwurf: Melania Trump 
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720103473/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720103473
{'eval_loss': 7.519521713256836, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.21188354486071237, 'eval_token_set_recall': 0.3360369871872199, 'eval_token_set_f1': 0.24887314851405687, 'eval_token_set_f1_sem': 0.003297288634716722, 'eval_n_ngrams_match_1': 3.06, 'eval_n_ngrams_match_2': 1.08, 'eval_n_ngrams_match_3': 0.044, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 14.192, 'eval_bleu_score': 5.633747431383502, 'eval_bleu_score_sem': 0.08062183365522972, 'eval_rouge_score': 0.18313256272431389, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8688660860061646, 'eval_emb_cos_sim_sem': 0.00689184015615574, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 128.7878, 'eval_samples_per_second': 3.882, 'eval_steps_per_second': 0.489}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/ydd_Hebr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 9.16 GiB is free. Including non-PyTorch memory, this process has 35.39 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.17 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.85 GiB is free. Including non-PyTorch memory, this process has 36.70 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: KAYAK 5 / KAYAK 6 / KAYAK 7 / KAYAK 8 / Tschechische Insel
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: Suḥaḥaḥaḥaḥaḥaḥaḥaḥaḥaḥaḥaḥaḥ
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: Wir wollen ihn entschuldigen: Wir wollen ihn entschuldigen: Pamela Tappa Tappa
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720107929/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720107929
{'eval_loss': 7.519521713256836, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.20726951603608001, 'eval_token_set_recall': 0.3381598111812513, 'eval_token_set_f1': 0.24459676282965964, 'eval_token_set_f1_sem': 0.0032227064587834913, 'eval_n_ngrams_match_1': 2.978, 'eval_n_ngrams_match_2': 1.072, 'eval_n_ngrams_match_3': 0.032, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 14.542, 'eval_bleu_score': 5.417911722602554, 'eval_bleu_score_sem': 0.07263906489110879, 'eval_rouge_score': 0.18094150147729005, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8445966243743896, 'eval_emb_cos_sim_sem': 0.009255358370939243, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4383.8324, 'eval_samples_per_second': 0.114, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/ydd_Hebr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating heb_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: In einem wissenschaftlichen Forschungsprojekt, welches sich letzte Woche unter dem Titel “Why I have been persecuted”
[true] query: במחקר שהתפרסם לאחרונה (ואני מתנצל שלא הגעתי לדון בו עד כה מפאת עניינים אחר



[pred] query: LAWLINET. Eine nationale Qualifikation, welche sich u.a. durch RADIATION, unsere
[true] query: תוכנית ריאליטי בישראל היא לא רק תוכנית ריאליטי. היא שיעור באזרחות,



[pred] query: Diese Anfrage beantragt Ihnen einen Urteil, welches Ihnen einen Urteil MAZ 21.04.2011 sowie
[true] query: בפני בקשה לעיכוב ביצוע פסק הדין אשר ניתן ביום 20.4.11 ואשר במסגרתו חו
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720108089/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720108089
{'eval_loss': 7.5442938804626465, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19154484285064824, 'eval_token_set_recall': 0.20593043962401564, 'eval_token_set_f1': 0.1958460065959517, 'eval_token_set_f1_sem': 0.0027331713241043245, 'eval_n_ngrams_match_1': 3.184, 'eval_n_ngrams_match_2': 1.048, 'eval_n_ngrams_match_3': 0.022, 'eval_num_true_words': 15.944, 'eval_num_pred_words': 16.89, 'eval_bleu_score': 5.118154792589052, 'eval_bleu_score_sem': 0.045838380346182706, 'eval_rouge_score': 0.14094702235090148, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8967000842094421, 'eval_emb_cos_sim_sem': 0.003463171310008985, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 123.513, 'eval_samples_per_second': 4.048, 'eval_steps_per_second': 0.51}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/heb_Hebr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: In einem wissenschaftlichen Forschungsprojekt, welches sich letzte Woche unter den folgenden Begriffen befasst: “
[true] query: במחקר שהתפרסם לאחרונה (ואני מתנצל שלא הגעתי לדון בו עד כה מפאת עניינים אחר



[pred] query: Unsere Reihe RADIATION, welche sich u.a. durch eine nationale Qualifikation erfüllt, 
[true] query: תוכנית ריאליטי בישראל היא לא רק תוכנית ריאליטי. היא שיעור באזרחות,



[pred] query: Eine schriftliche Anfrage, welche Ihnen schriftlich beantragt wurde, bezüglich § 44 Zivilrecht
[true] query: בפני בקשה לעיכוב ביצוע פסק הדין אשר ניתן ביום 20.4.11 ואשר במסגרתו חו
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720112524/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720112524
{'eval_loss': 7.5442938804626465, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.1938949182654295, 'eval_token_set_recall': 0.2008005133583309, 'eval_token_set_f1': 0.1954143505330555, 'eval_token_set_f1_sem': 0.002718188322575806, 'eval_n_ngrams_match_1': 3.206, 'eval_n_ngrams_match_2': 1.052, 'eval_n_ngrams_match_3': 0.024, 'eval_num_true_words': 15.944, 'eval_num_pred_words': 17.08, 'eval_bleu_score': 5.041273928766825, 'eval_bleu_score_sem': 0.04508170898178874, 'eval_rouge_score': 0.1378026958145282, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8871148824691772, 'eval_emb_cos_sim_sem': 0.006869907989861883, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4361.6588, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/heb_Hebr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating arb_Arab val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Einzigartiges Dekorationskleid, bestehend aus ‚Monarch Yacht‘, ‚Monarch Yacht‘ aus
[true] query: فستان زفاف أنيق بقصّة الأميرة من نسيج الميكادو، مُزيّن بالأزهار



[pred] query: Dr. Mohammad Nawassi präsentiert auf seiner Webseite einen Privilegien Präventionsprogramm 20 Medina
[true] query: رئيس القمة الدينية لمجموعة العشرين الشيخ د.محمد العيسى يطلق منصة R20 



[pred] query: Die School of Islam e.V. strebt einen breiteren Enthusiasmus auf, sich auf Hochschulreife und
[true] query: تسعى كلية العلوم الإسلامية إلى تبوأ مكانة وسمعة مرموقة بين جامعات العالم، 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720112692/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720112692
{'eval_loss': 6.462327003479004, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.15816658283237273, 'eval_token_set_recall': 0.187515947597295, 'eval_token_set_f1': 0.16657786426185187, 'eval_token_set_f1_sem': 0.00248521665117874, 'eval_n_ngrams_match_1': 2.454, 'eval_n_ngrams_match_2': 1.036, 'eval_n_ngrams_match_3': 0.02, 'eval_num_true_words': 15.48, 'eval_num_pred_words': 16.2, 'eval_bleu_score': 4.934306064098387, 'eval_bleu_score_sem': 0.08621428008910922, 'eval_rouge_score': 0.14283603131048853, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8378649353981018, 'eval_emb_cos_sim_sem': 0.009210448269672853, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 130.9076, 'eval_samples_per_second': 3.819, 'eval_steps_per_second': 0.481}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/arb_Arab_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Einzigartige Dekoration, bestehend aus ‚Mädchen aus Zanzibar‘, ‚Mädchen aus Zanzibar‘, 
[true] query: فستان زفاف أنيق بقصّة الأميرة من نسيج الميكادو، مُزيّن بالأزهار



[pred] query: Dr. Mohammad Nawassi präsentiert auf seiner Webseite einen Präventionsprogramm R20 e.V.
[true] query: رئيس القمة الدينية لمجموعة العشرين الشيخ د.محمد العيسى يطلق منصة R20 



[pred] query: Die Faculty of Islam e.V. strebt, einen breiteren Blick auf gesellschaftliche Entwicklung und
[true] query: تسعى كلية العلوم الإسلامية إلى تبوأ مكانة وسمعة مرموقة بين جامعات العالم، 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720117128/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720117128
{'eval_loss': 6.462327003479004, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.15570617314402188, 'eval_token_set_recall': 0.18907523224969114, 'eval_token_set_f1': 0.16393232509503494, 'eval_token_set_f1_sem': 0.0023107357007089093, 'eval_n_ngrams_match_1': 2.426, 'eval_n_ngrams_match_2': 1.034, 'eval_n_ngrams_match_3': 0.02, 'eval_num_true_words': 15.48, 'eval_num_pred_words': 16.232, 'eval_bleu_score': 4.886650364427792, 'eval_bleu_score_sem': 0.08927677562916124, 'eval_rouge_score': 0.14359696991399484, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8282934427261353, 'eval_emb_cos_sim_sem': 0.015332042256946354, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 4364.0633, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/arb_Arab_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating amh_Ethi val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: 20. April 2016 eymar eymars eymars eymars eymars eymars 
[true] query: ማርች 20, 2016 የራስ ዱሜራ ደሴቶችና የባህር ግዛት የሚያሳን የኤ



[pred] query: Einheitsbewusstsein - Einheitsbewusstsein - Einheitsbewusstsein - Einheitsbewusstsein -
[true] query: አንድነት አንድነት ውስጥ ጥንካሬ - የህብረት ማህበረሰብ እንክብካቤ



[pred] query: ᐅ Weitere Veranstaltungen ᐅ Kommen 20 Bewaffneter aus Bosnien nach Ägypten bewaffnet
[true] query: ከቡናማዎቹ ጋር ነገ ወደ ዩጋንዳ የሚያቀኑ 20 ተጫዋቾች ተለይተው
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720117289/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720117289
{'eval_loss': 7.721737384796143, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.22902505455500893, 'eval_token_set_recall': 0.34116453595424284, 'eval_token_set_f1': 0.2621851056047923, 'eval_token_set_f1_sem': 0.0031050882225639185, 'eval_n_ngrams_match_1': 2.694, 'eval_n_ngrams_match_2': 1.084, 'eval_n_ngrams_match_3': 0.042, 'eval_num_true_words': 11.838, 'eval_num_pred_words': 13.48, 'eval_bleu_score': 6.201455746704216, 'eval_bleu_score_sem': 0.10234420811121127, 'eval_rouge_score': 0.1927082997784495, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8415570259094238, 'eval_emb_cos_sim_sem': 0.009425054753934263, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 124.0839, 'eval_samples_per_second': 4.03, 'eval_steps_per_second': 0.508}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/amh_Ethi_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: 20. März 2016 eymars eymars eymars eymars eymars eymars
[true] query: ማርች 20, 2016 የራስ ዱሜራ ደሴቶችና የባህር ግዛት የሚያሳን የኤ



[pred] query: Einheitsbewusstsein - Einheitsbewusstsein - Einheitsbewusstsein - Einheitsbewusstsein -
[true] query: አንድነት አንድነት ውስጥ ጥንካሬ - የህብረት ማህበረሰብ እንክብካቤ



[pred] query: Andere Veranstaltungen ᐅ 20 Auszubildende würden morgen nach Zypern fliegen ᐅ 20 Auszubildende
[true] query: ከቡናማዎቹ ጋር ነገ ወደ ዩጋንዳ የሚያቀኑ 20 ተጫዋቾች ተለይተው
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720121719/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720121719
{'eval_loss': 7.721737384796143, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2274631775431319, 'eval_token_set_recall': 0.3352766890316431, 'eval_token_set_f1': 0.2585151950142023, 'eval_token_set_f1_sem': 0.003090198178498952, 'eval_n_ngrams_match_1': 2.66, 'eval_n_ngrams_match_2': 1.086, 'eval_n_ngrams_match_3': 0.044, 'eval_num_true_words': 11.838, 'eval_num_pred_words': 13.584, 'eval_bleu_score': 6.070107752588039, 'eval_bleu_score_sem': 0.10623088083899354, 'eval_rouge_score': 0.19176641017667698, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8488644957542419, 'eval_emb_cos_sim_sem': 0.011622653338476027, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4357.243, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/amh_Ethi_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mlt_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Muscular Problems and Muscular Problems - Methoden und Übungen - Muscular Problems Muscular Problems 
[true] query: Dħul Temi Temi Problemi muskuloskeletali Practical tools and guidance - Musculoskeletal disorders



[pred] query: Posted on January 1, 2020 - Pandemie fordert den ersten Bericht einer Covid-19-Pandemie in 
[true] query: test – One News Mindu feġġ l-ewwel każ ta' coronavirus f'pajjiżna, saru aktar



[pred] query: "MfA ruft den Spielern, den er nicht erlaubt - mfA u.l.
[true] query: 'L-MFA emmnet lil min ibagħbas il-logħob u mhux lili' - Illum
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720121881/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720121881
{'eval_loss': 5.509066104888916, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.23672048270786664, 'eval_token_set_recall': 0.32994043736621187, 'eval_token_set_f1': 0.2666315738192142, 'eval_token_set_f1_sem': 0.003895862406129004, 'eval_n_ngrams_match_1': 3.378, 'eval_n_ngrams_match_2': 1.182, 'eval_n_ngrams_match_3': 0.078, 'eval_num_true_words': 13.932, 'eval_num_pred_words': 15.054, 'eval_bleu_score': 6.076833646022682, 'eval_bleu_score_sem': 0.10534179941333421, 'eval_rouge_score': 0.12786252238788615, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.891637921333313, 'eval_emb_cos_sim_sem': 0.010383058547487455, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 126.0692, 'eval_samples_per_second': 3.966, 'eval_steps_per_second': 0.5}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/mlt_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Musculoskeletal Problems and Triggers - Educational guides to the basics of Musculoskeletal Problems and
[true] query: Dħul Temi Temi Problemi muskuloskeletali Practical tools and guidance - Musculoskeletal disorders



[pred] query: Posted on January 1, 2020 - In Myanmar ereignete sich der erste Test einer Covid-19-Pandemie,
[true] query: test – One News Mindu feġġ l-ewwel każ ta' coronavirus f'pajjiżna, saru aktar



[pred] query: "MfL e.V. fordert, dass er den Spielern "mfL e.V.
[true] query: 'L-MFA emmnet lil min ibagħbas il-logħob u mhux lili' - Illum
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720126308/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720126308
{'eval_loss': 5.509066104888916, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2392700538969116, 'eval_token_set_recall': 0.32303183222006754, 'eval_token_set_f1': 0.26416952864520554, 'eval_token_set_f1_sem': 0.0037892772998022925, 'eval_n_ngrams_match_1': 3.392, 'eval_n_ngrams_match_2': 1.172, 'eval_n_ngrams_match_3': 0.072, 'eval_num_true_words': 13.932, 'eval_num_pred_words': 14.982, 'eval_bleu_score': 5.97325523959372, 'eval_bleu_score_sem': 0.10335512708341459, 'eval_rouge_score': 0.13330320956438035, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8968985676765442, 'eval_emb_cos_sim_sem': 0.01334078015473475, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 4354.6607, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/mlt_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating hin_Deva val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: :...... Muslime müssen nicht mächtig sein!.. 
[true] query: Blog News: ग़लती न करे मुसलमान!!! ग़लती न करे मुसलमान!!! 



[pred] query: Algebra 9 - Algebra 9 - Algebra 9 - Algebra 9 - Algebra 9 - Algebra 9
[true] query: RBSE Solutions for Class 9 Hindi Sparsh Chapter 11 आदमी नामा - Rbse solutions RBSE Solutions for Class 9



[pred] query: unsere regierung nimmt bereits über 14 Monate dauern, pdf download md narendra Modi 2022
[true] query: नई दिल्ली, प्रधानमंत्री नरेंद्र मोदी का कार्यकाल पूरा होने में केवल 14 महीने का वक्त बा
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720126468/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720126468
{'eval_loss': 5.304243564605713, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.1929463282746335, 'eval_token_set_recall': 0.3758413743721027, 'eval_token_set_f1': 0.242190942093104, 'eval_token_set_f1_sem': 0.004226745675230778, 'eval_n_ngrams_match_1': 3.448, 'eval_n_ngrams_match_2': 1.246, 'eval_n_ngrams_match_3': 0.118, 'eval_num_true_words': 17.206, 'eval_num_pred_words': 16.404, 'eval_bleu_score': 5.414731888362275, 'eval_bleu_score_sem': 0.1476511743259676, 'eval_rouge_score': 0.19323119735269206, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8738921284675598, 'eval_emb_cos_sim_sem': 0.01748414331852061, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 123.4581, 'eval_samples_per_second': 4.05, 'eval_steps_per_second': 0.51}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/hin_Deva_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: : : : : : ISLAMIK : Muslime müssen müssen müssen müssen müssen m
[true] query: Blog News: ग़लती न करे मुसलमान!!! ग़लती न करे मुसलमान!!! 



[pred] query: Algebra Chapter 11 - Algebra Chapter 11 - Algebra Chapter 11 - Algebra Chapter 11 -
[true] query: RBSE Solutions for Class 9 Hindi Sparsh Chapter 11 आदमी नामा - Rbse solutions RBSE Solutions for Class 9



[pred] query: unsere regierung muss mindestens 14 Monate dauern mds narendra modi, geboren 1984 in delhi
[true] query: नई दिल्ली, प्रधानमंत्री नरेंद्र मोदी का कार्यकाल पूरा होने में केवल 14 महीने का वक्त बा
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720130909/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720130909
{'eval_loss': 5.304243564605713, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.1950189845227542, 'eval_token_set_recall': 0.3878354856272044, 'eval_token_set_f1': 0.2452028634937283, 'eval_token_set_f1_sem': 0.004117638403889466, 'eval_n_ngrams_match_1': 3.49, 'eval_n_ngrams_match_2': 1.228, 'eval_n_ngrams_match_3': 0.11, 'eval_num_true_words': 17.206, 'eval_num_pred_words': 16.42, 'eval_bleu_score': 5.298094508096613, 'eval_bleu_score_sem': 0.12652169673875274, 'eval_rouge_score': 0.19436698766039678, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8719531297683716, 'eval_emb_cos_sim_sem': 0.018083143549180548, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 4368.3168, 'eval_samples_per_second': 0.114, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/hin_Deva_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating urd_Arab val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: r r r r r r r r r r r r Rubrik über
[true] query: قائداعظم سے نہرو تک ۔۔ رؤف کلاسرا مرکزی صفحہ/ لکھاری/ ر



[pred] query: Sonja Misaki wurde nicht nur außerhalb ihrer Social Media Influencer sondern ihre Social Media Influence
[true] query: سوناکشی سنہا سوشل میڈیا میمز کے نشے میں مبتلا ہو گئیں اداکارہ نہ صرف خود



[pred] query: Marathi: In den vergangenen 4 Jahren hat Maharashtra (MdL) bereits über 1450 Erwerbstätige
[true] query: نئی دہلی:مہاراشٹر میں گزشتہ 5 سالوں میں (18-2014)14034 کسانوں نے خود
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720131073/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720131073
{'eval_loss': 6.864589691162109, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.1553901825381066, 'eval_token_set_recall': 0.2569486211329096, 'eval_token_set_f1': 0.18623261912729247, 'eval_token_set_f1_sem': 0.0028393414616455933, 'eval_n_ngrams_match_1': 2.578, 'eval_n_ngrams_match_2': 1.042, 'eval_n_ngrams_match_3': 0.018, 'eval_num_true_words': 17.024, 'eval_num_pred_words': 16.132, 'eval_bleu_score': 4.620479721043695, 'eval_bleu_score_sem': 0.05646895387104733, 'eval_rouge_score': 0.15120578250705782, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.864403486251831, 'eval_emb_cos_sim_sem': 0.009877219315649293, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 127.8372, 'eval_samples_per_second': 3.911, 'eval_steps_per_second': 0.493}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/urd_Arab_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: r r r r r r r r r r r r r r
[true] query: قائداعظم سے نہرو تک ۔۔ رؤف کلاسرا مرکزی صفحہ/ لکھاری/ ر



[pred] query: Sonja Misaki wurde nicht nur außerhalb ihres Social Media Influencers in seinem Instagram Posting 
[true] query: سوناکشی سنہا سوشل میڈیا میمز کے نشے میں مبتلا ہو گئیں اداکارہ نہ صرف خود



[pred] query: Madhya Pradesh: In den vergangenen 4 Jahren hat der Landwirtschaftsstaat Madhya Pradesh (Erwachsene: 2013, 
[true] query: نئی دہلی:مہاراشٹر میں گزشتہ 5 سالوں میں (18-2014)14034 کسانوں نے خود
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720135508/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720135508
{'eval_loss': 6.864589691162109, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.15233928820540107, 'eval_token_set_recall': 0.2673862058821816, 'eval_token_set_f1': 0.1847860823586095, 'eval_token_set_f1_sem': 0.0026750599638508334, 'eval_n_ngrams_match_1': 2.516, 'eval_n_ngrams_match_2': 1.036, 'eval_n_ngrams_match_3': 0.018, 'eval_num_true_words': 17.024, 'eval_num_pred_words': 16.176, 'eval_bleu_score': 4.563825057744973, 'eval_bleu_score_sem': 0.0698764565623108, 'eval_rouge_score': 0.15140925604282351, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8569883704185486, 'eval_emb_cos_sim_sem': 0.01135856645406283, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 4361.2961, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/urd_Arab_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating guj_Gujr val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Warum heiraten, weil ihren Bruder geheiratet hätte? | Kundalini-Käsa |
[true] query: 'અમારા વિરોધીને લગ્નમાં કેમ બોલાવ્યો?' કહી કન્યાના મા-બા



[pred] query: heute geht’s über den gujarat tourism overview, heute geht’s hier gujarat tourism overview
[true] query: આજે સાંજથી કેજરીવાલની ગુજરાત યાત્રા શરૂ, જાણો આખો કાર્યક્રમ | Read here



[pred] query: hunger hunger hunger hunger hunger hunger hunger hunger hunger hunger hunger hunger 2018 von Dr.
[true] query: ફરહાનની ડૉન 3માં જોવા મળશે ગુજરાતી શાહરુખ ખાન | Shahrukh Kahn
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720135670/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720135670
{'eval_loss': 7.860496520996094, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.210942774287976, 'eval_token_set_recall': 0.2824303556952168, 'eval_token_set_f1': 0.23026616284870358, 'eval_token_set_f1_sem': 0.003238744059801742, 'eval_n_ngrams_match_1': 2.84, 'eval_n_ngrams_match_2': 1.04, 'eval_n_ngrams_match_3': 0.012, 'eval_num_true_words': 13.074, 'eval_num_pred_words': 15.074, 'eval_bleu_score': 5.368104810517941, 'eval_bleu_score_sem': 0.06567829531419814, 'eval_rouge_score': 0.16757037283426762, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8756153583526611, 'eval_emb_cos_sim_sem': 0.0094663059819143, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 125.1193, 'eval_samples_per_second': 3.996, 'eval_steps_per_second': 0.504}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/guj_Gujr_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Warum haben unsere Kund*innen gefragt, warum sie ihren Bruder geheiratet? M.A.
[true] query: 'અમારા વિરોધીને લગ્નમાં કેમ બોલાવ્યો?' કહી કન્યાના મા-બા



[pred] query: heute geht’s über den gujarat tourism overview, heute geht’s den gujarat tourism overview
[true] query: આજે સાંજથી કેજરીવાલની ગુજરાત યાત્રા શરૂ, જાણો આખો કાર્યક્રમ | Read here



[pred] query: hunger hunger hunger hunger hunger hunger hunger hunger hunger hunger hunger hunger 2018 von Dr.
[true] query: ફરહાનની ડૉન 3માં જોવા મળશે ગુજરાતી શાહરુખ ખાન | Shahrukh Kahn
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720140103/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720140103
{'eval_loss': 7.860496520996094, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.20934350749869374, 'eval_token_set_recall': 0.284730159383101, 'eval_token_set_f1': 0.22878290055298994, 'eval_token_set_f1_sem': 0.003224262986364652, 'eval_n_ngrams_match_1': 2.816, 'eval_n_ngrams_match_2': 1.044, 'eval_n_ngrams_match_3': 0.014, 'eval_num_true_words': 13.074, 'eval_num_pred_words': 15.256, 'eval_bleu_score': 5.429390674755131, 'eval_bleu_score_sem': 0.06766986603906297, 'eval_rouge_score': 0.16630384649436442, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8687702417373657, 'eval_emb_cos_sim_sem': 0.008547616636943168, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 4360.6505, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/guj_Gujr_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating sin_Sinh val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Posted by lehrerin Posted on 16. März 2016 Posted by lehrerin Posted on 16. März 2016 -
[true] query: මිනිස්සු | ඇවිද යන මඟ ← ගරු කිරීම ගුරුවරු → 16 අප් රේල් අපිට කෙනෙක් දැක්කාම ආ



[pred] query: Silhouette Veröffentlicht am März 24, 2017 | Silhouette Veröffentlicht am März 24, 2017 | Silhouette Veröffentlicht am März 24,
[true] query: සිවුමැලියා සිකුරු ලියා... | Sunday Apple සිවුමැලියා සිකුරු ලියා... March 24, 2017 | 11:00 am 0



[pred] query: Posted by Sri Lanka - Aktuelle News - Aktuelle News - Teenagergeschichte - Teenagergeschichte 
[true] query: නිළිකමට මැදි වුණේ පුංචි කෙල්ලක කාලේ... - Sri Lanka News Update නිළිකමට මැ
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720140263/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720140263
{'eval_loss': 7.270110130310059, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2113506709406867, 'eval_token_set_recall': 0.3362622985889243, 'eval_token_set_f1': 0.24891148790815026, 'eval_token_set_f1_sem': 0.0037444381153859323, 'eval_n_ngrams_match_1': 3.046, 'eval_n_ngrams_match_2': 1.1, 'eval_n_ngrams_match_3': 0.026, 'eval_num_true_words': 14.694, 'eval_num_pred_words': 15.492, 'eval_bleu_score': 5.52072300067335, 'eval_bleu_score_sem': 0.08604223279054485, 'eval_rouge_score': 0.18632252362468996, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8705187439918518, 'eval_emb_cos_sim_sem': 0.009184918474731888, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 123.4987, 'eval_samples_per_second': 4.049, 'eval_steps_per_second': 0.51}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/sin_Sinh_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Posted on 16. März 2016 Posted by lehrer_innen Posted on 16. März 2016 Posted by lehrer_innen
[true] query: මිනිස්සු | ඇවිද යන මඟ ← ගරු කිරීම ගුරුවරු → 16 අප් රේල් අපිට කෙනෙක් දැක්කාම ආ



[pred] query: Sizzimaci geschrieben am 24. März 2017 | Sizzimaci geschrieben am 24. März 2017 | Sizzimaci
[true] query: සිවුමැලියා සිකුරු ලියා... | Sunday Apple සිවුමැලියා සිකුරු ලියා... March 24, 2017 | 11:00 am 0



[pred] query: Posted by Sri Lanka - Neuigkeiten zu ihrer Kindheit Posted by Sri Lanka - Neuigkeiten zu ihrer
[true] query: නිළිකමට මැදි වුණේ පුංචි කෙල්ලක කාලේ... - Sri Lanka News Update නිළිකමට මැ
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720144694/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720144694
{'eval_loss': 7.270110130310059, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.20922080514085203, 'eval_token_set_recall': 0.3301630217735483, 'eval_token_set_f1': 0.24532319047188622, 'eval_token_set_f1_sem': 0.0036104001321828425, 'eval_n_ngrams_match_1': 3.022, 'eval_n_ngrams_match_2': 1.104, 'eval_n_ngrams_match_3': 0.032, 'eval_num_true_words': 14.694, 'eval_num_pred_words': 15.696, 'eval_bleu_score': 5.385929157049946, 'eval_bleu_score_sem': 0.09600775354316707, 'eval_rouge_score': 0.18505976736394697, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.863567590713501, 'eval_emb_cos_sim_sem': 0.009528102481454382, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 4358.2584, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/sin_Sinh_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating pan_Guru val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Schließen ohne bezahlte Produktionen Schließen ohne bezahlte Produktionen Schließen ohne bezahlte
[true] query: ਕਰੋਨਾ ਮਹਾਂਮਾਰੀ ਦੇ ਚੱਲਦੇ ਫੋਟੋਗ੍ਰਾਫਰ ਦੀਆਂ ਬੰਦ ਪਈਆਂ ਦੁਕਾਨਾਂ ਖੋ



[pred] query: Um den Wunsch der MPU zu verwirklichen, könnte er künftig erfolgreich werden - mdp -
[true] query: ਮੋਦੀ ਦੇ ਸੁਪਨਿਆਂ ਦਾ ਯੂ ਪੀ ਬਣਾਉਣ ਲਈ ਕਵਾਇਦ ਆਰੰਭ - Panja



[pred] query: Vorlagen zu meinen Erinnerungsbildern in der VHS: : : : : : :
[true] query: ਸ਼ਹੀਦਾਂ ਦੀਆਂ ਤਸਵੀਰਾਂ ਅਜਾਇਬ ਘਰ 'ਚ ਲਗਾਉਣ ਦੀ ਮੰਗ :
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720144855/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720144855
{'eval_loss': 7.423713684082031, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.21035864951182345, 'eval_token_set_recall': 0.3211880696101289, 'eval_token_set_f1': 0.24059247817366222, 'eval_token_set_f1_sem': 0.003512004101092822, 'eval_n_ngrams_match_1': 2.788, 'eval_n_ngrams_match_2': 1.058, 'eval_n_ngrams_match_3': 0.014, 'eval_num_true_words': 13.07, 'eval_num_pred_words': 15.388, 'eval_bleu_score': 5.484482513824625, 'eval_bleu_score_sem': 0.0595732179428365, 'eval_rouge_score': 0.20703657180893734, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8697797060012817, 'eval_emb_cos_sim_sem': 0.009902278251267051, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 124.0939, 'eval_samples_per_second': 4.029, 'eval_steps_per_second': 0.508}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/pan_Guru_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Schließen Schließen Schließen Schließen Schließen Schließen Schließen Schließen an den japanischen
[true] query: ਕਰੋਨਾ ਮਹਾਂਮਾਰੀ ਦੇ ਚੱਲਦੇ ਫੋਟੋਗ੍ਰਾਫਰ ਦੀਆਂ ਬੰਦ ਪਈਆਂ ਦੁਕਾਨਾਂ ਖੋ



[pred] query: Um den Wunsch der Pädagogik zu verwirklichen, könnte man künftig MPU-Pläne erarbeiten - 
[true] query: ਮੋਦੀ ਦੇ ਸੁਪਨਿਆਂ ਦਾ ਯੂ ਪੀ ਬਣਾਉਣ ਲਈ ਕਵਾਇਦ ਆਰੰਭ - Panja



[pred] query: Vorlagen zu meinen Erinnerungsbedürfnissen in den Häusern der VHS: : : : 
[true] query: ਸ਼ਹੀਦਾਂ ਦੀਆਂ ਤਸਵੀਰਾਂ ਅਜਾਇਬ ਘਰ 'ਚ ਲਗਾਉਣ ਦੀ ਮੰਗ :
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720149286/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720149286
{'eval_loss': 7.423713684082031, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2109817842202522, 'eval_token_set_recall': 0.32662438169845365, 'eval_token_set_f1': 0.24154090999131833, 'eval_token_set_f1_sem': 0.0037222238076476608, 'eval_n_ngrams_match_1': 2.79, 'eval_n_ngrams_match_2': 1.054, 'eval_n_ngrams_match_3': 0.012, 'eval_num_true_words': 13.07, 'eval_num_pred_words': 15.32, 'eval_bleu_score': 5.417826508051038, 'eval_bleu_score_sem': 0.06440248161217277, 'eval_rouge_score': 0.20630764752443148, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8600300550460815, 'eval_emb_cos_sim_sem': 0.01025525744900128, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4359.5343, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/pan_Guru_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating tur_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: TÜRK TÜRK TÜRK TÜRK TÜRK TÜRK TÜRK TÜRK TÜRK TÜRK TÜRK!!! Auf dieser Seite
[true] query: tek parti devri TEK PARTİ DEVRİ haberleri haber haberi | Sayfa 7 Tek parti chp zamanında yapılan... 15 Şu



[pred] query: Galatasaray Istanbul hat einen Topspiel-Kader bestätigt: https://www.dna.com/wp-content/
[true] query: Anasayfa Spor Fenerbahçe-Dinamo Zagreb maçının hakemleri açıklandı kaynuka Tarih: 2018-11-27 Saat: 15:07:19 



[pred] query: Çocuk education / Çocuklar education / Çocuklar education / Çocuklar education / Çocuklar education Schritt für Schritt
[true] query: Alışveriş Annelik Bebek Çocuk Çocuk Kitapları Eğitim Sağlık 7–14 yaş çocuklar için öğretim metodları 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720149449/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720149449
{'eval_loss': 4.35856819152832, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.209938295037922, 'eval_token_set_recall': 0.31560441268397965, 'eval_token_set_f1': 0.2429814530686771, 'eval_token_set_f1_sem': 0.0033980227244063215, 'eval_n_ngrams_match_1': 3.41, 'eval_n_ngrams_match_2': 1.138, 'eval_n_ngrams_match_3': 0.05, 'eval_num_true_words': 16.658, 'eval_num_pred_words': 16.23, 'eval_bleu_score': 5.21944288501981, 'eval_bleu_score_sem': 0.06848250415516245, 'eval_rouge_score': 0.12512545074386933, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8591521978378296, 'eval_emb_cos_sim_sem': 0.01014613135567248, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 125.6385, 'eval_samples_per_second': 3.98, 'eval_steps_per_second': 0.501}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/tur_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti parti...
[true] query: tek parti devri TEK PARTİ DEVRİ haberleri haber haberi | Sayfa 7 Tek parti chp zamanında yapılan... 15 Şu



[pred] query: Fenerbahçe hat einen Topspielbericht zu Galatasaray Istanbul veröffentlicht. https://www.dnk.de/news/
[true] query: Anasayfa Spor Fenerbahçe-Dinamo Zagreb maçının hakemleri açıklandı kaynuka Tarih: 2018-11-27 Saat: 15:07:19 



[pred] query: Eine Reihe meiner Bestseller für Grundschulen - Çocuk education - Çocuk education - Çocuk education 
[true] query: Alışveriş Annelik Bebek Çocuk Çocuk Kitapları Eğitim Sağlık 7–14 yaş çocuklar için öğretim metodları 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720153886/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720153886
{'eval_loss': 4.35856819152832, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2096560495486331, 'eval_token_set_recall': 0.3143133267918873, 'eval_token_set_f1': 0.2407437895464892, 'eval_token_set_f1_sem': 0.003406670231650754, 'eval_n_ngrams_match_1': 3.39, 'eval_n_ngrams_match_2': 1.166, 'eval_n_ngrams_match_3': 0.062, 'eval_num_true_words': 16.658, 'eval_num_pred_words': 16.602, 'eval_bleu_score': 5.154260719199306, 'eval_bleu_score_sem': 0.07054243992008104, 'eval_rouge_score': 0.12208812909768865, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8567866086959839, 'eval_emb_cos_sim_sem': 0.014790334081391897, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 4365.2031, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/tur_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating kaz_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: MAĞAŞI ARBEIT & SECURITY e.V. e.V. ehrenamtliche Mitgliederversammlung
[true] query: ҚМГ АЛТЫН ЕРЕЖЕЛЕРІ - ЕҢбек қауіпсіздігі және еңбекті қОРҒау жиналыстарын



[pred] query: Vorlage der Abschnittsprüfung der Abschnittsprüfung der Abschnittsprüfung psychologie pdf 18.10.2018 pdf 18.10.2018 
[true] query: психометриялық тестілеу кестесі инструкция по приму апелляциялық ведомость 18.10.2018 ж No 578 бұйры



[pred] query: I - I - I - I - I - I - I - I - Großschöpfer der
[true] query: Ыбырай Алтынсарин - Ы - Ұлы заман Тұлғалары - Скачать Рефераты,
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720154051/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720154051
{'eval_loss': 6.408956050872803, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2171946050767261, 'eval_token_set_recall': 0.2898860313577034, 'eval_token_set_f1': 0.2406262579106963, 'eval_token_set_f1_sem': 0.003545206997608266, 'eval_n_ngrams_match_1': 3.422, 'eval_n_ngrams_match_2': 1.126, 'eval_n_ngrams_match_3': 0.054, 'eval_num_true_words': 15.352, 'eval_num_pred_words': 17.018, 'eval_bleu_score': 5.383469882279384, 'eval_bleu_score_sem': 0.08633803327466903, 'eval_rouge_score': 0.1722901396951425, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.861864447593689, 'eval_emb_cos_sim_sem': 0.005864345429031194, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 128.8691, 'eval_samples_per_second': 3.88, 'eval_steps_per_second': 0.489}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/kaz_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: MAĞAŞI ARBEIT & KONTROLLE e.V. e.V. e.V. Zusammenarbeit
[true] query: ҚМГ АЛТЫН ЕРЕЖЕЛЕРІ - ЕҢбек қауіпсіздігі және еңбекті қОРҒау жиналыстарын



[pred] query: Vorlage der psychologischen Prüfungsordnung pdf 18 pdf 18 pdf 18 pdf 18 pdf 18 pdf 18 pdf
[true] query: психометриялық тестілеу кестесі инструкция по приму апелляциялық ведомость 18.10.2018 ж No 578 бұйры



[pred] query: Ulrike - I - I - I - I - I - I - I - Großschöpfer
[true] query: Ыбырай Алтынсарин - Ы - Ұлы заман Тұлғалары - Скачать Рефераты,
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720158485/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720158485
{'eval_loss': 6.408956050872803, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.212254641772057, 'eval_token_set_recall': 0.29330397131248565, 'eval_token_set_f1': 0.23727971692976266, 'eval_token_set_f1_sem': 0.0034153792566715127, 'eval_n_ngrams_match_1': 3.314, 'eval_n_ngrams_match_2': 1.1, 'eval_n_ngrams_match_3': 0.046, 'eval_num_true_words': 15.352, 'eval_num_pred_words': 16.418, 'eval_bleu_score': 5.22775334505685, 'eval_bleu_score_sem': 0.07774783527178121, 'eval_rouge_score': 0.17341269483999128, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8586553931236267, 'eval_emb_cos_sim_sem': 0.008737110184937162, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4360.8569, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/kaz_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating cmn_Hani val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: aktuelle Konsolidierung, stark schwankende Preise, kurzfristig stark schwankende Konsolidierung...FINDAX
[true] query: 下行以及现货成交偏弱拖累,市场主导地区价格继续快速调低,邯郸中板价格重



[pred] query: {description}DOKUSOFT besitzt hochwertige, hochwertige, hochwertige Flaschenbox erfolgt nach
[true] query: 每日彩票 珍珠棉的包装定位是一种具有高强的缓冲吸震抗震作用的有明显环保效力的包装



[pred] query: neue Finanzplattform, die sich vor kurzem online entwickelt hat.https://www.money.china.com,bitcoin,
[true] query: 火币云于上个月刚刚推出,允许用户开发他们自己的类似火币网的数字货币交易平台,其中包括钱
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720158646/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720158646
{'eval_loss': 7.072175025939941, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.9140625, 'eval_token_set_precision': 0.42883839289365566, 'eval_token_set_recall': 0.23867651843863646, 'eval_token_set_f1': 0.290631030946227, 'eval_token_set_f1_sem': 0.003229136690299545, 'eval_n_ngrams_match_1': 3.16, 'eval_n_ngrams_match_2': 1.008, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 7.802, 'eval_num_pred_words': 18.264, 'eval_bleu_score': 4.6141162492124135, 'eval_bleu_score_sem': 0.07003219580603316, 'eval_rouge_score': 0.1497766167410981, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8453820943832397, 'eval_emb_cos_sim_sem': 0.008945061418400898, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 125.0945, 'eval_samples_per_second': 3.997, 'eval_steps_per_second': 0.504}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/cmn_Hani_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: aktuelle Konsolidierung stark schwankende Preise, kurzfristig stark schwankende Preise,...FINDDAX
[true] query: 下行以及现货成交偏弱拖累,市场主导地区价格继续快速调低,邯郸中板价格重



[pred] query: oben oben oben oben oben oben oben oben oben oben oben oben oben Produktbeschreibung
[true] query: 每日彩票 珍珠棉的包装定位是一种具有高强的缓冲吸震抗震作用的有明显环保效力的包装



[pred] query: neue Finanzplattform, die sich vor kurzem online entwickelt hat.https://www.funmoney.com,https://www
[true] query: 火币云于上个月刚刚推出,允许用户开发他们自己的类似火币网的数字货币交易平台,其中包括钱
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720163081/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720163081
{'eval_loss': 7.072175025939941, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 31.9140625, 'eval_token_set_precision': 0.42216685858001624, 'eval_token_set_recall': 0.23509475393028054, 'eval_token_set_f1': 0.2854596772384641, 'eval_token_set_f1_sem': 0.0030622820856383245, 'eval_n_ngrams_match_1': 3.102, 'eval_n_ngrams_match_2': 1.012, 'eval_n_ngrams_match_3': 0.002, 'eval_num_true_words': 7.802, 'eval_num_pred_words': 17.116, 'eval_bleu_score': 4.5894966164425695, 'eval_bleu_score_sem': 0.07008376304322089, 'eval_rouge_score': 0.14331156375421938, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8304550647735596, 'eval_emb_cos_sim_sem': 0.009914856451369521, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4361.0253, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/cmn_Hani_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating jpn_Jpan val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: autumn(autumn) autumn(autumn) autumn(autumn) wegen meiner kleinen Unterkunft fallen die früh
[true] query: 花立山荘では夜半から雨が降り続いていて、朝にちょっとだけ雨脚が弱くなったときに出発。 しばらく



[pred] query: yoshifuji shooting in almost wintertime. während dieser schwierigen Schneephase auch unsere
[true] query: 今シーズン初の凍結した桧原湖の湖上撮影です。 かなり結氷は進んでいましたが、まだワカサギ



[pred] query: [youtube]Diese gute Tatsache ist, dass sich die hauptsächlichen Twitter-Teams [email protected] 
[true] query: まず少なくともこの人たちチームにネット周りが強い人間がいることは間違いなくて、YouTubeのメタタグ(メタタグって?って人はこの記事
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720163242/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720163242
{'eval_loss': 7.217320442199707, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.5345396784502032, 'eval_token_set_recall': 0.2235905878950782, 'eval_token_set_f1': 0.2793968728911937, 'eval_token_set_f1_sem': 0.004671251951100589, 'eval_n_ngrams_match_1': 2.24, 'eval_n_ngrams_match_2': 1.01, 'eval_n_ngrams_match_3': 0.004, 'eval_num_true_words': 4.93, 'eval_num_pred_words': 14.944, 'eval_bleu_score': 5.01034675116953, 'eval_bleu_score_sem': 0.09892622477080869, 'eval_rouge_score': 0.1711585817328509, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8706622123718262, 'eval_emb_cos_sim_sem': 0.01218498844510952, 'eval_emb_top1_equal': 0.25, 'eval_emb_top1_equal_sem': 0.16366341987889688, 'eval_runtime': 124.9021, 'eval_samples_per_second': 4.003, 'eval_steps_per_second': 0.504}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/jpn_Jpan_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: autumn(autumn) autumn(autumn) wegen meiner kleinen Haustour fallen die frühen Morgenstunden aus,
[true] query: 花立山荘では夜半から雨が降り続いていて、朝にちょっとだけ雨脚が弱くなったときに出発。 しばらく



[pred] query: ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ ❄️ während der
[true] query: 今シーズン初の凍結した桧原湖の湖上撮影です。 かなり結氷は進んでいましたが、まだワカサギ



[pred] query: [email protected]Diese Tatsache ist wahrscheinlich, dass sich die hauptsächlichen Twitter-Teams [email protected]
[true] query: まず少なくともこの人たちチームにネット周りが強い人間がいることは間違いなくて、YouTubeのメタタグ(メタタグって?って人はこの記事
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720167676/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720167676
{'eval_loss': 7.217320442199707, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.5331745990851237, 'eval_token_set_recall': 0.2304547207608365, 'eval_token_set_f1': 0.2839374817443125, 'eval_token_set_f1_sem': 0.004817192486579569, 'eval_n_ngrams_match_1': 2.226, 'eval_n_ngrams_match_2': 1.014, 'eval_n_ngrams_match_3': 0.004, 'eval_num_true_words': 4.93, 'eval_num_pred_words': 15.116, 'eval_bleu_score': 4.944183020720835, 'eval_bleu_score_sem': 0.09834543366992266, 'eval_rouge_score': 0.1738939233178052, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8611706495285034, 'eval_emb_cos_sim_sem': 0.013567609225064317, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4359.8965, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/jpn_Jpan_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating kor_Hang val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: <br><br><br><br><br><br><br><br><br><br><br><br><br><br
[true] query: 세일 중 – Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price



[pred] query: query: Gewinnspielentscheidung ohne prüfung | Gewinnspielentscheidung ohne prüfung | Gewinnspielentscheidung ohne prüfung | 
[true] query: 신용위험 결정요인 과 관련 - 토토사이트 검증사이트 메이저토토사이트 - 토토탐정 - 신



[pred] query: Samsung iG - Iphone, Android iG - Android iG - Thailand iG - 
[true] query: 안드로이드 : 삼성바다폰 영국 온라인 등록 - 타이젠 - 안드로이드 스마트폰과 태블릿 새
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720167839/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720167839
{'eval_loss': 6.484063148498535, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.21361352976229184, 'eval_token_set_recall': 0.3055400195178063, 'eval_token_set_f1': 0.24092387456493936, 'eval_token_set_f1_sem': 0.0036298136406276832, 'eval_n_ngrams_match_1': 3.022, 'eval_n_ngrams_match_2': 1.122, 'eval_n_ngrams_match_3': 0.07, 'eval_num_true_words': 14.33, 'eval_num_pred_words': 15.478, 'eval_bleu_score': 5.100414993299953, 'eval_bleu_score_sem': 0.08024425026076791, 'eval_rouge_score': 0.17877526633547453, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8971096277236938, 'eval_emb_cos_sim_sem': 0.009572386965438188, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 126.9811, 'eval_samples_per_second': 3.938, 'eval_steps_per_second': 0.496}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/kor_Hang_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Previous Next Next Next Next Previous Next Previous Next Previous Next Previous Next Previous Next Previous Next Previous Next Previous Next Previous Next Previous Next Previous Next Next
[true] query: 세일 중 – Natural Health {% if first_available_variant.compare_at_price > first_available_variant.price



[pred] query: Gewinnspielentscheidung ohne prüfung | Gewinnspielentscheidung ohne prüfung | Gewinnspielentscheidung ohne prüfung | Gewinnspielentscheidung 
[true] query: 신용위험 결정요인 과 관련 - 토토사이트 검증사이트 메이저토토사이트 - 토토탐정 - 신



[pred] query: Android iG iG iG iG iG iG iG iG iG
[true] query: 안드로이드 : 삼성바다폰 영국 온라인 등록 - 타이젠 - 안드로이드 스마트폰과 태블릿 새
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720172274/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720172274
{'eval_loss': 6.484063148498535, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.20960210271324875, 'eval_token_set_recall': 0.30644539767078516, 'eval_token_set_f1': 0.2376102597960553, 'eval_token_set_f1_sem': 0.0035037326553992608, 'eval_n_ngrams_match_1': 2.964, 'eval_n_ngrams_match_2': 1.098, 'eval_n_ngrams_match_3': 0.06, 'eval_num_true_words': 14.33, 'eval_num_pred_words': 15.278, 'eval_bleu_score': 5.1108053241982505, 'eval_bleu_score_sem': 0.08676852625437025, 'eval_rouge_score': 0.1740992314936145, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8910717964172363, 'eval_emb_cos_sim_sem': 0.011887575257325348, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 4362.1629, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/kor_Hang_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mon_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query:...... Investitionen aus der ostafrikanischen Wirtschaft werden höher geworden.
[true] query: Алтны олборлолт амжилтад хүрнэ ОХУын гадаад өр 56 тэрбум ам.доллар болж өсчээ



[pred] query: Kommentare deaktiviert für 3 Faktoren, die Google Maps ändern müssen - Page 3 of Google Maps -
[true] query: Google Текстийн зарын өөрчлөлтийг анхаарч үзэх 3 зүйл | Martech Zone Google Текстийн зарын



[pred] query: ᐅ Ändern ᐅ Ändern ᐅ Ändern ᐅ Ändern ᐅ Ändern ᐅ Sex
[true] query: » СЕКС (1085550) » ШАР МЭДЭЭ (805751) » ӨГҮҮЛЛЭГ (906359) хөлийг 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720172434/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720172434
{'eval_loss': 7.428752899169922, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.20037541826938154, 'eval_token_set_recall': 0.3204410141114484, 'eval_token_set_f1': 0.2347760866418183, 'eval_token_set_f1_sem': 0.003031716089891082, 'eval_n_ngrams_match_1': 2.858, 'eval_n_ngrams_match_2': 1.098, 'eval_n_ngrams_match_3': 0.068, 'eval_num_true_words': 14.004, 'eval_num_pred_words': 14.242, 'eval_bleu_score': 5.728080119401564, 'eval_bleu_score_sem': 0.117271959446686, 'eval_rouge_score': 0.19375104513985808, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8716588020324707, 'eval_emb_cos_sim_sem': 0.015601580572796633, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 123.6695, 'eval_samples_per_second': 4.043, 'eval_steps_per_second': 0.509}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/mon_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: a l t l t l t l Wachstum der ostafrikanischen Ölindustrie steigt.
[true] query: Алтны олборлолт амжилтад хүрнэ ОХУын гадаад өр 56 тэрбум ам.доллар болж өсчээ



[pred] query: Kommentare deaktiviert für 3 Faktoren, die Google Maps auf Google Maps ändern müssen - Grita 
[true] query: Google Текстийн зарын өөрчлөлтийг анхаарч үзэх 3 зүйл | Martech Zone Google Текстийн зарын



[pred] query: ❱ Ältere Suche ❱ Ältere Suche ❱ Ältere Suche ❱ Ältere Suche
[true] query: » СЕКС (1085550) » ШАР МЭДЭЭ (805751) » ӨГҮҮЛЛЭГ (906359) хөлийг 
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720176867/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720176867
{'eval_loss': 7.428752899169922, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19738795777665813, 'eval_token_set_recall': 0.3351991552479173, 'eval_token_set_f1': 0.23349992603268943, 'eval_token_set_f1_sem': 0.002961734266575736, 'eval_n_ngrams_match_1': 2.816, 'eval_n_ngrams_match_2': 1.086, 'eval_n_ngrams_match_3': 0.062, 'eval_num_true_words': 14.004, 'eval_num_pred_words': 15.37, 'eval_bleu_score': 5.513744173585932, 'eval_bleu_score_sem': 0.11033594972199573, 'eval_rouge_score': 0.2034722085449902, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8787028193473816, 'eval_emb_cos_sim_sem': 0.014653966635945882, 'eval_emb_top1_equal': 0.375, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 4360.6152, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/mon_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating hun_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: Übungsanleitung: Ultraschallentzündung ohne akustisches Hörvermögen. Ultraschallentzündung ohne akustisches Hörvermögen
[true] query: Ultrahang kezelés: Fájdalomcsillapítás tűszűrás nélkül [teljes útmutató] Ízületi fájdalom fono



[pred] query: Es ist soweit. Das neue "Tampa Bay Lightning", Freitag, 13.11.2022, Tampa Bay Lightning, Mexiko
[true] query: Az új Mike Tyson | SamanSport.hu 2019. 12. 13., Péntek, 18:40 Gervonta "Tank" Davis hatalmas



[pred] query: Unsere spannende Werkstatt – The Tractor Tractor Tractor Tractor – The Tractor Tractor Tractor Tractor
[true] query: Járművek | Hobbi Zóna - Part 2 TankChair – az Off Road tolószék A rendkívüli gépezet
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720177033/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720177033
{'eval_loss': 5.069188117980957, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.20801576482513073, 'eval_token_set_recall': 0.2925493602716517, 'eval_token_set_f1': 0.23301137887824167, 'eval_token_set_f1_sem': 0.0032876145161484416, 'eval_n_ngrams_match_1': 3.396, 'eval_n_ngrams_match_2': 1.076, 'eval_n_ngrams_match_3': 0.03, 'eval_num_true_words': 16.376, 'eval_num_pred_words': 15.422, 'eval_bleu_score': 5.130365308962141, 'eval_bleu_score_sem': 0.07089807923327672, 'eval_rouge_score': 0.11280048779171675, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.885412335395813, 'eval_emb_cos_sim_sem': 0.008718611669707927, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.18898223296457348, 'eval_runtime': 129.5471, 'eval_samples_per_second': 3.86, 'eval_steps_per_second': 0.486}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/hun_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: Übungsanleitung: Ultraschallentzündung ohne akustische Füllung. Übungsanleitung: Ultraschallentzündung ohne aku
[true] query: Ultrahang kezelés: Fájdalomcsillapítás tűszűrás nélkül [teljes útmutató] Ízületi fájdalom fono



[pred] query: Es ist Freitag, 13.11.2022, das neue Trainingsteam "Tampa Bay Lightning".... 
[true] query: Az új Mike Tyson | SamanSport.hu 2019. 12. 13., Péntek, 18:40 Gervonta "Tank" Davis hatalmas



[pred] query: Unsere spannende Seite – Tractor Tractor Tractor Tractor Tractor Tractor Tractor Tractor Tractor Tractor
[true] query: Járművek | Hobbi Zóna - Part 2 TankChair – az Off Road tolószék A rendkívüli gépezet
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720181467/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720181467
{'eval_loss': 5.069188117980957, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.20723948996480007, 'eval_token_set_recall': 0.281388848664236, 'eval_token_set_f1': 0.22866726726625416, 'eval_token_set_f1_sem': 0.0032208959155072756, 'eval_n_ngrams_match_1': 3.346, 'eval_n_ngrams_match_2': 1.066, 'eval_n_ngrams_match_3': 0.028, 'eval_num_true_words': 16.376, 'eval_num_pred_words': 15.77, 'eval_bleu_score': 5.063628271874331, 'eval_bleu_score_sem': 0.06958539149055865, 'eval_rouge_score': 0.1086940549451123, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.899388313293457, 'eval_emb_cos_sim_sem': 0.008260903480324698, 'eval_emb_top1_equal': 0.625, 'eval_emb_top1_equal_sem': 0.1829812593064711, 'eval_runtime': 4360.9596, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/hun_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating mhr_Cyrl val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: 'Der letzte Tag war schwierig, 'Der letzte Tag war schwierig, 'Maja
[true] query: Тургым жапыште, шошо ага годым, кеч ик гана Кугу Качак ялыште лияш



[pred] query: ââââââââââââââ
[true] query: Мо тыгай Агавайрем? Кузе тудо эрта? Тиде да моло йодышлан вашмутым Марий в



[pred] query: «Nöre nörde nörde nörde nörde nörde nörde
[true] query: Коряк рвезе Пётр Нестеров дене мый Наро-Фоминск олаште эртыше «По
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720181627/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720181627
{'eval_loss': 7.281070709228516, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19653652181152217, 'eval_token_set_recall': 0.382557915287327, 'eval_token_set_f1': 0.24732567073149747, 'eval_token_set_f1_sem': 0.0029976624796901226, 'eval_n_ngrams_match_1': 2.766, 'eval_n_ngrams_match_2': 1.07, 'eval_n_ngrams_match_3': 0.046, 'eval_num_true_words': 13.858, 'eval_num_pred_words': 14.338, 'eval_bleu_score': 5.652260006225474, 'eval_bleu_score_sem': 0.07982345504250958, 'eval_rouge_score': 0.19122238588428558, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8171710968017578, 'eval_emb_cos_sim_sem': 0.010020810994347876, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 123.7129, 'eval_samples_per_second': 4.042, 'eval_steps_per_second': 0.509}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/mhr_Cyrl_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: 'Der letzte Tag kämpft' 'Klug kämpft' 'Klug kämpft '
[true] query: Тургым жапыште, шошо ага годым, кеч ик гана Кугу Качак ялыште лияш



[pred] query: â€žAju â€žAju â€žAju â€žAju â€ž
[true] query: Мо тыгай Агавайрем? Кузе тудо эрта? Тиде да моло йодышлан вашмутым Марий в



[pred] query: «Nöre nörde nörde nörde nörde nörde nörde
[true] query: Коряк рвезе Пётр Нестеров дене мый Наро-Фоминск олаште эртыше «По
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720186046/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720186046
{'eval_loss': 7.281070709228516, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19086548206695303, 'eval_token_set_recall': 0.39216787739531167, 'eval_token_set_f1': 0.24357321218609423, 'eval_token_set_f1_sem': 0.0028770401431463884, 'eval_n_ngrams_match_1': 2.694, 'eval_n_ngrams_match_2': 1.056, 'eval_n_ngrams_match_3': 0.044, 'eval_num_true_words': 13.858, 'eval_num_pred_words': 14.426, 'eval_bleu_score': 5.5038616681792, 'eval_bleu_score_sem': 0.07755966947333186, 'eval_rouge_score': 0.19721673620011543, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8178677558898926, 'eval_emb_cos_sim_sem': 0.004808686070389243, 'eval_emb_top1_equal': 0.125, 'eval_emb_top1_equal_sem': 0.12499999786071611, 'eval_runtime': 4346.6391, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/mhr_Cyrl_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating fin_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
[pred] query: 2018 entwickeln wir unsere ehrenamtliche Tätigkeitsschwerpunkte. asiakastatmosphäre verändert sich,
[true] query: Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. Työympäristö muutos hankkeissa tuotetaan myö



[pred] query: Unsere Arbeit soll ehrenamtlich gestaltet werden. Dafür arbeite ich: Pohjois-Pohjanlands-O
[true] query: Pohjois-suomalaisuus ja kaikille arvokas elämä - siinä tavoitteet toiminnalle. Työskentelen Diakonia-



[pred] query: Im Inhaltsverzeichnis erwähnt wurden, dass koffeinhaltige ätherischen Öle, sondern auch m
[true] query: Kun kirjoitimme koivunjalojen lääketieteellisistä ominaisuuksista, mainitsimme, että paitsi munuaiset, myös ko
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720186209/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720186209
{'eval_loss': 6.144726753234863, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19167885441012397, 'eval_token_set_recall': 0.25765401444101155, 'eval_token_set_f1': 0.20992509155734665, 'eval_token_set_f1_sem': 0.002627170041290454, 'eval_n_ngrams_match_1': 3.076, 'eval_n_ngrams_match_2': 1.048, 'eval_n_ngrams_match_3': 0.024, 'eval_num_true_words': 15.462, 'eval_num_pred_words': 14.602, 'eval_bleu_score': 5.435432639415876, 'eval_bleu_score_sem': 0.07226619861648625, 'eval_rouge_score': 0.09516777988288053, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8822082877159119, 'eval_emb_cos_sim_sem': 0.0037224583927757513, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 126.1857, 'eval_samples_per_second': 3.962, 'eval_steps_per_second': 0.499}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/fin_Latn_steps-1.json
evaluating corrector with steps 20
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 7.97 GiB is free. Including non-PyTorch memory, this process has 36.58 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 6.37 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
evaluating corrector with steps 50 and beam width 4
[pred] query: 2018 entwickeln wir unsere täglichen Arbeitsprozesse, bereichern unsere Abhängigkeit von asiakkaiden.
[true] query: Tulemme jatkamaan asiakkaan kuuntelua, osallistamista ja haastamista. Työympäristö muutos hankkeissa tuotetaan myö



[pred] query: Unsere Arbeit soll ehrenamtlich sein. Dabei arbeite ich: Pädiatrisch-ökonomisch-
[true] query: Pohjois-suomalaisuus ja kaikille arvokas elämä - siinä tavoitteet toiminnalle. Työskentelen Diakonia-



[pred] query: Im Juni wurden unsere ätherischen Öle vorgestellt, denn sie zeigen, dass koffeinhaltige Substanzen
[true] query: Kun kirjoitimme koivunjalojen lääketieteellisistä ominaisuuksista, mainitsimme, että paitsi munuaiset, myös ko
outptufile for decoded sequences:  saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720190645/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_deu_Latn_32_2layers_corrector/decoded_eval_1720190645
{'eval_loss': 6.144726753234863, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.19327929253409146, 'eval_token_set_recall': 0.25384083555763154, 'eval_token_set_f1': 0.20961182700297906, 'eval_token_set_f1_sem': 0.00247606233236163, 'eval_n_ngrams_match_1': 3.076, 'eval_n_ngrams_match_2': 1.05, 'eval_n_ngrams_match_3': 0.03, 'eval_num_true_words': 15.462, 'eval_num_pred_words': 14.772, 'eval_bleu_score': 5.420033343216571, 'eval_bleu_score_sem': 0.08528342195805771, 'eval_rouge_score': 0.09659607919810045, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8800458312034607, 'eval_emb_cos_sim_sem': 0.005219600721213253, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 4362.23, 'eval_samples_per_second': 0.115, 'eval_steps_per_second': 0.014}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_deu_Latn_32_2layers_prefix/evaluations/fin_Latn_steps-50_sbeam-4.json
evaluating corrector with steps 50 and beam width 8
CUDA out of memory. Tried to allocate 14.79 GiB. GPU 0 has a total capacty of 44.56 GiB of which 8.45 GiB is free. Including non-PyTorch memory, this process has 36.10 GiB memory in use. Of the allocated memory 29.90 GiB is allocated by PyTorch, and 5.89 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF, eval did not finish
