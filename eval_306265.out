working directory /home/cs.aau.dk/ng78zb/vec2text_exp
sif /home/cs.aau.dk/ng78zb/pytorch_23.10-py3.sif
launch evaluation yiyic/mt5_me5_cyrl-script_32_2layers_corrector
loading experiment and trainer from yiyic/mt5_me5_cyrl-script_32_2layers_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector
on rank 0, output dir: saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector
num_workers 7
Set num workers to 7
Experiment output_dir = saves/yiyic__mt5_me5_cyrl-script_32_2layers_inverter
on rank 0, output dir: saves/yiyic__mt5_me5_cyrl-script_32_2layers_inverter
adding embedding type to dataset args.
Loading datasets with TOKENIZERS_PARALLELISM = False
loading train dataset from path: /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/ba3118a6cc6bd0713dd32a64df09e3eb.arrow
loaded dict of val datasets from /home/cs.aau.dk/ng78zb/vec2text_exp/.cache/inversion/b7c2d88873c9bb4061ee54b83d4d22ce.arrow
07/06/2024 00:06:35 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
07/06/2024 00:07:36 - WARNING - accelerate.utils.other - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
data arguments for experiment: DataArguments(dataset_name='mt-ms_cyr_scrp', max_eval_samples=500, use_less_data=3000)
model yiyic/mt5_me5_cyrl-script_32_2layers_corrector parameters 890566656
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
dataset kwargs: {'remove_columns': ['text'], 'batched': True, 'batch_size': 1024, 'num_proc': 6, 'desc': 'Running tokenizer on dataset'}
Using Frozen Embeddings as Input -- Val datasets
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '24e7b7ef1b0606ddc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7cf9deee5c6ee34dc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7d3c7a3fdc899099c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'a808a07212534aa6c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '1835610d5c7fc595c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '74575508bfab4c9cc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'af6bef1b30e3c5dbc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'bfa2f55e85bb2562c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd839c9a8871bbce8c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '67555e67fd16afc9c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '48ec325196197014c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'a20c740ae5a0d86bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'cc2235accdffe49bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '104320b250ecc6cac111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'd7b432ef61da1e93c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': 'c06e214a198bcc2cc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '3ae3df71733802abc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '18a40ab4beb7f210c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '96cd5258a58b461bc111194716da8091da112d4db2a7a08e', 'num_proc': 1}
dataset kwargs: {'batched': True, 'batch_size': 128, 'new_fingerprint': '7ee1e04e96a3faa2c111194716da8091da112d4db2a7a08e', 'num_proc': 1}
output dir ./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations
evaluating deu_Latn val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-1.json already exists
evaluating corrector with steps 20
./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-20.json already exists
evaluating corrector with steps 50
./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-50.json already exists
evaluating corrector with beam width 4
./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-50_sbeam-4.json already exists
evaluating corrector with beam width 8
[pred] query: Diese Seite verfügt über Relevante Informationen über Einkaufsgutscheine. Diese Seite verfügt über Relevante Informationen über Einkaufsgutscheine.
[true] query: In unserem Themenverzeichnis finden Sie alle wichtigen Informationen zum Thema Conveniencestore. Die Artikel sind nach Relevanz sort



[pred] query: Unsere Beratung und Beratung über Beauty & Hair Studio bieten eine ganze Palette von Beauty und Wellness Dienstleistungen. Und Sie
[true] query: Unser Hair and Beauty Studio bietet Ihnen eine grosse Palette an Dienstleistungen rund um Wellness und Beauty. Dabei geht



[pred] query: 2022/12/20 · Unsere Besten Produkte Testbericht ✅ Unsere Besten Produkte Testbericht ✅ Unsere Besten Produkte
[true] query: ❱ Unsere Bestenliste Dec/2022 ᐅ Ausführlicher Produkttest ☑ Ausgezeichnete Produkte ☑ Aktuelle
outptufile for decoded sequences:  saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720234203/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720234203
{'eval_loss': 3.0406415462493896, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.29491347091460174, 'eval_token_set_recall': 0.37956057453113634, 'eval_token_set_f1': 0.326441363794302, 'eval_token_set_f1_sem': 0.004580755515309532, 'eval_n_ngrams_match_1': 5.748, 'eval_n_ngrams_match_2': 1.568, 'eval_n_ngrams_match_3': 0.224, 'eval_num_true_words': 19.254, 'eval_num_pred_words': 18.0, 'eval_bleu_score': 6.240676462182604, 'eval_bleu_score_sem': 0.17416624767922897, 'eval_rouge_score': 0.2525179041759764, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.9471467137336731, 'eval_emb_cos_sim_sem': 0.014169156705881132, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.49999999144286444, 'eval_runtime': 16833.1847, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/deu_Latn_steps-50_sbeam-8.json
evaluating ydd_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/ydd_Hebr_steps-1.json already exists
evaluating corrector with steps 20
[pred] query: ТҮРКІСТАН (Queensland) ТҮРКІСТАН (Queensland) 5 зочид буудлыг хий
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: ұйытқы - Sunnet.kz ұйытқы - Sunnet.kz ұйытқы Sunnet.kz
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: Бид Трампын уриаг түргэн зарлана: Бид Трампын уриаг түргэн зарлана IN
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720240932/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720240932
{'eval_loss': 8.248156547546387, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2531155129700021, 'eval_token_set_recall': 0.3380885686209222, 'eval_token_set_f1': 0.2862178918049035, 'eval_token_set_f1_sem': 0.003914710707681819, 'eval_n_ngrams_match_1': 3.62, 'eval_n_ngrams_match_2': 1.23, 'eval_n_ngrams_match_3': 0.104, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 12.978, 'eval_bleu_score': 6.882613728920357, 'eval_bleu_score_sem': 0.15785482675415258, 'eval_rouge_score': 0.5900544483899612, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8455482721328735, 'eval_emb_cos_sim_sem': 0.03956043866339418, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 6729.1046, 'eval_samples_per_second': 0.074, 'eval_steps_per_second': 0.037}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/ydd_Hebr_steps-20.json
evaluating corrector with steps 50
[pred] query: ТҮРКІСТАН (Queensland) ТҮРКІСТАН (Queensland) 5 зочид буудлыг хий
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: ұйытқы - Sunnet.kz ұйытқы - Sunnet.kz ұйытқы Sunnet.kz
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: Бид Трампын уриаг түргэн зарлана: Бид Трампын уриаг түргэн зарлана IN
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720257734/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720257734
{'eval_loss': 8.248156547546387, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2531155129700021, 'eval_token_set_recall': 0.3380885686209222, 'eval_token_set_f1': 0.2862178918049035, 'eval_token_set_f1_sem': 0.003914710707681819, 'eval_n_ngrams_match_1': 3.62, 'eval_n_ngrams_match_2': 1.23, 'eval_n_ngrams_match_3': 0.104, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 12.974, 'eval_bleu_score': 6.885529709256344, 'eval_bleu_score_sem': 0.15788007647020944, 'eval_rouge_score': 0.5900544483899612, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8455482721328735, 'eval_emb_cos_sim_sem': 0.03956043866339418, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16802.0219, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/ydd_Hebr_steps-50.json
evaluating corrector with beam width 4
./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/ydd_Hebr_steps-50_sbeam-4.json already exists
evaluating corrector with beam width 8
[pred] query: ТҮРКІСТАН (Queensland) ТҮРКІСТАН (Queensland) 5 зочид буудлыг хий
[true] query: טשיינאַ (מעריאַט / הילטאָן) האָטעל קאַלעקשאַן עוראָטאָפּ 5 שטערן האָטעל מאַטראַ



[pred] query: ұйытқы - Sunnet.kz ұйытқы - Sunnet.kz ұйытқы Sunnet.kz
[true] query: חול־המועד סוכּות, תּשע״ז - yiddish.forward.com חול־המועד סוכּ



[pred] query: Бид Трампын уриаг түргэн зарлана: Бид Трампын уриаг түргэн зарлана IN
[true] query: איראן פראוואקירט טראמפ: מיר וועלן אויסברייטערן דעם מיסיל פראגראם טראץ אפמא
outptufile for decoded sequences:  saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720274427/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720274427
{'eval_loss': 8.248156547546387, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.2531155129700021, 'eval_token_set_recall': 0.3380885686209222, 'eval_token_set_f1': 0.2862178918049035, 'eval_token_set_f1_sem': 0.003914710707681819, 'eval_n_ngrams_match_1': 3.62, 'eval_n_ngrams_match_2': 1.23, 'eval_n_ngrams_match_3': 0.104, 'eval_num_true_words': 14.482, 'eval_num_pred_words': 12.974, 'eval_bleu_score': 6.885529709256344, 'eval_bleu_score_sem': 0.15788007647020944, 'eval_rouge_score': 0.5900544483899612, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8455482721328735, 'eval_emb_cos_sim_sem': 0.03956043866339418, 'eval_emb_top1_equal': 0.0, 'eval_emb_top1_equal_sem': 0.0, 'eval_runtime': 16692.51, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/ydd_Hebr_steps-50_sbeam-8.json
evaluating heb_Hebr val_dataset
evaluating corrector 
evaluating corrector with steps 1
./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/heb_Hebr_steps-1.json already exists
evaluating corrector with steps 20
[pred] query: Нақтырақ айтқанда, 나는 өз ісіне қатысты бір пікір білдірген (DEFINITI DEFINITI DEFINIT
[true] query: במחקר שהתפרסם לאחרונה (ואני מתנצל שלא הגעתי לדון בו עד כה מפאת עניינים אחר



[pred] query: LATIN RADIATION. LATIN RADIATION. LATIN RADIATION нь таны елдің еркін, 
[true] query: תוכנית ריאליטי בישראל היא לא רק תוכנית ריאליטי. היא שיעור באזרחות,



[pred] query: - заңды тұлға, заңды тұлға, заңды тұлға, заңды тұлға 00192011
[true] query: בפני בקשה לעיכוב ביצוע פסק הדין אשר ניתן ביום 20.4.11 ואשר במסגרתו חו
outptufile for decoded sequences:  saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720281181/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720281181
{'eval_loss': 6.911904335021973, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.18098356196607007, 'eval_token_set_recall': 0.30812703300311706, 'eval_token_set_f1': 0.22170760102330184, 'eval_token_set_f1_sem': 0.0029082858115849768, 'eval_n_ngrams_match_1': 2.948, 'eval_n_ngrams_match_2': 1.06, 'eval_n_ngrams_match_3': 0.036, 'eval_num_true_words': 15.944, 'eval_num_pred_words': 15.71, 'eval_bleu_score': 5.122451490590996, 'eval_bleu_score_sem': 0.05313281640465037, 'eval_rouge_score': 0.4621558308127468, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8781983256340027, 'eval_emb_cos_sim_sem': 0.039100587570181984, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.49999999144286444, 'eval_runtime': 6753.8333, 'eval_samples_per_second': 0.074, 'eval_steps_per_second': 0.037}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/heb_Hebr_steps-20.json
evaluating corrector with steps 50
[pred] query: Нақтырақ айтқанда, 나는 өз ісіне қатысты бір пікір білдірген (DEFINITI DEFINITI DEFINIT
[true] query: במחקר שהתפרסם לאחרונה (ואני מתנצל שלא הגעתי לדון בו עד כה מפאת עניינים אחר



[pred] query: LATIN RADIATION. LATIN RADIATION. LATIN RADIATION нь таны елдің еркін, 
[true] query: תוכנית ריאליטי בישראל היא לא רק תוכנית ריאליטי. היא שיעור באזרחות,



[pred] query: - заңды тұлға, заңды тұлға, заңды тұлға, заңды тұлға 00192011
[true] query: בפני בקשה לעיכוב ביצוע פסק הדין אשר ניתן ביום 20.4.11 ואשר במסגרתו חו
outptufile for decoded sequences:  saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720297983/decoded_sequences.csv
saving embeddings for preds and labels ....
saving embeddings for preds and labels to saves/yiyic__mt5_me5_cyrl-script_32_2layers_corrector/decoded_eval_1720297983
{'eval_loss': 6.911904335021973, 'eval_pred_num_tokens': 31.0, 'eval_true_num_tokens': 32.0, 'eval_token_set_precision': 0.18098356196607007, 'eval_token_set_recall': 0.3082381441142282, 'eval_token_set_f1': 0.2217322164079172, 'eval_token_set_f1_sem': 0.0029098480083734036, 'eval_n_ngrams_match_1': 2.948, 'eval_n_ngrams_match_2': 1.06, 'eval_n_ngrams_match_3': 0.036, 'eval_num_true_words': 15.944, 'eval_num_pred_words': 15.71, 'eval_bleu_score': 5.12238204544952, 'eval_bleu_score_sem': 0.05312497709173449, 'eval_rouge_score': 0.4621558308127468, 'eval_exact_match': 0.0, 'eval_exact_match_sem': 0.0, 'eval_emb_cos_sim': 0.8781983256340027, 'eval_emb_cos_sim_sem': 0.039100587570181984, 'eval_emb_top1_equal': 0.5, 'eval_emb_top1_equal_sem': 0.49999999144286444, 'eval_runtime': 16802.0625, 'eval_samples_per_second': 0.03, 'eval_steps_per_second': 0.015}
saving results to ./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/heb_Hebr_steps-50.json
evaluating corrector with beam width 4
./saves/correctors/mt5_multilingual_e5_base_mt-ms_cyr_scrp_32_2layers_prefix/evaluations/heb_Hebr_steps-50_sbeam-4.json already exists
evaluating corrector with beam width 8
